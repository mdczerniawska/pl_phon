{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train and use an ASR (Automatic Speech Recognition) system, many components are required, among them - a pronunciation model. A simplest form of a pronunciation model is a dictionary of pronunciations, consisting of words in a given language and their pronunciations.\n",
    "\n",
    "Such dictionaries can be prepared by hand, using rule-based grammars or a trained model, generating pronunciations. The latter two cases are of course much more time- and cost-effective, they may however introduce some errors. A common source of such error may be a word with \"non-native\" pronunciation used in a language - often a name of a person or a product, sometimes inflected using morphological rules of the studied language.\n",
    "\n",
    "Words such as *googlowałam*, *facebook* or *Williamów* can serve as tricky examples in Polish. A simple pronunciation model may fail to provide correct pronunciation for such tokens, introducing error to the dataset. To avoid that, a \"non-native\" word detection model can be used, to find words requiring attention, for inspection of engineers or data annotators.\n",
    "\n",
    "**The type of the problem is binary classification (native vs non-native pronunciation, or in this case - Polish vs non-Polish), as further division into source languages is not necessary.**\n",
    "\n",
    "As is presented below, general-use state-of-the-art language detection models do not provide the information necessary in this case. When given examples listed above, they (correctly) identify *googlowałam* and *Williamów* as Polish words, not accounting for the \"non-native\" pronunciation.\n",
    "\n",
    "For this reason, after basic tests, the author decided to attempt to create own solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, fbeta_score, make_scorer\n",
    "from sklearn import set_config\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM, Bidirectional, Conv1D, Flatten, MaxPooling1D, Dropout, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall, PrecisionAtRecall, RecallAtPrecision\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display='diagram')\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented data is a very small random sample of OSCAR Polish corpus (https://oscar-corpus.com). It was cleaned and preprocessed using tools which are not openly available, thus the author is unable to present the full process here. Resulting sample was hand-annotated by the author.\n",
    "\n",
    "The dataset consists of 12.000 examples of words used in Polish texts with annotations: 0 for pronunciation consistent with rules of Polish pronunciation and 1 for foreign pronunciation.\n",
    "\n",
    "The dataset was divided into `train` and `test` using scikit-learn's `train_test_split` tool with options `test_size=0.2, random_state=42, stratify=y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>not_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>niekorzystnemu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>konsensualna</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>czernych</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rossija</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mondi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  not_pl\n",
       "0  niekorzystnemu       0\n",
       "1    konsensualna       0\n",
       "2        czernych       0\n",
       "3         rossija       1\n",
       "4           mondi       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('trainset.csv')\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>not_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>szambie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaiserslautern</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>krystalizująca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>przestudiuje</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zetknęliśmy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  not_pl\n",
       "0         szambie       0\n",
       "1  kaiserslautern       1\n",
       "2  krystalizująca       0\n",
       "3    przestudiuje       0\n",
       "4     zetknęliśmy       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('testset.csv')\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9600 entries, 0 to 9599\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   word    9600 non-null   object\n",
      " 1   not_pl  9600 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 150.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.124271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.329907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            not_pl\n",
       "count  9600.000000\n",
       "mean      0.124271\n",
       "std       0.329907\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is visible from the mean of `data_train.not_pl` column, the dataset is imbalanced, with **negatives about 7 times more frequent than positives**. This, however, reflects the reality of the problem - only a fraction of the words in a language are loanwords from other languages.\n",
    "\n",
    "Because of this imbalance, it is necessary to focus on metrics connected to recall and precision in model evaluation, rather than use accuracy. The main goal, business-wise, would be to minimize the number of false negatives (words with non-Polish pronunciation classified as Polish) and focus on achieving high recall, even with average precision (as all data classified as positives will be analysed in later stages of the business process).\n",
    "\n",
    "**Therefore main metrics chosen for evaluation are F-beta scores with beta=1.5 and beta=2, as well as recall.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving scores for a chosen model.\n",
    "\n",
    "def save_model_results(y_true, y_pred, model_name, save_file=True):\n",
    "    \n",
    "    '''\n",
    "    Returns pd.DataFrame with scores for given y_true, y_pred:\n",
    "    - accuracy\n",
    "    - Fbeta-score(beta=1.5) = F1.5-score\n",
    "    - F1-score\n",
    "    - Fbeta-score(beta=2) = F2-score\n",
    "    - recall\n",
    "    - precision\n",
    "    - TN, FP, FN, TP\n",
    "    \n",
    "    Saves a csv file with results in 'results' directory.\n",
    "    '''\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    summary = [model_name,\n",
    "               accuracy_score(y_true, y_pred),\n",
    "               fbeta_score(y_true, y_pred, beta=1.5),\n",
    "               f1_score(y_true, y_pred),\n",
    "               fbeta_score(y_true, y_pred, beta=2),\n",
    "               recall_score(y_true, y_pred),\n",
    "               precision_score(y_true, y_pred),\n",
    "               tn, fp, fn, tp]\n",
    "        \n",
    "    result_df = pd.DataFrame([summary])\n",
    "    result_df.columns = ['model',\n",
    "                       'accuracy',\n",
    "                       'F1.5-score',\n",
    "                       'F1-score',\n",
    "                       'F2-score',\n",
    "                       'recall',\n",
    "                       'precision',\n",
    "                       'tn','fp','fn','tp']\n",
    "    \n",
    "    result_df = result_df.sort_values(by=['F1.5-score'], ascending=False)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%y%m%d_%H%M\")\n",
    "    \n",
    "    out_file = f\"results/{model_name}_{current_time}.csv\"\n",
    "\n",
    "    pd.DataFrame.to_csv(result_df, out_file, index=False)   \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop(columns='not_pl')\n",
    "y_train = data_train.not_pl\n",
    "\n",
    "X_test = data_test.drop(columns='not_pl')\n",
    "y_test = data_test.not_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation using CountVectorizer()\n",
    "\n",
    "For neural networks consisting only of Dense() Layers.\n",
    "\n",
    "Words are represented as vectors of occurences of character 3-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_train = data_train.word\n",
    "words_test = data_test.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(3,3), analyzer='char_wb')\n",
    "\n",
    "cv = vectorizer.fit(words_train)\n",
    "\n",
    "Xcv_train = cv.transform(words_train)\n",
    "Xcv_test = cv.transform(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9600x7198 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 89000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcv_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train = Xcv_train.todense()\n",
    "Xcv_test = Xcv_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "maxabs = MaxAbsScaler()\n",
    "\n",
    "scaler.fit(Xcv_train)\n",
    "Xscaled_train = scaler.transform(Xcv_train)\n",
    "Xscaled_test = scaler.transform(Xcv_test)\n",
    "\n",
    "maxabs.fit(Xcv_train)\n",
    "Xmaxabs_train = maxabs.transform(Xcv_train)\n",
    "Xmaxabs_test = maxabs.transform(Xcv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation using Tokenizer()\n",
    "\n",
    "For neural networks with Embedding() layer.\n",
    "\n",
    "Words are represented as same-length vectors of numbers representing characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtok_train = tokenizer.texts_to_sequences(words_train)\n",
    "Xtok_test = tokenizer.texts_to_sequences(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 2, 4, 12, 3, 6, 7, 11, 10, 13, 5, 4, 14, 17],\n",
       " [12, 3, 5, 10, 4, 5, 10, 17, 1, 16, 5, 1],\n",
       " [9, 7, 4, 6, 5, 11, 9, 23],\n",
       " [6, 3, 10, 10, 2, 19, 1],\n",
       " [14, 3, 5, 18, 2]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtok_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'i': 2,\n",
       " 'o': 3,\n",
       " 'e': 4,\n",
       " 'n': 5,\n",
       " 'r': 6,\n",
       " 'z': 7,\n",
       " 'w': 8,\n",
       " 'c': 9,\n",
       " 's': 10,\n",
       " 'y': 11,\n",
       " 'k': 12,\n",
       " 't': 13,\n",
       " 'm': 14,\n",
       " 'p': 15,\n",
       " 'l': 16,\n",
       " 'u': 17,\n",
       " 'd': 18,\n",
       " 'j': 19,\n",
       " 'g': 20,\n",
       " 'ł': 21,\n",
       " 'b': 22,\n",
       " 'h': 23,\n",
       " 'ą': 24,\n",
       " 'ę': 25,\n",
       " 'ś': 26,\n",
       " 'f': 27,\n",
       " 'ó': 28,\n",
       " 'ż': 29,\n",
       " 'ń': 30,\n",
       " 'ć': 31,\n",
       " 'v': 32,\n",
       " 'ź': 33,\n",
       " 'x': 34,\n",
       " 'q': 35,\n",
       " \"'\": 36,\n",
       " 'á': 37}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = words_train.str.len().max()\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtok_train = pad_sequences(Xtok_train, padding='pre', truncating='post', maxlen=maxlen)\n",
    "Xtok_test = pad_sequences(Xtok_test, padding='pre', truncating='post',  maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  2,\n",
       "         4, 12,  3,  6,  7, 11, 10, 13,  5,  4, 14, 17],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        12,  3,  5, 10,  4,  5, 10, 17,  1, 16,  5,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  9,  7,  4,  6,  5, 11,  9, 23],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  6,  3, 10, 10,  2, 19,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0, 14,  3,  5, 18,  2]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtok_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytok_train = np.array(y_train).reshape(-1,1)\n",
    "ytok_test = np.array(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING EXISTING SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section author used information and code snippets available under the links:\n",
    "\n",
    "* https://amitness.com/2019/07/identify-text-language-python/\n",
    "* https://www.nltk.org/api/nltk.classify.html?highlight=classify%20textcat#module-nltk.classify.textcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL_PATH = './fasttext/lid.176.ftz'\n",
    "fasttext_model = fasttext.load_model(PRETRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[__label__es]</td>\n",
       "      <td>[__label__pl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7234646]</td>\n",
       "      <td>[0.9548101]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0              1\n",
       "0  [__label__es]  [__label__pl]\n",
       "1    [0.7234646]    [0.9548101]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['Conoce Jim el Google Cloud Platform en Python o JavaScript?',\n",
    "             'Wygooglowałam newsy o historii obu Williamów.']\n",
    "predictions = fasttext_model.predict(sentences)\n",
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Compact Language Detector v3 (CLD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = gcld3.NNetLanguageIdentifier(min_num_bytes=0, \n",
    "                                        max_num_bytes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Conoce Jim el Google Cloud Platform en Python o JavaScript?'\n",
    "cld_result1 = detector.FindLanguage(text=text1)\n",
    "\n",
    "text2 = 'Wygooglowałam newsy o historii obu Williamów.'\n",
    "cld_result2 = detector.FindLanguage(text=text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: es\n",
      "is the result reliable? False\n",
      "probability: 0.5869095325469971\n",
      "================\n",
      "language: pl\n",
      "is the result reliable? True\n",
      "probability: 0.9951347708702087\n"
     ]
    }
   ],
   "source": [
    "print('language:', cld_result1.language)\n",
    "print('is the result reliable?', cld_result1.is_reliable)\n",
    "print('probability:', cld_result1.probability)\n",
    "print('================')\n",
    "print('language:', cld_result2.language)\n",
    "print('is the result reliable?', cld_result2.is_reliable)\n",
    "print('probability:', cld_result2.probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.classify.textcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import textcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('eng', 18446744073709640590),\n",
       " ('eng ', 27670116110564408190),\n",
       " ('deu', 36893488147419267083),\n",
       " ('dan', 46116860184274013704),\n",
       " ('sun', 55340232221128795629)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'Conoce Jim el Google Cloud Platform en Python o JavaScript?'\n",
    "cls = textcat.TextCat()\n",
    "\n",
    "distances = cls.lang_dists(text1)\n",
    "print(cls.guess_language(text1))\n",
    "\n",
    "# show distances from languages in the corpus\n",
    "sorted_distances = sorted(distances.items(), key = lambda kv: kv[1])\n",
    "sorted_distances[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pol', 92598),\n",
       " ('eng', 73786976294838279945),\n",
       " ('eng ', 83010348331693041539),\n",
       " ('afr', 83010348331693055136),\n",
       " ('fri', 92233720368547823683)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'Wygooglowałam newsy o historii obu Williamów.'\n",
    "cls = textcat.TextCat()\n",
    "\n",
    "distances = cls.lang_dists(text2)\n",
    "print(cls.guess_language(text2))\n",
    "\n",
    "sorted_distances = sorted(distances.items(), key = lambda kv: kv[1])\n",
    "sorted_distances[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = ['wygooglowałam', 'facebook', 'Williamów']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wygooglowałam</th>\n",
       "      <th>facebook</th>\n",
       "      <th>Williamów</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>[__label__pl]</td>\n",
       "      <td>[__label__es]</td>\n",
       "      <td>[__label__pl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probability</th>\n",
       "      <td>[0.99788636]</td>\n",
       "      <td>[0.8521678]</td>\n",
       "      <td>[0.8911561]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             wygooglowałam       facebook      Williamów\n",
       "language     [__label__pl]  [__label__es]  [__label__pl]\n",
       "probability   [0.99788636]    [0.8521678]    [0.8911561]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastText\n",
    "\n",
    "predictions = fasttext_model.predict(toy)\n",
    "pd.DataFrame(predictions, columns=toy, index=['language', 'probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wygooglowałam</th>\n",
       "      <th>facebook</th>\n",
       "      <th>Williamów</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>pl</td>\n",
       "      <td>la</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probability</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.451175</td>\n",
       "      <td>0.494716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wygooglowałam  facebook Williamów\n",
       "language               pl        la        pl\n",
       "probability      0.999977  0.451175  0.494716"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLD3\n",
    "\n",
    "languages = []\n",
    "probabilities = []\n",
    "\n",
    "for item in toy:\n",
    "    \n",
    "    cld_result = detector.FindLanguage(text=item)\n",
    "    languages.append(cld_result.language)\n",
    "    probabilities.append(cld_result.probability)\n",
    "    \n",
    "cld3_toy = pd.DataFrame([languages, probabilities], columns=toy, index=['language', 'probability'])\n",
    "cld3_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wygooglowałam</th>\n",
       "      <th>facebook</th>\n",
       "      <th>Williamów</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>pol</td>\n",
       "      <td>por</td>\n",
       "      <td>pol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>29382</td>\n",
       "      <td>11252</td>\n",
       "      <td>26358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wygooglowałam facebook Williamów\n",
       "language           pol      por       pol\n",
       "distance         29382    11252     26358"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK TextCat\n",
    "\n",
    "languages = []\n",
    "dists = []\n",
    "\n",
    "cls = textcat.TextCat()\n",
    "\n",
    "for item in toy:\n",
    "\n",
    "    distances = cls.lang_dists(item)\n",
    "    sorted_distances = sorted(distances.items(), key = lambda kv: kv[1])\n",
    "    \n",
    "    languages.append(sorted_distances[0][0])\n",
    "    dists.append(sorted_distances[0][1])\n",
    "    \n",
    "nltk_toy = pd.DataFrame([languages, dists], columns=toy, index=['language', 'distance'])\n",
    "nltk_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>szambie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaiserslautern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>krystalizująca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>przestudiuje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zetknęliśmy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word\n",
       "0         szambie\n",
       "1  kaiserslautern\n",
       "2  krystalizująca\n",
       "3    przestudiuje\n",
       "4     zetknęliśmy"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_testing(X_test, y_test):\n",
    "    '''\n",
    "    Tests FastText model on a given testset and returns scores:\n",
    "    - accuracy\n",
    "    - Fbeta-score(beta=1.5) = F1.5-score\n",
    "    - F1-score\n",
    "    - Fbeta-score(beta=2) = F2-score\n",
    "    - recall\n",
    "    - precision\n",
    "    - TN, FP, FN, TP\n",
    "    \n",
    "    Saves a csv file with results and txt file with predictions created by Fasttext model.\n",
    "    '''\n",
    "    \n",
    "    PRETRAINED_MODEL_PATH = './fasttext/lid.176.ftz'\n",
    "    fasttext_model = fasttext.load_model(PRETRAINED_MODEL_PATH)\n",
    "    \n",
    "    y_pred_fasttext = []\n",
    "\n",
    "    for item in X_test:\n",
    "\n",
    "        predictions = fasttext_model.predict(item)\n",
    "        \n",
    "        if '__label__pl' in predictions[0][0]:\n",
    "            y_pred_fasttext.append(0)\n",
    "        else:\n",
    "            y_pred_fasttext.append(1)\n",
    "\n",
    "    with open('fasttext_results.txt', 'w') as f_out:\n",
    "        for item in y_pred_fasttext:\n",
    "            f_out.write(f\"{item}\\n\")\n",
    "    \n",
    "    fasttext_df = save_model_results(y_test, y_pred_fasttext, 'fasttext')\n",
    "\n",
    "    return fasttext_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>0.767917</td>\n",
       "      <td>0.591516</td>\n",
       "      <td>0.488522</td>\n",
       "      <td>0.670701</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.336283</td>\n",
       "      <td>1577</td>\n",
       "      <td>525</td>\n",
       "      <td>32</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  fasttext  0.767917    0.591516  0.488522  0.670701  0.892617   0.336283   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1577  525  32  266  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_testing(words_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google CLD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cld3_testing(X_test, y_test):\n",
    "    '''\n",
    "    Tests Google CLD3 model on a given testset and returns scores:\n",
    "    - accuracy\n",
    "    - Fbeta-score(beta=1.5) = F1.5-score\n",
    "    - F1-score\n",
    "    - Fbeta-score(beta=2) = F2-score\n",
    "    - recall\n",
    "    - precision\n",
    "    - TN, FP, FN, TP\n",
    "    \n",
    "    Saves a csv file with results and txt file with predictions created by Google CLD3 model.\n",
    "    '''\n",
    "    \n",
    "    detector = gcld3.NNetLanguageIdentifier(min_num_bytes=0,\n",
    "                                            max_num_bytes=1000)\n",
    "    \n",
    "    y_pred_cld3 = []\n",
    "\n",
    "    for item in X_test:\n",
    "\n",
    "        cld_result = detector.FindLanguage(text=item)\n",
    "        \n",
    "        if cld_result.language == 'pl':\n",
    "            y_pred_cld3.append(0)\n",
    "        else:\n",
    "            y_pred_cld3.append(1)\n",
    "\n",
    "    with open('results/cld3_results.txt', 'w') as f_out:\n",
    "        for item in y_pred_cld3:\n",
    "            f_out.write(f\"{item}\\n\")\n",
    "    \n",
    "    cld3_df = save_model_results(y_test, y_pred_cld3, 'cld3')\n",
    "\n",
    "    return cld3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cld3</td>\n",
       "      <td>0.580833</td>\n",
       "      <td>0.473001</td>\n",
       "      <td>0.360051</td>\n",
       "      <td>0.573804</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.222135</td>\n",
       "      <td>1111</td>\n",
       "      <td>991</td>\n",
       "      <td>15</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  cld3  0.580833    0.473001  0.360051  0.573804  0.949664   0.222135  1111   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  991  15  283  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cld3_testing(words_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.classify.textcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textcat_testing(X_test, y_test):\n",
    "    '''\n",
    "    Tests nltk.classify.textcat model on a given testset and returns scores:\n",
    "    - accuracy\n",
    "    - Fbeta-score(beta=1.5) = F1.5-score\n",
    "    - F1-score\n",
    "    - Fbeta-score(beta=2) = F2-score\n",
    "    - recall\n",
    "    - precision\n",
    "    - TN, FP, FN, TP\n",
    "    \n",
    "    Saves a csv file with results and txt file with predictions created by nltk.classify.textcat model.\n",
    "    '''\n",
    "    \n",
    "    cls = textcat.TextCat()\n",
    "    \n",
    "    y_pred_textcat = []\n",
    "\n",
    "    for item in X_test:\n",
    "        \n",
    "        if cls.guess_language(item) == 'pol':\n",
    "            y_pred_textcat.append(0)\n",
    "        else:\n",
    "            y_pred_textcat.append(1)\n",
    "\n",
    "    with open('results/textcat_results.txt', 'w') as f_out:\n",
    "        for item in y_pred_textcat:\n",
    "            f_out.write(f\"{item}\\n\")\n",
    "    \n",
    "    textcat_df = save_model_results(y_test, y_pred_textcat, 'textcat')\n",
    "\n",
    "    return textcat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textcat</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.61968</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>1584</td>\n",
       "      <td>518</td>\n",
       "      <td>18</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  textcat  0.776667     0.61968  0.510949  0.703518  0.939597   0.350877   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1584  518  18  280  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat_testing(words_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As testing shows, existing models do not perform well in this task. They not only generate false negatives on corner cases such as presented in toy example, but also achieve low precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING A MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "LogisticRegression() with StandardScaler() on default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"289fb97b-e000-4116-8581-5f21159b3be1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"289fb97b-e000-4116-8581-5f21159b3be1\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('countvectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                3)))]),\n",
       "                                                  'word')])),\n",
       "                ('logisticregression', LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"50da282b-ef78-4251-b907-7bbcdfd70532\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"50da282b-ef78-4251-b907-7bbcdfd70532\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('countvectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               3)))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7458426e-5b20-4a17-95fb-4dec4d903d95\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7458426e-5b20-4a17-95fb-4dec4d903d95\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f2a93863-f9b2-482f-a6ce-5d9968285154\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f2a93863-f9b2-482f-a6ce-5d9968285154\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 3))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0ee67072-7a99-47ac-b99c-19c3202ce5a2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0ee67072-7a99-47ac-b99c-19c3202ce5a2\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('countvectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                3)))]),\n",
       "                                                  'word')])),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_prepr = ColumnTransformer([(\"ngrams\",\n",
    "                                     make_pipeline(CountVectorizer(ngram_range=(3,3), analyzer=\"char_wb\")),\n",
    "                                     \"word\"),], sparse_threshold=1)\n",
    "\n",
    "baseline = make_pipeline(baseline_prepr, LogisticRegression())\n",
    "\n",
    "baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.641373</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.615994</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>2077</td>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  baseline  0.936667    0.641373  0.692308  0.615994  0.573826   0.872449   \n",
       "\n",
       "     tn  fp   fn   tp  \n",
       "0  2077  25  127  171  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_results(y_test, baseline.predict(X_test), 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms chosen for testing:\n",
    "* LogisticRegression()\n",
    "* RidgeRegression()\n",
    "* DecisionTreeClassifier()\n",
    "* SVC()\n",
    "* RandomForestClassifier()\n",
    "* KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params_part1 = {'logreg': {'penalty': ['l1', 'l2'],\n",
    "                                  'solver': ['saga'],\n",
    "                                  'max_iter': [100, 1000],\n",
    "                                  'C': [0.1, 1, 10],\n",
    "                                  'class_weight': ['dict', 'balanced'],\n",
    "                                  'fit_intercept': [True, False]},\n",
    "                       'ridge': {'alpha': [0.01, 0.1, 1, 10],\n",
    "                                 'fit_intercept': [True, False],\n",
    "                                 'normalize': [True, False],\n",
    "                                 'class_weight': ['dict', 'balanced']},\n",
    "                       'dtc': {'max_depth': [10, 50, 100, None],\n",
    "                               'min_samples_split': [2, 5, 10, 20],\n",
    "                               'min_samples_leaf': [1, 2, 5, 10, 20],\n",
    "                               'criterion':['gini', 'entropy'],\n",
    "                               'random_state': [42]}\n",
    "                      }\n",
    "                       \n",
    "\n",
    "models_params_part2 = {'knn': {'n_neighbors': [2, 5, 10, 20, 50],\n",
    "                               'metric': ['minkowski', 'canberra'],\n",
    "                               'weights': ['uniform', 'distance']},\n",
    "                       'rfc': {'random_state': [42],\n",
    "                               'n_estimators': [100],\n",
    "                               'bootstrap': [True, False],\n",
    "                               'max_depth': [None],\n",
    "                               'min_samples_split': [2, 5, 10],\n",
    "                               'min_samples_leaf': [1, 2, 5, 10],\n",
    "                               'criterion':['gini', 'entropy']},\n",
    "                       'svm': {'kernel':['linear', 'poly', 'sigmoid', 'rbf'],\n",
    "                               'degree':[3, 4],\n",
    "                               'C':[0.01, 0.1, 1, 10, 100]}\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for grid search automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b1e1a2ed23a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m def multi_classifier_automation(models_params, X_train, y_train, X_test, y_test, filename,\n\u001b[0;32m---> 88\u001b[0;31m                                 scaler=scaler, svd=svd, cv=None):\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"For each model returns a pd.DataFrame of best parameters, accuracy score for trainset and testset with best\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "def classifier_automation(model, param_grid, X_train, y_train, X_test, y_test,\n",
    "                          scaler=None, svd=False, cv=None, full_results=False):\n",
    "                          \n",
    "    \"\"\"Returns best parameters and accuracy score for trainset and testset with best parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - model:\n",
    "        - 'logreg' - sklearn.linear_model.LogisticRegression()\n",
    "        - 'dtc' - sklearn.tree.DecisionTreeClassifier()\n",
    "        - 'svm' - sklearn.svm.SVC()\n",
    "        - 'rfc' - sklearn.ensemble.RandomForestClassifier()\n",
    "        - 'knn' - sklearn.neighbors.KNeighborsClassifier()\n",
    "        - 'ridge' - sklearn.linear_model.RidgeClassifier()\n",
    "    - param_grid - parameter grid with parameters for chosen model, a dict with str keys and list values\n",
    "    - X_train, X_test - array of data\n",
    "    - y_train, y_test - array of target\n",
    "    - scaler - whether data should be scaled, default None\n",
    "        - 'standard' - StandardScaler()\n",
    "        - 'maxabs' - MaxAbsScaler()\n",
    "    - svd - whether TruncatedSVD() should be used in preprocessing, default False\n",
    "    - cv - int, number of samples for cross validation, default None (meaning: 5-fold)\n",
    "    - full_results - bool, whether GridSearchCV.cv_results_ should be returned as pd.DataFrame, default False\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    models = {'logreg': LogisticRegression(), 'dtc': DecisionTreeClassifier(), 'svm': SVC(),\n",
    "              'rfc': RandomForestClassifier(), 'knn': KNeighborsClassifier(), 'ridge': RidgeClassifier()}\n",
    "    \n",
    "    scalers = {'standard': StandardScaler(with_mean=False), 'maxabs': MaxAbsScaler()}\n",
    "\n",
    "    assert model in models.keys(), \"Chosen model is not supported, choose from: \\\n",
    "                                    logreg, dtc, svm, rfc, knn, ridge.\"\n",
    "\n",
    "    if svd:\n",
    "        \n",
    "        prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb')),\n",
    "                                     ('svd', TruncatedSVD())])\n",
    "        \n",
    "        model_param_grid = {'preprocessing__ngrams__svd__n_components':[100,256],\n",
    "                            'preprocessing__ngrams__svd__random_state':[42],\n",
    "                            'preprocessing__ngrams__svd__algorithm':['arpack', 'randomized']}\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb'),)])\n",
    "        model_param_grid = {}\n",
    "\n",
    "    preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "    if scaler=='standard':\n",
    "        \n",
    "        model_param_grid['scaler__with_mean'] = [False]\n",
    "        \n",
    "        pipe = Pipeline([('preprocessing', preprocessing),\n",
    "                         ('scaler', StandardScaler()),\n",
    "                         (model, models[model])])\n",
    "    \n",
    "    if scaler=='maxabs':\n",
    "        pipe = Pipeline([('preprocessing', preprocessing),\n",
    "                         ('scaler', MaxAbsScaler()),\n",
    "                         (model, models[model])])\n",
    "    \n",
    "    elif scaler==None:\n",
    "        pipe = Pipeline([('preprocessing', preprocessing),\n",
    "                         (model, models[model])])\n",
    "\n",
    "    for key in param_grid.keys():\n",
    "        model_key = model + '__' + key\n",
    "        model_param_grid[model_key] = param_grid[key]\n",
    "        \n",
    "    print(model_param_grid)\n",
    "    \n",
    "    f1p5_scorer = make_scorer(fbeta_score, beta=1.5)\n",
    "    \n",
    "    grid = GridSearchCV(pipe, model_param_grid, cv=cv, n_jobs=4, verbose=3, scoring=f1p5_scorer)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    train_score = grid.best_score_\n",
    "\n",
    "    if full_results:\n",
    "        return pd.DataFrame(grid.cv_results_)\n",
    "    else:\n",
    "        return [grid.best_params_, train_score, grid.score(X_test, y_test)]\n",
    "    \n",
    "    \n",
    "def multi_classifier_automation(models_params, X_train, y_train, X_test, y_test, filename,\n",
    "                                scaler=scaler, svd=svd, cv=None):\n",
    "\n",
    "    \"\"\"For each model returns a pd.DataFrame of best parameters, accuracy score for trainset and testset with best\n",
    "    parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - models_params - a dict with models as keys and dicts of parameters as values.\n",
    "        Model names must be consistent with requirements for classifier_automation function.\n",
    "    - X_train, X_test - array of data\n",
    "    - y_train, y_test - array of target\n",
    "    - filename - path for CSV export of results\n",
    "    - scaler - whether data should be scaled, default None\n",
    "    - svd - whether TruncatedSVD() should be used in preprocessing, default False\n",
    "    - cv - int, number of samples for cross validation, default None\n",
    "\n",
    "    \"\"\"\n",
    "    score = []\n",
    "\n",
    "    for model in models_params.keys():\n",
    "        result = classifier_automation(model, models_params[model], X_train, y_train, X_test, y_test,\n",
    "                                       scaler=scaler, svd=svd, cv=cv, full_results=False)\n",
    "        print(result)\n",
    "        \n",
    "        score.append([model, models_params[model],\n",
    "                         result[0],\n",
    "                         result[1],\n",
    "                         result[2]])\n",
    "\n",
    "    score_df = pd.DataFrame(score)\n",
    "    score_df.columns = ['model',\n",
    "                        'param_grid',\n",
    "                        'best_parameters',\n",
    "                        'score_train',\n",
    "                        'score_test']\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%y%m%d_%H%M\")\n",
    "    \n",
    "    out_file = f\"results/{filename}_{current_time}.csv\"\n",
    "\n",
    "    pd.DataFrame.to_csv(score_df, out_file, index=False)\n",
    "    \n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "### CountVectorizer + model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__penalty': ['l1', 'l2'], 'logreg__solver': ['saga'], 'logreg__max_iter': [100, 1000], 'logreg__C': [0.1, 1, 10], 'logreg__class_weight': ['dict', 'balanced'], 'logreg__fit_intercept': [True, False]}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed: 16.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'logreg__C': 1, 'logreg__class_weight': 'balanced', 'logreg__fit_intercept': False, 'logreg__max_iter': 1000, 'logreg__penalty': 'l2', 'logreg__solver': 'saga'}, 0.7612086346595162, 0.7637418053454362]\n",
      "{'ridge__alpha': [0.01, 0.1, 1, 10], 'ridge__fit_intercept': [True, False], 'ridge__normalize': [True, False], 'ridge__class_weight': ['dict', 'balanced']}\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=4)]: Done 160 out of 160 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ridge__alpha': 10, 'ridge__class_weight': 'balanced', 'ridge__fit_intercept': False, 'ridge__normalize': True}, 0.7624286737351296, 0.7769964841788045]\n",
      "{'dtc__max_depth': [10, 50, 100, None], 'dtc__min_samples_split': [2, 5, 10, 20], 'dtc__min_samples_leaf': [1, 2, 5, 10, 20], 'dtc__criterion': ['gini', 'entropy'], 'dtc__random_state': [42]}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dtc__criterion': 'gini', 'dtc__max_depth': None, 'dtc__min_samples_leaf': 1, 'dtc__min_samples_split': 2, 'dtc__random_state': 42}, 0.6346356419108045, 0.6247892074198987]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'penalty': ['l1', 'l2'], 'solver': ['saga'], ...</td>\n",
       "      <td>{'logreg__C': 1, 'logreg__class_weight': 'bala...</td>\n",
       "      <td>0.761209</td>\n",
       "      <td>0.763742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...</td>\n",
       "      <td>{'ridge__alpha': 10, 'ridge__class_weight': 'b...</td>\n",
       "      <td>0.762429</td>\n",
       "      <td>0.776996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtc</td>\n",
       "      <td>{'max_depth': [10, 50, 100, None], 'min_sample...</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__max_depth': N...</td>\n",
       "      <td>0.634636</td>\n",
       "      <td>0.624789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model                                         param_grid  \\\n",
       "0  logreg  {'penalty': ['l1', 'l2'], 'solver': ['saga'], ...   \n",
       "1   ridge  {'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...   \n",
       "2     dtc  {'max_depth': [10, 50, 100, None], 'min_sample...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'logreg__C': 1, 'logreg__class_weight': 'bala...     0.761209    0.763742  \n",
       "1  {'ridge__alpha': 10, 'ridge__class_weight': 'b...     0.762429    0.776996  \n",
       "2  {'dtc__criterion': 'gini', 'dtc__max_depth': N...     0.634636    0.624789  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part1, X_train, y_train, X_test, y_test,\n",
    "                            scaler=None, svd=False, filename='part1_CV_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': [2, 5, 10, 20, 50], 'knn__metric': ['minkowski', 'canberra'], 'knn__weights': ['uniform', 'distance']}\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'knn__metric': 'minkowski', 'knn__n_neighbors': 2, 'knn__weights': 'distance'}, 0.24631795532739997, 0.2405816259087905]\n",
      "{'rfc__random_state': [42], 'rfc__n_estimators': [100], 'rfc__bootstrap': [True, False], 'rfc__max_depth': [None], 'rfc__min_samples_split': [2, 5, 10], 'rfc__min_samples_leaf': [1, 2, 5, 10], 'rfc__criterion': ['gini', 'entropy']}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rfc__bootstrap': False, 'rfc__criterion': 'gini', 'rfc__max_depth': None, 'rfc__min_samples_leaf': 1, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 100, 'rfc__random_state': 42}, 0.6044342113665725, 0.6230274693161894]\n",
      "{'svm__kernel': ['linear', 'poly', 'sigmoid', 'rbf'], 'svm__degree': [3, 4], 'svm__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'svm__C': 10, 'svm__degree': 3, 'svm__kernel': 'sigmoid'}, 0.6693055352686506, 0.6836512261580382]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...</td>\n",
       "      <td>{'knn__metric': 'minkowski', 'knn__n_neighbors...</td>\n",
       "      <td>0.246318</td>\n",
       "      <td>0.240582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc</td>\n",
       "      <td>{'random_state': [42], 'n_estimators': [100], ...</td>\n",
       "      <td>{'rfc__bootstrap': False, 'rfc__criterion': 'g...</td>\n",
       "      <td>0.604434</td>\n",
       "      <td>0.623027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...</td>\n",
       "      <td>{'svm__C': 10, 'svm__degree': 3, 'svm__kernel'...</td>\n",
       "      <td>0.669306</td>\n",
       "      <td>0.683651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                         param_grid  \\\n",
       "0   knn  {'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...   \n",
       "1   rfc  {'random_state': [42], 'n_estimators': [100], ...   \n",
       "2   svm  {'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'knn__metric': 'minkowski', 'knn__n_neighbors...     0.246318    0.240582  \n",
       "1  {'rfc__bootstrap': False, 'rfc__criterion': 'g...     0.604434    0.623027  \n",
       "2  {'svm__C': 10, 'svm__degree': 3, 'svm__kernel'...     0.669306    0.683651  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part2, X_train, y_train, X_test, y_test,\n",
    "                            scaler=None, svd=False, filename='part2_CV_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer + TruncatedSVD() + model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'logreg__penalty': ['l1', 'l2'], 'logreg__solver': ['saga'], 'logreg__max_iter': [100, 1000], 'logreg__C': [0.1, 1, 10], 'logreg__class_weight': ['dict', 'balanced'], 'logreg__fit_intercept': [True, False]}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'logreg__C': 10, 'logreg__class_weight': 'balanced', 'logreg__fit_intercept': True, 'logreg__max_iter': 1000, 'logreg__penalty': 'l1', 'logreg__solver': 'saga', 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42}, 0.651744536480884, 0.6502560063016937]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'ridge__alpha': [0.01, 0.1, 1, 10], 'ridge__fit_intercept': [True, False], 'ridge__normalize': [True, False], 'ridge__class_weight': ['dict', 'balanced']}\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 640 out of 640 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'ridge__alpha': 10, 'ridge__class_weight': 'balanced', 'ridge__fit_intercept': False, 'ridge__normalize': True}, 0.6171370986704648, 0.624949290060852]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'dtc__max_depth': [10, 50, 100, None], 'dtc__min_samples_split': [2, 5, 10, 20], 'dtc__min_samples_leaf': [1, 2, 5, 10, 20], 'dtc__criterion': ['gini', 'entropy'], 'dtc__random_state': [42]}\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=4)]: Done 3200 out of 3200 | elapsed: 36.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dtc__criterion': 'gini', 'dtc__max_depth': 10, 'dtc__min_samples_leaf': 1, 'dtc__min_samples_split': 10, 'dtc__random_state': 42, 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 100, 'preprocessing__ngrams__svd__random_state': 42}, 0.4431038545897241, 0.41995425957690113]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'penalty': ['l1', 'l2'], 'solver': ['saga'], ...</td>\n",
       "      <td>{'logreg__C': 10, 'logreg__class_weight': 'bal...</td>\n",
       "      <td>0.651745</td>\n",
       "      <td>0.650256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.617137</td>\n",
       "      <td>0.624949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtc</td>\n",
       "      <td>{'max_depth': [10, 50, 100, None], 'min_sample...</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__max_depth': 1...</td>\n",
       "      <td>0.443104</td>\n",
       "      <td>0.419954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model                                         param_grid  \\\n",
       "0  logreg  {'penalty': ['l1', 'l2'], 'solver': ['saga'], ...   \n",
       "1   ridge  {'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...   \n",
       "2     dtc  {'max_depth': [10, 50, 100, None], 'min_sample...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'logreg__C': 10, 'logreg__class_weight': 'bal...     0.651745    0.650256  \n",
       "1  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.617137    0.624949  \n",
       "2  {'dtc__criterion': 'gini', 'dtc__max_depth': 1...     0.443104    0.419954  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part1, X_train, y_train, X_test, y_test,\n",
    "                            scaler=None, svd=True, filename='part1_CV_TrSVD_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'knn__n_neighbors': [2, 5, 10, 20, 50], 'knn__metric': ['minkowski', 'canberra'], 'knn__weights': ['uniform', 'distance']}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/opt/anaconda3/envs/bootcamp_project/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'knn__metric': 'minkowski', 'knn__n_neighbors': 50, 'knn__weights': 'distance', 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42}, 0.5716614698983179, 0.5842033590558331]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'rfc__random_state': [42], 'rfc__n_estimators': [100], 'rfc__bootstrap': [True, False], 'rfc__max_depth': [None], 'rfc__min_samples_split': [2, 5, 10], 'rfc__min_samples_leaf': [1, 2, 5, 10], 'rfc__criterion': ['gini', 'entropy']}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 24.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'rfc__bootstrap': False, 'rfc__criterion': 'entropy', 'rfc__max_depth': None, 'rfc__min_samples_leaf': 5, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 100, 'rfc__random_state': 42}, 0.4798243965752268, 0.45348837209302334]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'svm__kernel': ['linear', 'poly', 'sigmoid', 'rbf'], 'svm__degree': [3, 4], 'svm__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'svm__C': 100, 'svm__degree': 3, 'svm__kernel': 'rbf'}, 0.6138550958147712, 0.6017902813299233]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...</td>\n",
       "      <td>{'knn__metric': 'minkowski', 'knn__n_neighbors...</td>\n",
       "      <td>0.571661</td>\n",
       "      <td>0.584203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc</td>\n",
       "      <td>{'random_state': [42], 'n_estimators': [100], ...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.479824</td>\n",
       "      <td>0.453488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.613855</td>\n",
       "      <td>0.601790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                         param_grid  \\\n",
       "0   knn  {'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...   \n",
       "1   rfc  {'random_state': [42], 'n_estimators': [100], ...   \n",
       "2   svm  {'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'knn__metric': 'minkowski', 'knn__n_neighbors...     0.571661    0.584203  \n",
       "1  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.479824    0.453488  \n",
       "2  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.613855    0.601790  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part2, X_train, y_train, X_test, y_test,\n",
    "                            scaler=None, svd=True, filename='part2_CV_TrSVD_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer + TruncatedSVD() + StandardScaler() + model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'scaler__with_mean': [False], 'logreg__penalty': ['l1', 'l2'], 'logreg__solver': ['saga'], 'logreg__max_iter': [100, 1000], 'logreg__C': [0.1, 1, 10], 'logreg__class_weight': ['dict', 'balanced'], 'logreg__fit_intercept': [True, False]}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 19.1min finished\n",
      "/opt/anaconda3/envs/bootcamp_project/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'logreg__C': 10, 'logreg__class_weight': 'balanced', 'logreg__fit_intercept': True, 'logreg__max_iter': 1000, 'logreg__penalty': 'l2', 'logreg__solver': 'saga', 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'scaler__with_mean': False}, 0.651757069835041, 0.6523113393915448]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'scaler__with_mean': [False], 'ridge__alpha': [0.01, 0.1, 1, 10], 'ridge__fit_intercept': [True, False], 'ridge__normalize': [True, False], 'ridge__class_weight': ['dict', 'balanced']}\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.8min\n",
      "/opt/anaconda3/envs/bootcamp_project/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done 640 out of 640 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'ridge__alpha': 0.01, 'ridge__class_weight': 'balanced', 'ridge__fit_intercept': False, 'ridge__normalize': True, 'scaler__with_mean': False}, 0.615994709357017, 0.6196754563894523]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'scaler__with_mean': [False], 'dtc__max_depth': [10, 50, 100, None], 'dtc__min_samples_split': [2, 5, 10, 20], 'dtc__min_samples_leaf': [1, 2, 5, 10, 20], 'dtc__criterion': ['gini', 'entropy'], 'dtc__random_state': [42]}\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=4)]: Done 3200 out of 3200 | elapsed: 33.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dtc__criterion': 'gini', 'dtc__max_depth': 10, 'dtc__min_samples_leaf': 1, 'dtc__min_samples_split': 10, 'dtc__random_state': 42, 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 100, 'preprocessing__ngrams__svd__random_state': 42, 'scaler__with_mean': False}, 0.44182684688234913, 0.41995425957690113]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'penalty': ['l1', 'l2'], 'solver': ['saga'], ...</td>\n",
       "      <td>{'logreg__C': 10, 'logreg__class_weight': 'bal...</td>\n",
       "      <td>0.651757</td>\n",
       "      <td>0.652311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.615995</td>\n",
       "      <td>0.619675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtc</td>\n",
       "      <td>{'max_depth': [10, 50, 100, None], 'min_sample...</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__max_depth': 1...</td>\n",
       "      <td>0.441827</td>\n",
       "      <td>0.419954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model                                         param_grid  \\\n",
       "0  logreg  {'penalty': ['l1', 'l2'], 'solver': ['saga'], ...   \n",
       "1   ridge  {'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...   \n",
       "2     dtc  {'max_depth': [10, 50, 100, None], 'min_sample...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'logreg__C': 10, 'logreg__class_weight': 'bal...     0.651757    0.652311  \n",
       "1  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.615995    0.619675  \n",
       "2  {'dtc__criterion': 'gini', 'dtc__max_depth': 1...     0.441827    0.419954  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part1, X_train, y_train, X_test, y_test,\n",
    "                            scaler='standard', svd=True, filename='part1_CV_TrSVD_standard_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'scaler__with_mean': [False], 'knn__n_neighbors': [2, 5, 10, 20, 50], 'knn__metric': ['minkowski', 'canberra'], 'knn__weights': ['uniform', 'distance']}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'knn__metric': 'minkowski', 'knn__n_neighbors': 50, 'knn__weights': 'distance', 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'scaler__with_mean': False}, 0.5655805926012489, 0.6012847965738758]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'scaler__with_mean': [False], 'rfc__random_state': [42], 'rfc__n_estimators': [100], 'rfc__bootstrap': [True, False], 'rfc__max_depth': [None], 'rfc__min_samples_split': [2, 5, 10], 'rfc__min_samples_leaf': [1, 2, 5, 10], 'rfc__criterion': ['gini', 'entropy']}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 25.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'rfc__bootstrap': False, 'rfc__criterion': 'entropy', 'rfc__max_depth': None, 'rfc__min_samples_leaf': 5, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 100, 'rfc__random_state': 42, 'scaler__with_mean': False}, 0.4852259589332656, 0.4496124031007752]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'scaler__with_mean': [False], 'svm__kernel': ['linear', 'poly', 'sigmoid', 'rbf'], 'svm__degree': [3, 4], 'svm__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.2s\n",
      "/opt/anaconda3/envs/bootcamp_project/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 87.3min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed: 95.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'scaler__with_mean': False, 'svm__C': 100, 'svm__degree': 3, 'svm__kernel': 'rbf'}, 0.6252713719622048, 0.5997506234413965]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...</td>\n",
       "      <td>{'knn__metric': 'minkowski', 'knn__n_neighbors...</td>\n",
       "      <td>0.565581</td>\n",
       "      <td>0.601285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc</td>\n",
       "      <td>{'random_state': [42], 'n_estimators': [100], ...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.485226</td>\n",
       "      <td>0.449612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.625271</td>\n",
       "      <td>0.599751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                         param_grid  \\\n",
       "0   knn  {'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...   \n",
       "1   rfc  {'random_state': [42], 'n_estimators': [100], ...   \n",
       "2   svm  {'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'knn__metric': 'minkowski', 'knn__n_neighbors...     0.565581    0.601285  \n",
       "1  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.485226    0.449612  \n",
       "2  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.625271    0.599751  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part2, X_train, y_train, X_test, y_test,\n",
    "                            scaler='standard', svd=True, filename='part2_CV_TrSVD_standard_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer + TruncatedSVD() + MaxAbsScaler() + model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'logreg__penalty': ['l1', 'l2'], 'logreg__solver': ['saga'], 'logreg__max_iter': [100, 1000], 'logreg__C': [0.1, 1, 10], 'logreg__class_weight': ['dict', 'balanced'], 'logreg__fit_intercept': [True, False]}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 13.4min finished\n",
      "/opt/anaconda3/envs/bootcamp_project/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'logreg__C': 10, 'logreg__class_weight': 'balanced', 'logreg__fit_intercept': True, 'logreg__max_iter': 1000, 'logreg__penalty': 'l1', 'logreg__solver': 'saga', 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42}, 0.648948524034443, 0.6512770137524558]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'ridge__alpha': [0.01, 0.1, 1, 10], 'ridge__fit_intercept': [True, False], 'ridge__normalize': [True, False], 'ridge__class_weight': ['dict', 'balanced']}\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 640 out of 640 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'ridge__alpha': 1, 'ridge__class_weight': 'balanced', 'ridge__fit_intercept': False, 'ridge__normalize': True}, 0.6161625395690937, 0.6176708451273757]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'dtc__max_depth': [10, 50, 100, None], 'dtc__min_samples_split': [2, 5, 10, 20], 'dtc__min_samples_leaf': [1, 2, 5, 10, 20], 'dtc__criterion': ['gini', 'entropy'], 'dtc__random_state': [42]}\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=4)]: Done 3200 out of 3200 | elapsed: 32.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dtc__criterion': 'gini', 'dtc__max_depth': 10, 'dtc__min_samples_leaf': 1, 'dtc__min_samples_split': 10, 'dtc__random_state': 42, 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 100, 'preprocessing__ngrams__svd__random_state': 42}, 0.44551184762791624, 0.41995425957690113]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'penalty': ['l1', 'l2'], 'solver': ['saga'], ...</td>\n",
       "      <td>{'logreg__C': 10, 'logreg__class_weight': 'bal...</td>\n",
       "      <td>0.648949</td>\n",
       "      <td>0.651277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.616163</td>\n",
       "      <td>0.617671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtc</td>\n",
       "      <td>{'max_depth': [10, 50, 100, None], 'min_sample...</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__max_depth': 1...</td>\n",
       "      <td>0.445512</td>\n",
       "      <td>0.419954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model                                         param_grid  \\\n",
       "0  logreg  {'penalty': ['l1', 'l2'], 'solver': ['saga'], ...   \n",
       "1   ridge  {'alpha': [0.01, 0.1, 1, 10], 'fit_intercept':...   \n",
       "2     dtc  {'max_depth': [10, 50, 100, None], 'min_sample...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'logreg__C': 10, 'logreg__class_weight': 'bal...     0.648949    0.651277  \n",
       "1  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.616163    0.617671  \n",
       "2  {'dtc__criterion': 'gini', 'dtc__max_depth': 1...     0.445512    0.419954  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part1, X_train, y_train, X_test, y_test,\n",
    "                            scaler='maxabs', svd=True, filename='part1_CV_TrSVD_maxabs_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'knn__n_neighbors': [2, 5, 10, 20, 50], 'knn__metric': ['minkowski', 'canberra'], 'knn__weights': ['uniform', 'distance']}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'knn__metric': 'minkowski', 'knn__n_neighbors': 50, 'knn__weights': 'distance', 'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42}, 0.5614632731216419, 0.5718475073313782]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'rfc__random_state': [42], 'rfc__n_estimators': [100], 'rfc__bootstrap': [True, False], 'rfc__max_depth': [None], 'rfc__min_samples_split': [2, 5, 10], 'rfc__min_samples_leaf': [1, 2, 5, 10], 'rfc__criterion': ['gini', 'entropy']}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 26.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'rfc__bootstrap': False, 'rfc__criterion': 'entropy', 'rfc__max_depth': None, 'rfc__min_samples_leaf': 5, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 100, 'rfc__random_state': 42}, 0.48007397298957716, 0.4518716577540107]\n",
      "{'preprocessing__ngrams__svd__n_components': [100, 256], 'preprocessing__ngrams__svd__random_state': [42], 'preprocessing__ngrams__svd__algorithm': ['arpack', 'randomized'], 'svm__kernel': ['linear', 'poly', 'sigmoid', 'rbf'], 'svm__degree': [3, 4], 'svm__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   14.5s\n",
      "/opt/anaconda3/envs/bootcamp_project/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed: 15.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256, 'preprocessing__ngrams__svd__random_state': 42, 'svm__C': 100, 'svm__degree': 3, 'svm__kernel': 'rbf'}, 0.6225244527068583, 0.6014349332013856]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...</td>\n",
       "      <td>{'knn__metric': 'minkowski', 'knn__n_neighbors...</td>\n",
       "      <td>0.561463</td>\n",
       "      <td>0.571848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfc</td>\n",
       "      <td>{'random_state': [42], 'n_estimators': [100], ...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.480074</td>\n",
       "      <td>0.451872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...</td>\n",
       "      <td>{'preprocessing__ngrams__svd__algorithm': 'ran...</td>\n",
       "      <td>0.622524</td>\n",
       "      <td>0.601435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                         param_grid  \\\n",
       "0   knn  {'n_neighbors': [2, 5, 10, 20, 50], 'metric': ...   \n",
       "1   rfc  {'random_state': [42], 'n_estimators': [100], ...   \n",
       "2   svm  {'kernel': ['linear', 'poly', 'sigmoid', 'rbf'...   \n",
       "\n",
       "                                     best_parameters  score_train  score_test  \n",
       "0  {'knn__metric': 'minkowski', 'knn__n_neighbors...     0.561463    0.571848  \n",
       "1  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.480074    0.451872  \n",
       "2  {'preprocessing__ngrams__svd__algorithm': 'ran...     0.622524    0.601435  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_classifier_automation(models_params_part2, X_train, y_train, X_test, y_test,\n",
    "                            scaler='maxabs', svd=True, filename='part2_CV_TrSVD_maxabs_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retesting with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5f1813eb-9eb4-4b37-ae52-17a24e41d2fe\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5f1813eb-9eb4-4b37-ae52-17a24e41d2fe\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=1, class_weight='balanced',\n",
       "                                    fit_intercept=False, max_iter=1000,\n",
       "                                    solver='saga'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b5acaff2-d78a-46ca-938d-0a94c149f57a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b5acaff2-d78a-46ca-938d-0a94c149f57a\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('vectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               4)))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2838a1d7-d7cc-4e39-ac5c-25f57b54f9b2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2838a1d7-d7cc-4e39-ac5c-25f57b54f9b2\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6a7ac9aa-46b5-48ce-9581-e72300191705\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6a7ac9aa-46b5-48ce-9581-e72300191705\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 4))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"97d2d0ef-7d01-40dc-9463-28ad0d03d97e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"97d2d0ef-7d01-40dc-9463-28ad0d03d97e\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight='balanced', fit_intercept=False,\n",
       "                   max_iter=1000, solver='saga')</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=1, class_weight='balanced',\n",
       "                                    fit_intercept=False, max_iter=1000,\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression()\n",
    "# pipeline = CountVectorizer() + model\n",
    "# {'logreg__C': 1, 'logreg__class_weight': 'balanced', 'logreg__fit_intercept': False,\n",
    "#  'logreg__max_iter': 1000, 'logreg__penalty': 'l2', 'logreg__solver': 'saga'}\n",
    "\n",
    "prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb'),)])\n",
    "preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "logreg = Pipeline([('preprocessing', preprocessing),\n",
    "                 ('logreg', LogisticRegression(C=1, class_weight='balanced', fit_intercept=False, max_iter=1000,\n",
    "                                               penalty='l2', solver='saga'))])\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.763742</td>\n",
       "      <td>0.752827</td>\n",
       "      <td>0.769993</td>\n",
       "      <td>0.781879</td>\n",
       "      <td>0.725857</td>\n",
       "      <td>2014</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  logreg   0.93625    0.763742  0.752827  0.769993  0.781879   0.725857   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2014  88  65  233  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pred = logreg.predict(X_test)\n",
    "save_model_results(y_test, logreg_pred, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2452da17-28b9-4896-b4b1-40df981a8c04\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2452da17-28b9-4896-b4b1-40df981a8c04\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('ridge',\n",
       "                 RidgeClassifier(alpha=10, class_weight='balanced',\n",
       "                                 fit_intercept=False, normalize=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c62fa948-5163-48df-9ab4-3ba5ab82ae8b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c62fa948-5163-48df-9ab4-3ba5ab82ae8b\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('vectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               4)))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ceb4a977-8f1e-4924-bad1-1d8be71149da\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ceb4a977-8f1e-4924-bad1-1d8be71149da\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3c6d3b6e-f55a-4da5-b110-51fb46f95f3f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3c6d3b6e-f55a-4da5-b110-51fb46f95f3f\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 4))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"105af689-b32b-430b-9bea-b6173dfbc07c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"105af689-b32b-430b-9bea-b6173dfbc07c\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=10, class_weight='balanced', fit_intercept=False,\n",
       "                normalize=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('ridge',\n",
       "                 RidgeClassifier(alpha=10, class_weight='balanced',\n",
       "                                 fit_intercept=False, normalize=True))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RidgeClassifier()\n",
    "# pipeline = CountVectorizer() + model\n",
    "# {'ridge__alpha': 10, 'ridge__class_weight': 'balanced', 'ridge__fit_intercept': False, 'ridge__normalize': True}\n",
    "\n",
    "prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb'),)])\n",
    "preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "ridge = Pipeline([('preprocessing', preprocessing),\n",
    "                 ('ridge', RidgeClassifier(alpha=10, class_weight='balanced',\n",
    "                                           fit_intercept=False, normalize=True))])\n",
    "\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.93875</td>\n",
       "      <td>0.776996</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.784443</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.732308</td>\n",
       "      <td>2015</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  ridge   0.93875    0.776996  0.764045  0.784443  0.798658   0.732308  2015   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  87  60  238  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred = ridge.predict(X_test)\n",
    "save_model_results(y_test, ridge_pred, 'ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3963e24e-cba3-40b0-828c-00351012adab\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3963e24e-cba3-40b0-828c-00351012adab\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('dtc', DecisionTreeClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b26ee0c4-a0dc-44a0-b99f-2db40682fd10\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b26ee0c4-a0dc-44a0-b99f-2db40682fd10\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('vectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               4)))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"19302cdf-f562-4d3c-842b-95d6f064d62b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"19302cdf-f562-4d3c-842b-95d6f064d62b\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dcf419f7-b556-40be-b862-e5c193d90be7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"dcf419f7-b556-40be-b862-e5c193d90be7\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 4))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"063f84e8-4b3d-4eec-b426-c2aa9aa8a9d4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"063f84e8-4b3d-4eec-b426-c2aa9aa8a9d4\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('dtc', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier()\n",
    "# pipeline = CountVectorizer() + model\n",
    "# {'dtc__criterion': 'gini', 'dtc__max_depth': None,\n",
    "#  'dtc__min_samples_leaf': 1, 'dtc__min_samples_split': 2, 'dtc__random_state': 42}\n",
    "\n",
    "prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb'),)])\n",
    "preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "dtc = Pipeline([('preprocessing', preprocessing),\n",
    "                ('dtc', DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_leaf=1,\n",
    "                                               min_samples_split=2, random_state=42))])\n",
    "\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtc</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.624789</td>\n",
       "      <td>0.661509</td>\n",
       "      <td>0.605953</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>2054</td>\n",
       "      <td>48</td>\n",
       "      <td>127</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0   dtc  0.927083    0.624789  0.661509  0.605953  0.573826   0.780822  2054   \n",
       "\n",
       "   fp   fn   tp  \n",
       "0  48  127  171  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_pred = dtc.predict(X_test)\n",
    "save_model_results(y_test, dtc_pred, 'dtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"764355b3-69b2-4308-821e-4f07e00cc44e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"764355b3-69b2-4308-821e-4f07e00cc44e\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4))),\n",
       "                                                                  ('svd',\n",
       "                                                                   TruncatedSVD(n_components=256,\n",
       "                                                                                random_state=42))]),\n",
       "                                                  'word')])),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(n_neighbors=50, weights='distance'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"af916c15-b725-49dc-9db5-f60829160237\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"af916c15-b725-49dc-9db5-f60829160237\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('vectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               4))),\n",
       "                                                 ('svd',\n",
       "                                                  TruncatedSVD(n_components=256,\n",
       "                                                               random_state=42))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b1c7c0ca-a1b2-43c7-813c-345a6dab0bae\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b1c7c0ca-a1b2-43c7-813c-345a6dab0bae\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2b7632ed-e54e-480d-bf3c-3b9ce3905e35\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2b7632ed-e54e-480d-bf3c-3b9ce3905e35\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 4))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c2c965b9-0741-4b63-a033-71e2a8a5c632\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c2c965b9-0741-4b63-a033-71e2a8a5c632\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=256, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"75a82ddc-bfdd-4c09-8608-ca386fcfb725\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"75a82ddc-bfdd-4c09-8608-ca386fcfb725\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler(with_mean=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a7ca809f-0498-4bac-b8c1-9db2798e7613\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a7ca809f-0498-4bac-b8c1-9db2798e7613\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=50, weights='distance')</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4))),\n",
       "                                                                  ('svd',\n",
       "                                                                   TruncatedSVD(n_components=256,\n",
       "                                                                                random_state=42))]),\n",
       "                                                  'word')])),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(n_neighbors=50, weights='distance'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNeighborsClassifier()\n",
    "# pipeline = CountVectorizer + TruncatedSVD() + StandardScaler() + model\n",
    "# {'knn__metric': 'minkowski', 'knn__n_neighbors': 50, 'knn__weights': 'distance',\n",
    "#  'preprocessing__ngrams__svd__algorithm': 'randomized', 'preprocessing__ngrams__svd__n_components': 256,\n",
    "#  'preprocessing__ngrams__svd__random_state': 42, \n",
    "#  'scaler__with_mean': False}\n",
    "\n",
    "prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb')),\n",
    "                              ('svd', TruncatedSVD(n_components=256, algorithm='randomized', random_state=42))])\n",
    "\n",
    "preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "knn = Pipeline([('preprocessing', preprocessing),\n",
    "                ('scaler', StandardScaler(with_mean=False)),\n",
    "                ('knn', KNeighborsClassifier(n_neighbors=50, weights='distance', metric='minkowski'))])\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.84875</td>\n",
       "      <td>0.601285</td>\n",
       "      <td>0.543396</td>\n",
       "      <td>0.639432</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>1821</td>\n",
       "      <td>281</td>\n",
       "      <td>82</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0   knn   0.84875    0.601285  0.543396  0.639432  0.724832   0.434608  1821   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  281  82  216  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred = knn.predict(X_test)\n",
    "save_model_results(y_test, knn_pred, 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e3b55bfd-a3f6-414f-84b7-5ccdd9cbebff\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e3b55bfd-a3f6-414f-84b7-5ccdd9cbebff\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(bootstrap=False, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ff03fc59-4a4d-486d-acda-f3c4ba478981\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ff03fc59-4a4d-486d-acda-f3c4ba478981\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('vectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               4)))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c3733cc2-0805-477e-b34f-cdaa8ac1bcf6\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c3733cc2-0805-477e-b34f-cdaa8ac1bcf6\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"30f5beae-3b63-4ac0-a832-06fa49f137a1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"30f5beae-3b63-4ac0-a832-06fa49f137a1\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 4))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4fd94112-4cf2-4d08-9f6c-b93507b02fde\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4fd94112-4cf2-4d08-9f6c-b93507b02fde\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(bootstrap=False, random_state=42))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier()\n",
    "# pipeline = CountVectorizer() + model\n",
    "# {'rfc__bootstrap': False, 'rfc__criterion': 'gini', 'rfc__max_depth': None,\n",
    "#  'rfc__min_samples_leaf': 1, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 100,\n",
    "#  'rfc__random_state': 42}\n",
    "\n",
    "prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb'),)])\n",
    "preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "rfc = Pipeline([('preprocessing', preprocessing),\n",
    "                ('rfc', RandomForestClassifier(n_estimators=100, bootstrap=False, criterion='gini', max_depth=None,\n",
    "                                               min_samples_leaf=1, min_samples_split=2, random_state=42))])\n",
    "\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfc</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.623027</td>\n",
       "      <td>0.679089</td>\n",
       "      <td>0.595497</td>\n",
       "      <td>0.550336</td>\n",
       "      <td>0.886486</td>\n",
       "      <td>2081</td>\n",
       "      <td>21</td>\n",
       "      <td>134</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0   rfc  0.935417    0.623027  0.679089  0.595497  0.550336   0.886486  2081   \n",
       "\n",
       "   fp   fn   tp  \n",
       "0  21  134  164  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pred = rfc.predict(X_test)\n",
    "save_model_results(y_test, rfc_pred, 'rfc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6503e24b-2f59-4134-ad12-d80666dfdfd0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6503e24b-2f59-4134-ad12-d80666dfdfd0\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('svm', SVC(C=10, kernel='sigmoid'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"028e4994-2ea4-45c4-89a1-e51fd93daec2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"028e4994-2ea4-45c4-89a1-e51fd93daec2\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=1,\n",
       "                  transformers=[('ngrams',\n",
       "                                 Pipeline(steps=[('vectorizer',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(3,\n",
       "                                                                               4)))]),\n",
       "                                 'word')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"79db568f-986f-4df6-8d4b-16bdeb6167a2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"79db568f-986f-4df6-8d4b-16bdeb6167a2\">ngrams</label><div class=\"sk-toggleable__content\"><pre>word</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5557085a-dea5-4597-a70e-0ad0bc7ba734\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5557085a-dea5-4597-a70e-0ad0bc7ba734\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer='char_wb', ngram_range=(3, 4))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7ac9ebb7-29e1-4a9e-b472-3003d82ca6fd\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7ac9ebb7-29e1-4a9e-b472-3003d82ca6fd\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, kernel='sigmoid')</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(sparse_threshold=1,\n",
       "                                   transformers=[('ngrams',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(analyzer='char_wb',\n",
       "                                                                                   ngram_range=(3,\n",
       "                                                                                                4)))]),\n",
       "                                                  'word')])),\n",
       "                ('svm', SVC(C=10, kernel='sigmoid'))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC()\n",
    "# pipeline = CountVectorizer() + model\n",
    "# {'svm__C': 10, 'svm__degree': 3, 'svm__kernel': 'sigmoid'}\n",
    "\n",
    "prepr_transformer = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 4),analyzer='char_wb'),)])\n",
    "preprocessing = ColumnTransformer(transformers=[(\"ngrams\", prepr_transformer, \"word\")], sparse_threshold=1)\n",
    "        \n",
    "svm = Pipeline([('preprocessing', preprocessing),\n",
    "                ('svm', SVC(C=10, degree=3, kernel='sigmoid'))])\n",
    "\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.93375</td>\n",
       "      <td>0.683651</td>\n",
       "      <td>0.708257</td>\n",
       "      <td>0.670605</td>\n",
       "      <td>0.647651</td>\n",
       "      <td>0.781377</td>\n",
       "      <td>2048</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0   svm   0.93375    0.683651  0.708257  0.670605  0.647651   0.781377  2048   \n",
       "\n",
       "   fp   fn   tp  \n",
       "0  54  105  193  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred = svm.predict(X_test)\n",
    "save_model_results(y_test, svm_pred, 'svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing a parameter grid search including a few of the most popular classification algorithms in 4 variants of the pipeline, it is visible that for 5 of 6 algorithms best results are achieved on the pipeline with minimal data preparation, where sparse matrix from CountVectorizer() is fed directly to the classification algorithm.\n",
    "\n",
    "The results of RidgeClassifier() and Logistic Regression() are promising, but not satisfactory, which is why the author decided to test approaches using neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following experiments do not in any way aspire to be a thorough exploration of the possibilities.\n",
    "\n",
    "As the author is a novice in the field, following tests are a quick overview of different types of neural network architectures and layer types, with minimal parameter variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for smaller, simple MLP networks\n",
    "early_stopping = EarlyStopping(monitor=\"val_recall\",\n",
    "                               mode=\"max\",\n",
    "                               patience=5,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# used where first run with early_stopping3 showed promise\n",
    "early_stopping2 = EarlyStopping(monitor=\"val_recall\",\n",
    "                               mode=\"max\",\n",
    "                               patience=20,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "#default\n",
    "early_stopping3 = EarlyStopping(monitor=\"val_recall\",\n",
    "                               mode=\"max\",\n",
    "                               patience=10,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization = l2(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7198"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = Xcv_train.shape[-1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,201\n",
      "Trainable params: 115,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 2s 4ms/step - loss: 0.5074 - precision: 0.1313 - recall: 0.0299 - val_loss: 0.2512 - val_precision: 0.8571 - val_recall: 0.0469\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1902 - precision: 0.9475 - recall: 0.3097 - val_loss: 0.1749 - val_precision: 0.8272 - val_recall: 0.5234\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0963 - precision: 0.9407 - recall: 0.7901 - val_loss: 0.1547 - val_precision: 0.8235 - val_recall: 0.6562\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0610 - precision: 0.9655 - recall: 0.9202 - val_loss: 0.1555 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0389 - precision: 0.9765 - recall: 0.9599 - val_loss: 0.1588 - val_precision: 0.8165 - val_recall: 0.6953\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0287 - precision: 0.9848 - recall: 0.9769 - val_loss: 0.1659 - val_precision: 0.8302 - val_recall: 0.6875\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0209 - precision: 0.9824 - recall: 0.9857 - val_loss: 0.1712 - val_precision: 0.8257 - val_recall: 0.7031\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0154 - precision: 0.9949 - recall: 0.9894 - val_loss: 0.1802 - val_precision: 0.8131 - val_recall: 0.6797\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0115 - precision: 0.9933 - recall: 0.9961 - val_loss: 0.1883 - val_precision: 0.8036 - val_recall: 0.7031\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0093 - precision: 0.9931 - recall: 0.9978 - val_loss: 0.1973 - val_precision: 0.8091 - val_recall: 0.6953\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0076 - precision: 0.9979 - recall: 0.9981 - val_loss: 0.2075 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0059 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.2158 - val_precision: 0.8224 - val_recall: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9a374970>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp0 = Sequential()\n",
    "\n",
    "mlp0.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp0.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp0.summary()\n",
    "\n",
    "mlp0.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp0.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.722998</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.71281</td>\n",
       "      <td>0.694631</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>2049</td>\n",
       "      <td>53</td>\n",
       "      <td>91</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  mlp0      0.94    0.722998  0.741935   0.71281  0.694631   0.796154  2049   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  53  91  207  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp0_pred = (mlp0.predict(Xcv_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp0_pred, 'mlp0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,201\n",
      "Trainable params: 115,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 1.3442 - precision: 0.2250 - recall: 0.6486 - val_loss: 0.5388 - val_precision: 0.3623 - val_recall: 0.5859\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1562 - precision: 0.9017 - recall: 0.5966 - val_loss: 0.3833 - val_precision: 0.4369 - val_recall: 0.7031\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0566 - precision: 0.9603 - recall: 0.9082 - val_loss: 0.3766 - val_precision: 0.4509 - val_recall: 0.7891\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0267 - precision: 0.9874 - recall: 0.9754 - val_loss: 0.4001 - val_precision: 0.4375 - val_recall: 0.7656\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0126 - precision: 0.9959 - recall: 0.9864 - val_loss: 0.4214 - val_precision: 0.4353 - val_recall: 0.7891\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0085 - precision: 0.9991 - recall: 0.9934 - val_loss: 0.4454 - val_precision: 0.4244 - val_recall: 0.7891\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0050 - precision: 0.9999 - recall: 0.9945 - val_loss: 0.4638 - val_precision: 0.4292 - val_recall: 0.8047\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0047 - precision: 1.0000 - recall: 0.9926 - val_loss: 0.4840 - val_precision: 0.4204 - val_recall: 0.8047\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0028 - precision: 1.0000 - recall: 0.9962 - val_loss: 0.5010 - val_precision: 0.4204 - val_recall: 0.8047\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0026 - precision: 1.0000 - recall: 0.9956 - val_loss: 0.5194 - val_precision: 0.4221 - val_recall: 0.8047\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0019 - precision: 1.0000 - recall: 0.9972 - val_loss: 0.5357 - val_precision: 0.4170 - val_recall: 0.8047\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0018 - precision: 1.0000 - recall: 0.9952 - val_loss: 0.5508 - val_precision: 0.4163 - val_recall: 0.7969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9c31cc70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp0scaled = Sequential()\n",
    "\n",
    "mlp0scaled.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp0scaled.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp0scaled.summary()\n",
    "\n",
    "mlp0scaled.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp0scaled.fit(Xscaled_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp0scaled</td>\n",
       "      <td>0.919167</td>\n",
       "      <td>0.703055</td>\n",
       "      <td>0.690096</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>1990</td>\n",
       "      <td>112</td>\n",
       "      <td>82</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp0scaled  0.919167    0.703055  0.690096  0.710526  0.724832   0.658537   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1990  112  82  216  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp0scaled_pred = (mlp0scaled.predict(Xscaled_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp0scaled_pred, 'mlp0scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,201\n",
      "Trainable params: 115,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.4714 - precision: 0.2004 - recall: 0.0392 - val_loss: 0.2368 - val_precision: 0.8824 - val_recall: 0.1172\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1737 - precision: 0.9534 - recall: 0.4313 - val_loss: 0.1705 - val_precision: 0.8333 - val_recall: 0.5469\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0883 - precision: 0.9471 - recall: 0.8370 - val_loss: 0.1526 - val_precision: 0.8252 - val_recall: 0.6641\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0546 - precision: 0.9705 - recall: 0.9309 - val_loss: 0.1551 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0347 - precision: 0.9795 - recall: 0.9731 - val_loss: 0.1593 - val_precision: 0.8165 - val_recall: 0.6953\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0255 - precision: 0.9866 - recall: 0.9831 - val_loss: 0.1674 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0184 - precision: 0.9852 - recall: 0.9869 - val_loss: 0.1729 - val_precision: 0.8241 - val_recall: 0.6953\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0136 - precision: 0.9968 - recall: 0.9954 - val_loss: 0.1828 - val_precision: 0.8257 - val_recall: 0.7031\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0100 - precision: 0.9948 - recall: 0.9973 - val_loss: 0.1907 - val_precision: 0.8182 - val_recall: 0.7031\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0081 - precision: 0.9946 - recall: 0.9978 - val_loss: 0.2006 - val_precision: 0.8241 - val_recall: 0.6953\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0065 - precision: 0.9979 - recall: 0.9986 - val_loss: 0.2112 - val_precision: 0.8318 - val_recall: 0.6953\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0052 - precision: 0.9978 - recall: 0.9985 - val_loss: 0.2196 - val_precision: 0.8165 - val_recall: 0.6953\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0040 - precision: 0.9998 - recall: 0.9994 - val_loss: 0.2288 - val_precision: 0.8036 - val_recall: 0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdab2e25fd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp0maxabs = Sequential()\n",
    "\n",
    "mlp0maxabs.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp0maxabs.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "mlp0maxabs.summary()\n",
    "\n",
    "mlp0maxabs.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp0maxabs.fit(Xmaxabs_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp0maxabs</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.728056</td>\n",
       "      <td>0.748201</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>2052</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp0maxabs  0.941667    0.728056  0.748201  0.717241  0.697987   0.806202   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2052  50  90  208  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp0maxabs_pred = (mlp0maxabs.predict(Xmaxabs_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp0maxabs_pred, 'mlp0maxabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,201\n",
      "Trainable params: 115,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.6032 - precision: 0.1440 - recall: 0.4209 - val_loss: 0.3387 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.3064 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3003 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2495 - precision: 0.4723 - recall: 0.0021 - val_loss: 0.2630 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2173 - precision: 0.9575 - recall: 0.0991 - val_loss: 0.2284 - val_precision: 0.9444 - val_recall: 0.1328\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1713 - precision: 0.9891 - recall: 0.3829 - val_loss: 0.2007 - val_precision: 0.8824 - val_recall: 0.3516\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1378 - precision: 0.9731 - recall: 0.6379 - val_loss: 0.1822 - val_precision: 0.8194 - val_recall: 0.4609\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1097 - precision: 0.9534 - recall: 0.7891 - val_loss: 0.1693 - val_precision: 0.8242 - val_recall: 0.5859\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0910 - precision: 0.9584 - recall: 0.8573 - val_loss: 0.1627 - val_precision: 0.8261 - val_recall: 0.5938\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0740 - precision: 0.9554 - recall: 0.9021 - val_loss: 0.1579 - val_precision: 0.8283 - val_recall: 0.6406\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0652 - precision: 0.9551 - recall: 0.9203 - val_loss: 0.1558 - val_precision: 0.8173 - val_recall: 0.6641\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0552 - precision: 0.9608 - recall: 0.9394 - val_loss: 0.1566 - val_precision: 0.8155 - val_recall: 0.6562\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0483 - precision: 0.9718 - recall: 0.9468 - val_loss: 0.1574 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0420 - precision: 0.9825 - recall: 0.9570 - val_loss: 0.1582 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0348 - precision: 0.9781 - recall: 0.9672 - val_loss: 0.1596 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0325 - precision: 0.9790 - recall: 0.9767 - val_loss: 0.1623 - val_precision: 0.8241 - val_recall: 0.6953\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0260 - precision: 0.9905 - recall: 0.9819 - val_loss: 0.1656 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0245 - precision: 0.9894 - recall: 0.9846 - val_loss: 0.1688 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0225 - precision: 0.9842 - recall: 0.9803 - val_loss: 0.1719 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0192 - precision: 0.9882 - recall: 0.9878 - val_loss: 0.1762 - val_precision: 0.8286 - val_recall: 0.6797\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0150 - precision: 0.9920 - recall: 0.9970 - val_loss: 0.1795 - val_precision: 0.8241 - val_recall: 0.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdab3154910>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp1 = Sequential()\n",
    "mlp1.add(Dense(16, input_dim=input_size, activation='sigmoid'))\n",
    "mlp1.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp1.summary()\n",
    "\n",
    "mlp1.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp1.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp1</td>\n",
       "      <td>0.939583</td>\n",
       "      <td>0.712425</td>\n",
       "      <td>0.735883</td>\n",
       "      <td>0.699931</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>2053</td>\n",
       "      <td>49</td>\n",
       "      <td>96</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  mlp1  0.939583    0.712425  0.735883  0.699931  0.677852   0.804781  2053   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  49  96  202  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1_pred = (mlp1.predict(Xcv_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp1_pred, 'mlp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,201\n",
      "Trainable params: 115,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.4192 - precision: 0.2804 - recall: 0.4689 - val_loss: 0.3330 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2524 - precision: 0.6853 - recall: 0.0085 - val_loss: 0.2716 - val_precision: 0.8571 - val_recall: 0.0469\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1672 - precision: 0.9879 - recall: 0.2256 - val_loss: 0.2591 - val_precision: 0.7907 - val_recall: 0.2656\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1340 - precision: 0.9933 - recall: 0.7231 - val_loss: 0.2549 - val_precision: 0.6452 - val_recall: 0.4688\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1029 - precision: 0.8872 - recall: 0.8938 - val_loss: 0.2533 - val_precision: 0.4139 - val_recall: 0.7891\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0855 - precision: 0.8131 - recall: 0.9692 - val_loss: 0.2577 - val_precision: 0.4122 - val_recall: 0.7891\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0692 - precision: 0.8259 - recall: 0.9914 - val_loss: 0.2545 - val_precision: 0.4163 - val_recall: 0.7969\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0645 - precision: 0.8358 - recall: 0.9919 - val_loss: 0.2546 - val_precision: 0.4257 - val_recall: 0.8281\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0543 - precision: 0.8383 - recall: 0.9814 - val_loss: 0.2540 - val_precision: 0.4332 - val_recall: 0.8359\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0501 - precision: 0.9171 - recall: 0.9548 - val_loss: 0.2547 - val_precision: 0.6364 - val_recall: 0.6562\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0419 - precision: 0.9986 - recall: 0.9451 - val_loss: 0.2535 - val_precision: 0.6589 - val_recall: 0.6641\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0408 - precision: 1.0000 - recall: 0.9386 - val_loss: 0.2515 - val_precision: 0.6583 - val_recall: 0.6172\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0346 - precision: 1.0000 - recall: 0.9518 - val_loss: 0.2532 - val_precision: 0.6639 - val_recall: 0.6328\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0330 - precision: 1.0000 - recall: 0.9503 - val_loss: 0.2528 - val_precision: 0.6532 - val_recall: 0.6328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdab34b3160>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp1scaled = Sequential()\n",
    "mlp1scaled.add(Dense(16, input_dim=input_size, activation='sigmoid'))\n",
    "mlp1scaled.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp1scaled.summary()\n",
    "\n",
    "mlp1scaled.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp1scaled.fit(Xscaled_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp1scaled</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.678287</td>\n",
       "      <td>0.640805</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.748322</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>1927</td>\n",
       "      <td>175</td>\n",
       "      <td>75</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp1scaled  0.895833    0.678287  0.640805  0.701258  0.748322   0.560302   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1927  175  75  223  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1scaled_pred = (mlp1scaled.predict(Xscaled_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp1scaled_pred, 'mlp1scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,201\n",
      "Trainable params: 115,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.4365 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3318 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2962 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2860 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2296 - precision: 0.7580 - recall: 0.0133 - val_loss: 0.2390 - val_precision: 0.9167 - val_recall: 0.0859\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1864 - precision: 0.9861 - recall: 0.2974 - val_loss: 0.2049 - val_precision: 0.8667 - val_recall: 0.3047\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1405 - precision: 0.9752 - recall: 0.6227 - val_loss: 0.1828 - val_precision: 0.8333 - val_recall: 0.5078\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1113 - precision: 0.9547 - recall: 0.7695 - val_loss: 0.1706 - val_precision: 0.8295 - val_recall: 0.5703\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0893 - precision: 0.9451 - recall: 0.8747 - val_loss: 0.1624 - val_precision: 0.8191 - val_recall: 0.6016\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0741 - precision: 0.9525 - recall: 0.9146 - val_loss: 0.1597 - val_precision: 0.8163 - val_recall: 0.6250\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0609 - precision: 0.9536 - recall: 0.9398 - val_loss: 0.1574 - val_precision: 0.8155 - val_recall: 0.6562\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0541 - precision: 0.9579 - recall: 0.9401 - val_loss: 0.1571 - val_precision: 0.8173 - val_recall: 0.6641\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0461 - precision: 0.9670 - recall: 0.9547 - val_loss: 0.1599 - val_precision: 0.8155 - val_recall: 0.6562\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0403 - precision: 0.9741 - recall: 0.9634 - val_loss: 0.1616 - val_precision: 0.8137 - val_recall: 0.6484\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0352 - precision: 0.9840 - recall: 0.9690 - val_loss: 0.1632 - val_precision: 0.8190 - val_recall: 0.6719\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0291 - precision: 0.9830 - recall: 0.9747 - val_loss: 0.1652 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0277 - precision: 0.9862 - recall: 0.9839 - val_loss: 0.1684 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0218 - precision: 0.9916 - recall: 0.9849 - val_loss: 0.1723 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0207 - precision: 0.9930 - recall: 0.9892 - val_loss: 0.1758 - val_precision: 0.8302 - val_recall: 0.6875\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0191 - precision: 0.9873 - recall: 0.9863 - val_loss: 0.1790 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0162 - precision: 0.9900 - recall: 0.9978 - val_loss: 0.1836 - val_precision: 0.8224 - val_recall: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9d51c370>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp1maxabs = Sequential()\n",
    "mlp1maxabs.add(Dense(16, input_dim=input_size, activation='sigmoid'))\n",
    "mlp1maxabs.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp1maxabs.summary()\n",
    "\n",
    "mlp1maxabs.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp1maxabs.fit(Xmaxabs_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp1maxabs</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.709669</td>\n",
       "      <td>0.733577</td>\n",
       "      <td>0.696949</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.804</td>\n",
       "      <td>2053</td>\n",
       "      <td>49</td>\n",
       "      <td>97</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp1maxabs  0.939167    0.709669  0.733577  0.696949  0.674497      0.804   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2053  49  97  201  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1maxabs_pred = (mlp1maxabs.predict(Xmaxabs_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp1maxabs_pred, 'mlp1maxabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.5584 - precision: 0.1355 - recall: 0.1674 - val_loss: 0.2177 - val_precision: 0.8158 - val_recall: 0.2422\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1434 - precision: 0.8997 - recall: 0.6371 - val_loss: 0.1700 - val_precision: 0.8316 - val_recall: 0.6172\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0512 - precision: 0.9496 - recall: 0.9159 - val_loss: 0.1706 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0221 - precision: 0.9825 - recall: 0.9733 - val_loss: 0.1979 - val_precision: 0.8190 - val_recall: 0.6719\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0088 - precision: 0.9919 - recall: 0.9964 - val_loss: 0.2113 - val_precision: 0.8087 - val_recall: 0.7266\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0052 - precision: 0.9947 - recall: 0.9994 - val_loss: 0.2412 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0027 - precision: 0.9989 - recall: 0.9981 - val_loss: 0.2564 - val_precision: 0.8158 - val_recall: 0.7266\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0015 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2758 - val_precision: 0.8214 - val_recall: 0.7188\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 9.1758e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2888 - val_precision: 0.8158 - val_recall: 0.7266\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 6.9543e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3031 - val_precision: 0.8142 - val_recall: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9e51d340>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp2 = Sequential()\n",
    "mlp2.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp2.add(Dense(16, 'relu'))\n",
    "mlp2.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp2.summary()\n",
    "\n",
    "mlp2.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp2.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp2</td>\n",
       "      <td>0.93875</td>\n",
       "      <td>0.72645</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.780669</td>\n",
       "      <td>2043</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  mlp2   0.93875     0.72645  0.740741  0.718686  0.704698   0.780669  2043   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  59  88  210  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2_pred = (mlp2.predict(Xcv_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp2_pred, 'mlp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.5243 - precision: 0.2335 - recall: 0.4369 - val_loss: 0.2718 - val_precision: 0.3478 - val_recall: 0.0625\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1524 - precision: 0.8888 - recall: 0.4382 - val_loss: 0.2594 - val_precision: 0.5455 - val_recall: 0.7031\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0477 - precision: 0.9856 - recall: 0.8038 - val_loss: 0.2587 - val_precision: 0.5679 - val_recall: 0.7188\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0214 - precision: 0.9948 - recall: 0.9120 - val_loss: 0.2487 - val_precision: 0.6463 - val_recall: 0.7422\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0113 - precision: 0.9961 - recall: 0.9749 - val_loss: 0.2573 - val_precision: 0.6351 - val_recall: 0.7344\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0088 - precision: 0.9934 - recall: 0.9892 - val_loss: 0.2708 - val_precision: 0.6382 - val_recall: 0.7578\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0054 - precision: 0.9933 - recall: 0.9965 - val_loss: 0.2788 - val_precision: 0.6369 - val_recall: 0.7812\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0042 - precision: 0.9983 - recall: 0.9991 - val_loss: 0.2909 - val_precision: 0.6173 - val_recall: 0.7812\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0033 - precision: 0.9947 - recall: 0.9994 - val_loss: 0.3081 - val_precision: 0.6036 - val_recall: 0.7969\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0032 - precision: 0.9977 - recall: 0.9988 - val_loss: 0.3187 - val_precision: 0.6131 - val_recall: 0.8047\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0012 - precision: 0.9996 - recall: 1.0000 - val_loss: 0.3280 - val_precision: 0.6105 - val_recall: 0.8203\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 9.1965e-04 - precision: 0.9996 - recall: 1.0000 - val_loss: 0.3470 - val_precision: 0.6059 - val_recall: 0.8047\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 9.7303e-04 - precision: 0.9996 - recall: 1.0000 - val_loss: 0.3562 - val_precision: 0.6059 - val_recall: 0.8047\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 4.8717e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3580 - val_precision: 0.6000 - val_recall: 0.8203\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 6.8277e-04 - precision: 0.9990 - recall: 1.0000 - val_loss: 0.3691 - val_precision: 0.5943 - val_recall: 0.8125\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 3.6004e-04 - precision: 0.9995 - recall: 1.0000 - val_loss: 0.3744 - val_precision: 0.5977 - val_recall: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9e5b5190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp2scaled = Sequential()\n",
    "mlp2scaled.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp2scaled.add(Dense(16, 'relu'))\n",
    "mlp2scaled.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp2scaled.summary()\n",
    "\n",
    "mlp2scaled.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp2scaled.fit(Xscaled_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp2scaled</td>\n",
       "      <td>0.93125</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.768476</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>2000</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp2scaled   0.93125    0.758065  0.740157  0.768476  0.788591   0.697329   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  2000  102  63  235  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2scaled_pred = (mlp2scaled.predict(Xscaled_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp2scaled_pred, 'mlp2scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.5130 - precision: 0.1116 - recall: 0.0935 - val_loss: 0.2037 - val_precision: 0.8421 - val_recall: 0.3750\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1350 - precision: 0.9116 - recall: 0.6879 - val_loss: 0.1708 - val_precision: 0.8265 - val_recall: 0.6328\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0479 - precision: 0.9505 - recall: 0.9334 - val_loss: 0.1738 - val_precision: 0.8288 - val_recall: 0.7188\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0206 - precision: 0.9799 - recall: 0.9725 - val_loss: 0.2026 - val_precision: 0.7876 - val_recall: 0.6953\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.0084 - precision: 0.9925 - recall: 0.9949 - val_loss: 0.2194 - val_precision: 0.8087 - val_recall: 0.7266\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0051 - precision: 0.9941 - recall: 0.9997 - val_loss: 0.2474 - val_precision: 0.8165 - val_recall: 0.6953\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0031 - precision: 0.9965 - recall: 0.9984 - val_loss: 0.2602 - val_precision: 0.8103 - val_recall: 0.7344\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0016 - precision: 0.9989 - recall: 1.0000 - val_loss: 0.2805 - val_precision: 0.8125 - val_recall: 0.7109\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 9.5231e-04 - precision: 0.9991 - recall: 1.0000 - val_loss: 0.2922 - val_precision: 0.7982 - val_recall: 0.7109\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 7.1549e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3084 - val_precision: 0.7982 - val_recall: 0.7109\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 7.2139e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3205 - val_precision: 0.8053 - val_recall: 0.7109\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 5.0419e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3328 - val_precision: 0.8053 - val_recall: 0.7109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda61308100>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp2maxabs = Sequential()\n",
    "mlp2maxabs.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp2maxabs.add(Dense(16, 'relu'))\n",
    "mlp2maxabs.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp2maxabs.summary()\n",
    "\n",
    "mlp2maxabs.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp2maxabs.fit(Xmaxabs_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp2maxabs</td>\n",
       "      <td>0.93875</td>\n",
       "      <td>0.714825</td>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>2049</td>\n",
       "      <td>53</td>\n",
       "      <td>94</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp2maxabs   0.93875    0.714825  0.735135  0.703934  0.684564   0.793774   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2049  53  94  204  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2maxabs_pred = (mlp2maxabs.predict(Xmaxabs_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp2maxabs_pred, 'mlp2maxabs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data scaled MaxAbsScaler() did not improve results in the first 3 models, it was not used further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.4640 - precision: 0.2993 - recall: 0.0167 - val_loss: 0.2416 - val_precision: 0.7969 - val_recall: 0.3984\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1853 - precision: 0.9240 - recall: 0.6647 - val_loss: 0.2195 - val_precision: 0.8229 - val_recall: 0.6172\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1196 - precision: 0.9462 - recall: 0.8923 - val_loss: 0.2083 - val_precision: 0.7965 - val_recall: 0.7031\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0942 - precision: 0.9744 - recall: 0.9580 - val_loss: 0.2270 - val_precision: 0.8148 - val_recall: 0.6875\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0813 - precision: 0.9826 - recall: 0.9723 - val_loss: 0.2177 - val_precision: 0.7869 - val_recall: 0.7500\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0764 - precision: 0.9812 - recall: 0.9807 - val_loss: 0.2415 - val_precision: 0.7398 - val_recall: 0.7109\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0729 - precision: 0.9830 - recall: 0.9826 - val_loss: 0.2437 - val_precision: 0.7500 - val_recall: 0.6797\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0714 - precision: 0.9763 - recall: 0.9843 - val_loss: 0.2588 - val_precision: 0.7500 - val_recall: 0.6797\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0661 - precision: 0.9842 - recall: 0.9880 - val_loss: 0.2556 - val_precision: 0.7165 - val_recall: 0.7109\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0658 - precision: 0.9878 - recall: 0.9872 - val_loss: 0.2474 - val_precision: 0.7719 - val_recall: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda230caee0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp3 = Sequential()\n",
    "mlp3.add(Dense(16, input_dim=input_size, activation='relu', kernel_regularizer=regularization))\n",
    "mlp3.add(Dense(16, 'relu', kernel_regularizer=regularization))\n",
    "mlp3.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp3.summary()\n",
    "\n",
    "mlp3.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp3.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp3</td>\n",
       "      <td>0.937917</td>\n",
       "      <td>0.726815</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.708054</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>2040</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  mlp3  0.937917    0.726815  0.739054  0.720137  0.708054   0.772894  2040   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  62  87  211  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3_pred = (mlp3.predict(Xcv_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp3_pred, 'mlp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.9048 - precision: 0.2223 - recall: 0.5482 - val_loss: 0.3926 - val_precision: 0.6977 - val_recall: 0.2344\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2651 - precision: 0.9450 - recall: 0.4869 - val_loss: 0.3102 - val_precision: 0.8148 - val_recall: 0.5156\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1623 - precision: 0.9814 - recall: 0.7453 - val_loss: 0.2687 - val_precision: 0.7647 - val_recall: 0.6094\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1182 - precision: 0.9908 - recall: 0.8854 - val_loss: 0.2554 - val_precision: 0.7611 - val_recall: 0.6719\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0915 - precision: 0.9937 - recall: 0.9490 - val_loss: 0.2371 - val_precision: 0.7462 - val_recall: 0.7578\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0742 - precision: 0.9956 - recall: 0.9864 - val_loss: 0.2262 - val_precision: 0.7597 - val_recall: 0.7656\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0596 - precision: 0.9921 - recall: 0.9893 - val_loss: 0.2447 - val_precision: 0.6711 - val_recall: 0.7969\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0541 - precision: 0.9903 - recall: 0.9903 - val_loss: 0.2486 - val_precision: 0.7279 - val_recall: 0.7734\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0515 - precision: 0.9870 - recall: 0.9848 - val_loss: 0.2615 - val_precision: 0.6913 - val_recall: 0.8047\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0527 - precision: 0.9814 - recall: 0.9788 - val_loss: 0.3079 - val_precision: 0.6986 - val_recall: 0.7969\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0601 - precision: 0.9827 - recall: 0.9735 - val_loss: 0.3171 - val_precision: 0.6561 - val_recall: 0.8047\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0524 - precision: 0.9902 - recall: 0.9872 - val_loss: 0.2842 - val_precision: 0.7042 - val_recall: 0.7812\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0454 - precision: 0.9883 - recall: 0.9969 - val_loss: 0.3052 - val_precision: 0.6667 - val_recall: 0.8125\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0423 - precision: 0.9953 - recall: 0.9851 - val_loss: 0.3109 - val_precision: 0.6871 - val_recall: 0.7891\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0384 - precision: 0.9956 - recall: 0.9961 - val_loss: 0.2782 - val_precision: 0.6944 - val_recall: 0.7812\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0375 - precision: 0.9926 - recall: 0.9918 - val_loss: 0.3288 - val_precision: 0.7163 - val_recall: 0.7891\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0396 - precision: 0.9965 - recall: 0.9945 - val_loss: 0.3253 - val_precision: 0.7444 - val_recall: 0.7734\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0383 - precision: 0.9880 - recall: 0.9838 - val_loss: 0.3380 - val_precision: 0.6667 - val_recall: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda22ed9520>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp3scaled = Sequential()\n",
    "mlp3scaled.add(Dense(16, input_dim=input_size, activation='relu', kernel_regularizer=regularization))\n",
    "mlp3scaled.add(Dense(16, 'relu', kernel_regularizer=regularization))\n",
    "mlp3scaled.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp3scaled.summary()\n",
    "\n",
    "mlp3scaled.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp3scaled.fit(Xscaled_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp3scaled</td>\n",
       "      <td>0.932083</td>\n",
       "      <td>0.712375</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.708475</td>\n",
       "      <td>0.701342</td>\n",
       "      <td>0.738516</td>\n",
       "      <td>2028</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp3scaled  0.932083    0.712375  0.719449  0.708475  0.701342   0.738516   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2028  74  89  209  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3scaled_pred = (mlp3scaled.predict(Xscaled_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp3scaled_pred, 'mlp3scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.5177 - precision: 0.0830 - recall: 0.0213 - val_loss: 0.2794 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2497 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.2163 - precision: 0.0443 - recall: 5.5297e-04 - val_loss: 0.2423 - val_precision: 0.8889 - val_recall: 0.3750\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.2032 - precision: 0.9426 - recall: 0.5713 - val_loss: 0.2461 - val_precision: 0.8485 - val_recall: 0.4375\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1862 - precision: 0.9445 - recall: 0.7181 - val_loss: 0.2476 - val_precision: 0.8421 - val_recall: 0.5000\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1759 - precision: 0.9440 - recall: 0.8039 - val_loss: 0.2492 - val_precision: 0.8043 - val_recall: 0.5781\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1628 - precision: 0.9171 - recall: 0.8397 - val_loss: 0.2427 - val_precision: 0.8095 - val_recall: 0.6641\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1596 - precision: 0.9240 - recall: 0.8674 - val_loss: 0.2469 - val_precision: 0.8100 - val_recall: 0.6328\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1485 - precision: 0.9231 - recall: 0.8903 - val_loss: 0.2493 - val_precision: 0.7434 - val_recall: 0.6562\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1487 - precision: 0.9214 - recall: 0.9066 - val_loss: 0.2613 - val_precision: 0.7921 - val_recall: 0.6250\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1400 - precision: 0.9145 - recall: 0.9195 - val_loss: 0.2650 - val_precision: 0.7767 - val_recall: 0.6250\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1410 - precision: 0.9097 - recall: 0.9258 - val_loss: 0.2727 - val_precision: 0.7714 - val_recall: 0.6328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda23ce5cd0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp4 = Sequential()\n",
    "mlp4.add(Dense(16, input_dim=input_size, activation='relu', kernel_regularizer=regularization))\n",
    "mlp4.add(Dropout(0.5))\n",
    "mlp4.add(Dense(16, 'relu', kernel_regularizer=regularization))\n",
    "mlp4.add(Dropout(0.5))\n",
    "mlp4.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp4.summary()\n",
    "\n",
    "mlp4.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp4.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp4</td>\n",
       "      <td>0.93125</td>\n",
       "      <td>0.647454</td>\n",
       "      <td>0.683301</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>2057</td>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  mlp4   0.93125    0.647454  0.683301  0.628975  0.597315   0.798206  2057   \n",
       "\n",
       "   fp   fn   tp  \n",
       "0  45  120  178  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4_pred = (mlp4.predict(Xcv_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp4_pred, 'mlp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                115184    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 115,473\n",
      "Trainable params: 115,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.5839 - precision: 0.1573 - recall: 0.6063 - val_loss: 0.4424 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.7083 - precision: 0.2752 - recall: 0.2659 - val_loss: 0.3119 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.4438 - precision: 0.3187 - recall: 0.2552 - val_loss: 0.2832 - val_precision: 1.0000 - val_recall: 0.0078\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.3470 - precision: 0.4222 - recall: 0.2692 - val_loss: 0.2773 - val_precision: 1.0000 - val_recall: 0.0234\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2701 - precision: 0.5149 - recall: 0.2623 - val_loss: 0.2721 - val_precision: 1.0000 - val_recall: 0.0156\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2399 - precision: 0.6212 - recall: 0.2909 - val_loss: 0.2711 - val_precision: 1.0000 - val_recall: 0.0547\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.2146 - precision: 0.6314 - recall: 0.3040 - val_loss: 0.2634 - val_precision: 1.0000 - val_recall: 0.1094\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1992 - precision: 0.6865 - recall: 0.3918 - val_loss: 0.2619 - val_precision: 0.9444 - val_recall: 0.1328\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1765 - precision: 0.7480 - recall: 0.4138 - val_loss: 0.2557 - val_precision: 0.9333 - val_recall: 0.2188\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1685 - precision: 0.7752 - recall: 0.4474 - val_loss: 0.2627 - val_precision: 0.8298 - val_recall: 0.3047\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1418 - precision: 0.8274 - recall: 0.5065 - val_loss: 0.2696 - val_precision: 0.8200 - val_recall: 0.3203\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1331 - precision: 0.8609 - recall: 0.5596 - val_loss: 0.2650 - val_precision: 0.7969 - val_recall: 0.3984\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1188 - precision: 0.8877 - recall: 0.5531 - val_loss: 0.2701 - val_precision: 0.6909 - val_recall: 0.5938\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1202 - precision: 0.8824 - recall: 0.5704 - val_loss: 0.2598 - val_precision: 0.6462 - val_recall: 0.6562\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1100 - precision: 0.9312 - recall: 0.6214 - val_loss: 0.3064 - val_precision: 0.4870 - val_recall: 0.7344\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0987 - precision: 0.9056 - recall: 0.6197 - val_loss: 0.3493 - val_precision: 0.4524 - val_recall: 0.7422\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1086 - precision: 0.9295 - recall: 0.6115 - val_loss: 0.4672 - val_precision: 0.4138 - val_recall: 0.7500\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0986 - precision: 0.9337 - recall: 0.6035 - val_loss: 0.5261 - val_precision: 0.4093 - val_recall: 0.7578\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0935 - precision: 0.9528 - recall: 0.6157 - val_loss: 0.6670 - val_precision: 0.4118 - val_recall: 0.7656\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0911 - precision: 0.9646 - recall: 0.6240 - val_loss: 0.7554 - val_precision: 0.4160 - val_recall: 0.7734\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0853 - precision: 0.9538 - recall: 0.6549 - val_loss: 0.9179 - val_precision: 0.4076 - val_recall: 0.7578\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0947 - precision: 0.9616 - recall: 0.6042 - val_loss: 1.1245 - val_precision: 0.4093 - val_recall: 0.7578\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0889 - precision: 0.9666 - recall: 0.6519 - val_loss: 1.2333 - val_precision: 0.4118 - val_recall: 0.7656\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0758 - precision: 0.9787 - recall: 0.6435 - val_loss: 1.2706 - val_precision: 0.4085 - val_recall: 0.7500\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.0761 - precision: 0.9700 - recall: 0.6463 - val_loss: 1.5633 - val_precision: 0.4076 - val_recall: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda20a178b0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp4scaled = Sequential()\n",
    "mlp4scaled.add(Dense(16, input_dim=input_size, activation='relu'))\n",
    "mlp4scaled.add(Dropout(0.5))\n",
    "mlp4scaled.add(Dense(16, 'relu'))\n",
    "mlp4scaled.add(Dropout(0.5))\n",
    "mlp4scaled.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp4scaled.summary()\n",
    "\n",
    "mlp4scaled.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp4scaled.fit(Xscaled_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp4scaled</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.710141</td>\n",
       "      <td>0.715753</td>\n",
       "      <td>0.707037</td>\n",
       "      <td>0.701342</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>2025</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  mlp4scaled  0.930833    0.710141  0.715753  0.707037  0.701342   0.730769   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2025  77  89  209  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4scaled_pred = (mlp4scaled.predict(Xscaled_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp4scaled_pred, 'mlp4scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                230368    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 230,913\n",
      "Trainable params: 230,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.5145 - precision: 0.0807 - recall: 0.0469 - val_loss: 0.2788 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.2439 - precision: 0.3359 - recall: 0.0055 - val_loss: 0.2556 - val_precision: 0.8667 - val_recall: 0.3047\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1921 - precision: 0.9405 - recall: 0.5782 - val_loss: 0.2274 - val_precision: 0.8283 - val_recall: 0.6406\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1620 - precision: 0.9432 - recall: 0.8185 - val_loss: 0.2361 - val_precision: 0.7870 - val_recall: 0.6641\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1427 - precision: 0.9451 - recall: 0.8933 - val_loss: 0.2282 - val_precision: 0.7760 - val_recall: 0.7578\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1343 - precision: 0.9315 - recall: 0.9112 - val_loss: 0.2375 - val_precision: 0.7881 - val_recall: 0.7266\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1257 - precision: 0.9477 - recall: 0.9309 - val_loss: 0.2397 - val_precision: 0.7826 - val_recall: 0.7031\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1194 - precision: 0.9453 - recall: 0.9379 - val_loss: 0.2447 - val_precision: 0.7500 - val_recall: 0.7031\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1144 - precision: 0.9571 - recall: 0.9439 - val_loss: 0.2472 - val_precision: 0.7385 - val_recall: 0.7500\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1140 - precision: 0.9515 - recall: 0.9524 - val_loss: 0.2501 - val_precision: 0.7863 - val_recall: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd9f50a5910>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp5 = Sequential()\n",
    "mlp5.add(Dense(32, input_dim=input_size, activation='relu', kernel_regularizer=regularization))\n",
    "mlp5.add(Dropout(0.5))\n",
    "mlp5.add(Dense(16, 'relu', kernel_regularizer=regularization))\n",
    "mlp5.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp5.summary()\n",
    "\n",
    "mlp5.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp5.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp5</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.732589</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.725034</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>2044</td>\n",
       "      <td>58</td>\n",
       "      <td>86</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  mlp5      0.94    0.732589  0.746479  0.725034  0.711409   0.785185  2044   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  58  86  212  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp5_pred = (mlp5.predict(Xcv_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp5_pred, 'mlp5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                230368    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 230,913\n",
      "Trainable params: 230,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.5068 - precision: 0.1158 - recall: 0.0567 - val_loss: 0.2749 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.2413 - precision: 0.5983 - recall: 0.1163 - val_loss: 0.2408 - val_precision: 0.8313 - val_recall: 0.5391\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1754 - precision: 0.9094 - recall: 0.7181 - val_loss: 0.2200 - val_precision: 0.8148 - val_recall: 0.6875\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1490 - precision: 0.9475 - recall: 0.8581 - val_loss: 0.2296 - val_precision: 0.7692 - val_recall: 0.7031\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1320 - precision: 0.9393 - recall: 0.8950 - val_loss: 0.2282 - val_precision: 0.7692 - val_recall: 0.7031\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1223 - precision: 0.9483 - recall: 0.9168 - val_loss: 0.2288 - val_precision: 0.7787 - val_recall: 0.7422\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1188 - precision: 0.9370 - recall: 0.9283 - val_loss: 0.2346 - val_precision: 0.7778 - val_recall: 0.7109\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1118 - precision: 0.9606 - recall: 0.9444 - val_loss: 0.2451 - val_precision: 0.7699 - val_recall: 0.6797\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1062 - precision: 0.9558 - recall: 0.9352 - val_loss: 0.2546 - val_precision: 0.7311 - val_recall: 0.6797\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1072 - precision: 0.9551 - recall: 0.9373 - val_loss: 0.2524 - val_precision: 0.7965 - val_recall: 0.7031\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1030 - precision: 0.9564 - recall: 0.9476 - val_loss: 0.2590 - val_precision: 0.7838 - val_recall: 0.6797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda23905a00>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "mlp5scaled = Sequential()\n",
    "mlp5scaled.add(Dense(32, input_dim=input_size, activation='relu', kernel_regularizer=regularization))\n",
    "mlp5scaled.add(Dropout(0.5))\n",
    "mlp5scaled.add(Dense(16, 'relu', kernel_regularizer=regularization))\n",
    "mlp5scaled.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "mlp5scaled.summary()\n",
    "\n",
    "mlp5scaled.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[Precision(), Recall()])\n",
    "\n",
    "mlp5scaled.fit(Xcv_train, y_train,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp5scaled</td>\n",
       "      <td>0.782083</td>\n",
       "      <td>0.621076</td>\n",
       "      <td>0.514392</td>\n",
       "      <td>0.702689</td>\n",
       "      <td>0.92953</td>\n",
       "      <td>0.355584</td>\n",
       "      <td>1600</td>\n",
       "      <td>502</td>\n",
       "      <td>21</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  F1.5-score  F1-score  F2-score   recall  precision  \\\n",
       "0  mlp5scaled  0.782083    0.621076  0.514392  0.702689  0.92953   0.355584   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1600  502  21  277  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp5scaled_pred = (mlp5scaled.predict(Xscaled_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, mlp5scaled_pred, 'mlp5scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 50)            1900      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                14010     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 15,921\n",
      "Trainable params: 15,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "864/864 [==============================] - 2s 1ms/step - loss: 0.3342 - precision: 0.2741 - recall: 0.0260 - val_loss: 0.2379 - val_precision: 0.6292 - val_recall: 0.4375\n",
      "Epoch 2/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.2208 - precision: 0.6960 - recall: 0.4763 - val_loss: 0.2179 - val_precision: 0.7361 - val_recall: 0.4141\n",
      "Epoch 3/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1842 - precision: 0.7548 - recall: 0.4968 - val_loss: 0.2113 - val_precision: 0.6466 - val_recall: 0.5859\n",
      "Epoch 4/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1923 - precision: 0.7286 - recall: 0.5344 - val_loss: 0.2111 - val_precision: 0.6947 - val_recall: 0.5156\n",
      "Epoch 5/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1811 - precision: 0.7596 - recall: 0.5606 - val_loss: 0.2161 - val_precision: 0.6979 - val_recall: 0.5234\n",
      "Epoch 6/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1762 - precision: 0.7977 - recall: 0.5854 - val_loss: 0.2196 - val_precision: 0.6260 - val_recall: 0.6016\n",
      "Epoch 7/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1689 - precision: 0.7743 - recall: 0.5923 - val_loss: 0.2133 - val_precision: 0.7391 - val_recall: 0.5312\n",
      "Epoch 8/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1647 - precision: 0.7994 - recall: 0.6142 - val_loss: 0.2146 - val_precision: 0.6818 - val_recall: 0.5859\n",
      "Epoch 9/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1625 - precision: 0.7832 - recall: 0.5906 - val_loss: 0.2197 - val_precision: 0.6697 - val_recall: 0.5703\n",
      "Epoch 10/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1555 - precision: 0.8232 - recall: 0.6456 - val_loss: 0.2177 - val_precision: 0.7821 - val_recall: 0.4766\n",
      "Epoch 11/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1528 - precision: 0.8136 - recall: 0.6316 - val_loss: 0.2198 - val_precision: 0.7245 - val_recall: 0.5547\n",
      "Epoch 12/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1585 - precision: 0.8129 - recall: 0.6350 - val_loss: 0.2248 - val_precision: 0.7527 - val_recall: 0.5469\n",
      "Epoch 13/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1397 - precision: 0.8275 - recall: 0.6644 - val_loss: 0.2258 - val_precision: 0.6796 - val_recall: 0.5469\n",
      "Epoch 14/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1373 - precision: 0.8599 - recall: 0.6807 - val_loss: 0.2277 - val_precision: 0.7000 - val_recall: 0.5469\n",
      "Epoch 15/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1280 - precision: 0.8592 - recall: 0.7137 - val_loss: 0.2336 - val_precision: 0.6827 - val_recall: 0.5547\n",
      "Epoch 16/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1195 - precision: 0.8906 - recall: 0.7139 - val_loss: 0.2248 - val_precision: 0.7396 - val_recall: 0.5547\n",
      "Epoch 17/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1268 - precision: 0.8787 - recall: 0.7202 - val_loss: 0.2442 - val_precision: 0.6893 - val_recall: 0.5547\n",
      "Epoch 18/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1180 - precision: 0.8579 - recall: 0.7171 - val_loss: 0.2399 - val_precision: 0.6489 - val_recall: 0.6641\n",
      "Epoch 19/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1070 - precision: 0.8973 - recall: 0.7643 - val_loss: 0.2447 - val_precision: 0.7019 - val_recall: 0.5703\n",
      "Epoch 20/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0957 - precision: 0.9147 - recall: 0.7732 - val_loss: 0.2487 - val_precision: 0.6638 - val_recall: 0.6016\n",
      "Epoch 21/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0981 - precision: 0.9045 - recall: 0.7860 - val_loss: 0.2409 - val_precision: 0.6789 - val_recall: 0.5781\n",
      "Epoch 22/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0985 - precision: 0.9128 - recall: 0.7662 - val_loss: 0.2465 - val_precision: 0.7273 - val_recall: 0.5625\n",
      "Epoch 23/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0884 - precision: 0.9060 - recall: 0.8232 - val_loss: 0.2474 - val_precision: 0.6838 - val_recall: 0.6250\n",
      "Epoch 24/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0819 - precision: 0.9179 - recall: 0.8310 - val_loss: 0.2512 - val_precision: 0.7273 - val_recall: 0.6250\n",
      "Epoch 25/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0767 - precision: 0.9166 - recall: 0.8272 - val_loss: 0.2496 - val_precision: 0.7120 - val_recall: 0.6953\n",
      "Epoch 26/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0726 - precision: 0.9236 - recall: 0.8474 - val_loss: 0.2589 - val_precision: 0.7156 - val_recall: 0.6094\n",
      "Epoch 27/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0713 - precision: 0.9148 - recall: 0.8482 - val_loss: 0.2660 - val_precision: 0.6810 - val_recall: 0.6172\n",
      "Epoch 28/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0740 - precision: 0.9355 - recall: 0.8495 - val_loss: 0.2611 - val_precision: 0.7009 - val_recall: 0.6406\n",
      "Epoch 29/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0624 - precision: 0.9325 - recall: 0.8657 - val_loss: 0.2883 - val_precision: 0.6975 - val_recall: 0.6484\n",
      "Epoch 30/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0612 - precision: 0.9392 - recall: 0.8712 - val_loss: 0.2859 - val_precision: 0.6870 - val_recall: 0.6172\n",
      "Epoch 31/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0654 - precision: 0.9197 - recall: 0.8429 - val_loss: 0.2899 - val_precision: 0.7119 - val_recall: 0.6562\n",
      "Epoch 32/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0572 - precision: 0.9295 - recall: 0.8738 - val_loss: 0.2892 - val_precision: 0.7155 - val_recall: 0.6484\n",
      "Epoch 33/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0536 - precision: 0.9492 - recall: 0.8742 - val_loss: 0.3128 - val_precision: 0.7320 - val_recall: 0.5547\n",
      "Epoch 34/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0515 - precision: 0.9545 - recall: 0.8958 - val_loss: 0.3259 - val_precision: 0.6842 - val_recall: 0.6094\n",
      "Epoch 35/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0504 - precision: 0.9430 - recall: 0.8951 - val_loss: 0.3311 - val_precision: 0.6538 - val_recall: 0.6641\n",
      "Epoch 36/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0441 - precision: 0.9708 - recall: 0.9223 - val_loss: 0.3263 - val_precision: 0.6783 - val_recall: 0.6094\n",
      "Epoch 37/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0533 - precision: 0.9506 - recall: 0.8987 - val_loss: 0.3364 - val_precision: 0.6696 - val_recall: 0.6016\n",
      "Epoch 38/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0419 - precision: 0.9721 - recall: 0.9238 - val_loss: 0.3608 - val_precision: 0.6881 - val_recall: 0.5859\n",
      "Epoch 39/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0371 - precision: 0.9558 - recall: 0.9319 - val_loss: 0.3607 - val_precision: 0.6639 - val_recall: 0.6172\n",
      "Epoch 40/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0369 - precision: 0.9651 - recall: 0.9384 - val_loss: 0.3841 - val_precision: 0.6364 - val_recall: 0.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0430 - precision: 0.9427 - recall: 0.9369 - val_loss: 0.4049 - val_precision: 0.6695 - val_recall: 0.6172\n",
      "Epoch 42/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0355 - precision: 0.9682 - recall: 0.9226 - val_loss: 0.4124 - val_precision: 0.6480 - val_recall: 0.6328\n",
      "Epoch 43/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0314 - precision: 0.9595 - recall: 0.9516 - val_loss: 0.3900 - val_precision: 0.6838 - val_recall: 0.6250\n",
      "Epoch 44/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0292 - precision: 0.9746 - recall: 0.9549 - val_loss: 0.4231 - val_precision: 0.6446 - val_recall: 0.6094\n",
      "Epoch 45/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.0293 - precision: 0.9587 - recall: 0.9574 - val_loss: 0.4330 - val_precision: 0.6525 - val_recall: 0.6016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda6ab3c130>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "emb0 = Sequential()\n",
    "\n",
    "emb0.add(Embedding(input_dim=vocab_size,\n",
    "                   output_dim=50,\n",
    "                   input_length=maxlen))\n",
    "emb0.add(Flatten())\n",
    "emb0.add(Dense(10, activation='relu'))\n",
    "emb0.add(Dense(1, activation='sigmoid'))\n",
    "emb0.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[Precision(), Recall()])\n",
    "\n",
    "emb0.summary()\n",
    "\n",
    "emb0.fit(Xtok_train, ytok_train,\n",
    "         epochs=50,\n",
    "         batch_size=10,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emb0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.655837</td>\n",
       "      <td>0.665505</td>\n",
       "      <td>0.650545</td>\n",
       "      <td>0.64094</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>2017</td>\n",
       "      <td>85</td>\n",
       "      <td>107</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score   recall  precision    tn  \\\n",
       "0  emb0      0.92    0.655837  0.665505  0.650545  0.64094   0.692029  2017   \n",
       "\n",
       "   fp   fn   tp  \n",
       "0  85  107  191  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb0_pred = (emb0.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, emb0_pred, 'emb0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 50)            1900      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,421\n",
      "Trainable params: 2,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "864/864 [==============================] - 2s 1ms/step - loss: 0.3931 - precision: 0.4979 - recall: 0.0374 - val_loss: 0.2461 - val_precision: 0.5783 - val_recall: 0.3750\n",
      "Epoch 2/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.2209 - precision: 0.7025 - recall: 0.4424 - val_loss: 0.2370 - val_precision: 0.7347 - val_recall: 0.2812\n",
      "Epoch 3/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1976 - precision: 0.7977 - recall: 0.4361 - val_loss: 0.2218 - val_precision: 0.6517 - val_recall: 0.4531\n",
      "Epoch 4/50\n",
      "864/864 [==============================] - 1s 997us/step - loss: 0.2025 - precision: 0.7646 - recall: 0.4703 - val_loss: 0.2184 - val_precision: 0.6585 - val_recall: 0.4219\n",
      "Epoch 5/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1921 - precision: 0.7539 - recall: 0.4682 - val_loss: 0.2182 - val_precision: 0.6625 - val_recall: 0.4141\n",
      "Epoch 6/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1901 - precision: 0.7689 - recall: 0.4960 - val_loss: 0.2206 - val_precision: 0.6224 - val_recall: 0.4766\n",
      "Epoch 7/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1860 - precision: 0.7496 - recall: 0.5051 - val_loss: 0.2174 - val_precision: 0.6857 - val_recall: 0.3750\n",
      "Epoch 8/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1887 - precision: 0.7818 - recall: 0.5287 - val_loss: 0.2180 - val_precision: 0.6667 - val_recall: 0.4219\n",
      "Epoch 9/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1890 - precision: 0.7594 - recall: 0.4791 - val_loss: 0.2196 - val_precision: 0.6667 - val_recall: 0.3594\n",
      "Epoch 10/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1850 - precision: 0.7690 - recall: 0.5027 - val_loss: 0.2232 - val_precision: 0.6447 - val_recall: 0.3828\n",
      "Epoch 11/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1761 - precision: 0.7998 - recall: 0.5489 - val_loss: 0.2174 - val_precision: 0.6591 - val_recall: 0.4531\n",
      "Epoch 12/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1846 - precision: 0.7979 - recall: 0.5503 - val_loss: 0.2193 - val_precision: 0.6706 - val_recall: 0.4453\n",
      "Epoch 13/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1724 - precision: 0.7827 - recall: 0.5541 - val_loss: 0.2171 - val_precision: 0.6790 - val_recall: 0.4297\n",
      "Epoch 14/50\n",
      "864/864 [==============================] - 1s 999us/step - loss: 0.1734 - precision: 0.7820 - recall: 0.5636 - val_loss: 0.2197 - val_precision: 0.6588 - val_recall: 0.4375\n",
      "Epoch 15/50\n",
      "864/864 [==============================] - 1s 991us/step - loss: 0.1771 - precision: 0.7898 - recall: 0.5698 - val_loss: 0.2194 - val_precision: 0.6354 - val_recall: 0.4766\n",
      "Epoch 16/50\n",
      "864/864 [==============================] - 1s 1000us/step - loss: 0.1698 - precision: 0.8049 - recall: 0.5834 - val_loss: 0.2204 - val_precision: 0.6842 - val_recall: 0.4062\n",
      "Epoch 17/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1790 - precision: 0.8153 - recall: 0.5832 - val_loss: 0.2234 - val_precision: 0.6829 - val_recall: 0.4375\n",
      "Epoch 18/50\n",
      "864/864 [==============================] - 1s 991us/step - loss: 0.1669 - precision: 0.7837 - recall: 0.5858 - val_loss: 0.2180 - val_precision: 0.6566 - val_recall: 0.5078\n",
      "Epoch 19/50\n",
      "864/864 [==============================] - 1s 998us/step - loss: 0.1679 - precision: 0.7832 - recall: 0.5756 - val_loss: 0.2338 - val_precision: 0.6933 - val_recall: 0.4062\n",
      "Epoch 20/50\n",
      "864/864 [==============================] - 1s 992us/step - loss: 0.1609 - precision: 0.8044 - recall: 0.5754 - val_loss: 0.2253 - val_precision: 0.6744 - val_recall: 0.4531\n",
      "Epoch 21/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1712 - precision: 0.8023 - recall: 0.6020 - val_loss: 0.2238 - val_precision: 0.6593 - val_recall: 0.4688\n",
      "Epoch 22/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1712 - precision: 0.8010 - recall: 0.5963 - val_loss: 0.2287 - val_precision: 0.6867 - val_recall: 0.4453\n",
      "Epoch 23/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1704 - precision: 0.7806 - recall: 0.5919 - val_loss: 0.2265 - val_precision: 0.6364 - val_recall: 0.4922\n",
      "Epoch 24/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1719 - precision: 0.7796 - recall: 0.5951 - val_loss: 0.2343 - val_precision: 0.6591 - val_recall: 0.4531\n",
      "Epoch 25/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1579 - precision: 0.8186 - recall: 0.6170 - val_loss: 0.2254 - val_precision: 0.6465 - val_recall: 0.5000\n",
      "Epoch 26/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1471 - precision: 0.8183 - recall: 0.6468 - val_loss: 0.2258 - val_precision: 0.6538 - val_recall: 0.5312\n",
      "Epoch 27/50\n",
      "864/864 [==============================] - 1s 993us/step - loss: 0.1527 - precision: 0.8222 - recall: 0.6699 - val_loss: 0.2286 - val_precision: 0.6571 - val_recall: 0.5391\n",
      "Epoch 28/50\n",
      "864/864 [==============================] - 1s 998us/step - loss: 0.1593 - precision: 0.8006 - recall: 0.6209 - val_loss: 0.2271 - val_precision: 0.6667 - val_recall: 0.5156\n",
      "Epoch 29/50\n",
      "864/864 [==============================] - 1s 999us/step - loss: 0.1543 - precision: 0.7921 - recall: 0.6283 - val_loss: 0.2321 - val_precision: 0.6667 - val_recall: 0.5000\n",
      "Epoch 30/50\n",
      "864/864 [==============================] - 1s 999us/step - loss: 0.1539 - precision: 0.8335 - recall: 0.6369 - val_loss: 0.2313 - val_precision: 0.6829 - val_recall: 0.4375\n",
      "Epoch 31/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1680 - precision: 0.7930 - recall: 0.5803 - val_loss: 0.2356 - val_precision: 0.6667 - val_recall: 0.4844\n",
      "Epoch 32/50\n",
      "864/864 [==============================] - 1s 998us/step - loss: 0.1570 - precision: 0.7961 - recall: 0.6057 - val_loss: 0.2322 - val_precision: 0.6556 - val_recall: 0.4609\n",
      "Epoch 33/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1599 - precision: 0.8103 - recall: 0.6012 - val_loss: 0.2387 - val_precision: 0.6667 - val_recall: 0.4844\n",
      "Epoch 34/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1553 - precision: 0.8326 - recall: 0.6232 - val_loss: 0.2375 - val_precision: 0.6630 - val_recall: 0.4766\n",
      "Epoch 35/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1502 - precision: 0.8206 - recall: 0.6340 - val_loss: 0.2330 - val_precision: 0.6765 - val_recall: 0.5391\n",
      "Epoch 36/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1504 - precision: 0.8215 - recall: 0.6398 - val_loss: 0.2382 - val_precision: 0.6667 - val_recall: 0.4688\n",
      "Epoch 37/50\n",
      "864/864 [==============================] - 1s 993us/step - loss: 0.1582 - precision: 0.8213 - recall: 0.6156 - val_loss: 0.2399 - val_precision: 0.6429 - val_recall: 0.5625\n",
      "Epoch 38/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1522 - precision: 0.8097 - recall: 0.6581 - val_loss: 0.2353 - val_precision: 0.6703 - val_recall: 0.4766\n",
      "Epoch 39/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1506 - precision: 0.8005 - recall: 0.6203 - val_loss: 0.2504 - val_precision: 0.6231 - val_recall: 0.6328\n",
      "Epoch 40/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1528 - precision: 0.8237 - recall: 0.6472 - val_loss: 0.2366 - val_precision: 0.6566 - val_recall: 0.5078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1537 - precision: 0.8059 - recall: 0.6299 - val_loss: 0.2381 - val_precision: 0.6636 - val_recall: 0.5547\n",
      "Epoch 42/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1418 - precision: 0.8218 - recall: 0.6303 - val_loss: 0.2402 - val_precision: 0.6364 - val_recall: 0.4922\n",
      "Epoch 43/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1454 - precision: 0.8178 - recall: 0.6323 - val_loss: 0.2350 - val_precision: 0.6526 - val_recall: 0.4844\n",
      "Epoch 44/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1410 - precision: 0.8509 - recall: 0.6703 - val_loss: 0.2395 - val_precision: 0.6854 - val_recall: 0.4766\n",
      "Epoch 45/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1368 - precision: 0.8408 - recall: 0.6588 - val_loss: 0.2403 - val_precision: 0.6636 - val_recall: 0.5703\n",
      "Epoch 46/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1470 - precision: 0.8237 - recall: 0.6566 - val_loss: 0.2465 - val_precision: 0.6633 - val_recall: 0.5078\n",
      "Epoch 47/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1548 - precision: 0.8428 - recall: 0.6412 - val_loss: 0.2444 - val_precision: 0.6635 - val_recall: 0.5391\n",
      "Epoch 48/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1458 - precision: 0.8133 - recall: 0.6410 - val_loss: 0.2424 - val_precision: 0.6571 - val_recall: 0.5391\n",
      "Epoch 49/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1387 - precision: 0.8393 - recall: 0.6534 - val_loss: 0.2509 - val_precision: 0.6629 - val_recall: 0.4609\n",
      "Epoch 50/50\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 0.1398 - precision: 0.8228 - recall: 0.6653 - val_loss: 0.2461 - val_precision: 0.6466 - val_recall: 0.5859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda6db54070>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "emb1 = Sequential()\n",
    "\n",
    "emb1.add(Embedding(input_dim=vocab_size,\n",
    "                   output_dim=50,\n",
    "                   input_length=maxlen))\n",
    "emb1.add(GlobalMaxPool1D())\n",
    "emb1.add(Dense(10, activation='relu'))\n",
    "emb1.add(Dense(1, activation='sigmoid'))\n",
    "emb1.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[Precision(), Recall()])\n",
    "\n",
    "emb1.summary()\n",
    "\n",
    "emb1.fit(Xtok_train, ytok_train,\n",
    "         epochs=50,\n",
    "         batch_size=10,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emb1</td>\n",
       "      <td>0.91125</td>\n",
       "      <td>0.601399</td>\n",
       "      <td>0.617594</td>\n",
       "      <td>0.592695</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.664093</td>\n",
       "      <td>2015</td>\n",
       "      <td>87</td>\n",
       "      <td>126</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  emb1   0.91125    0.601399  0.617594  0.592695  0.577181   0.664093  2015   \n",
       "\n",
       "   fp   fn   tp  \n",
       "0  87  126  172  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1_pred = (emb1.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, emb1_pred, 'emb1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 24, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 69,229\n",
      "Trainable params: 69,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "864/864 [==============================] - 3s 2ms/step - loss: 0.3135 - precision: 0.5309 - recall: 0.2259 - val_loss: 0.1927 - val_precision: 0.7614 - val_recall: 0.5234\n",
      "Epoch 2/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.1691 - precision: 0.7898 - recall: 0.6169 - val_loss: 0.1670 - val_precision: 0.8824 - val_recall: 0.5859\n",
      "Epoch 3/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.1276 - precision: 0.8448 - recall: 0.6800 - val_loss: 0.1528 - val_precision: 0.7909 - val_recall: 0.6797\n",
      "Epoch 4/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.1068 - precision: 0.8713 - recall: 0.7747 - val_loss: 0.1653 - val_precision: 0.7857 - val_recall: 0.6875\n",
      "Epoch 5/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0864 - precision: 0.8926 - recall: 0.8228 - val_loss: 0.1646 - val_precision: 0.7260 - val_recall: 0.8281\n",
      "Epoch 6/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0657 - precision: 0.9285 - recall: 0.8666 - val_loss: 0.1546 - val_precision: 0.7744 - val_recall: 0.8047\n",
      "Epoch 7/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0536 - precision: 0.9315 - recall: 0.8941 - val_loss: 0.1698 - val_precision: 0.7481 - val_recall: 0.7891\n",
      "Epoch 8/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0493 - precision: 0.9322 - recall: 0.9350 - val_loss: 0.1578 - val_precision: 0.8189 - val_recall: 0.8125\n",
      "Epoch 9/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0280 - precision: 0.9681 - recall: 0.9610 - val_loss: 0.1943 - val_precision: 0.8264 - val_recall: 0.7812\n",
      "Epoch 10/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0347 - precision: 0.9580 - recall: 0.9420 - val_loss: 0.2146 - val_precision: 0.7727 - val_recall: 0.7969\n",
      "Epoch 11/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0278 - precision: 0.9689 - recall: 0.9562 - val_loss: 0.2395 - val_precision: 0.8211 - val_recall: 0.7891\n",
      "Epoch 12/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0195 - precision: 0.9766 - recall: 0.9687 - val_loss: 0.2472 - val_precision: 0.7863 - val_recall: 0.8047\n",
      "Epoch 13/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0208 - precision: 0.9757 - recall: 0.9713 - val_loss: 0.2706 - val_precision: 0.7347 - val_recall: 0.8438\n",
      "Epoch 14/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0265 - precision: 0.9651 - recall: 0.9573 - val_loss: 0.2298 - val_precision: 0.7786 - val_recall: 0.7969\n",
      "Epoch 15/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0155 - precision: 0.9864 - recall: 0.9833 - val_loss: 0.2728 - val_precision: 0.8151 - val_recall: 0.7578\n",
      "Epoch 16/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0139 - precision: 0.9872 - recall: 0.9788 - val_loss: 0.3168 - val_precision: 0.8017 - val_recall: 0.7578\n",
      "Epoch 17/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0133 - precision: 0.9813 - recall: 0.9828 - val_loss: 0.3826 - val_precision: 0.8447 - val_recall: 0.6797\n",
      "Epoch 18/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0248 - precision: 0.9676 - recall: 0.9552 - val_loss: 0.2708 - val_precision: 0.8000 - val_recall: 0.8438\n",
      "Epoch 19/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0085 - precision: 0.9857 - recall: 0.9864 - val_loss: 0.3409 - val_precision: 0.8333 - val_recall: 0.7031\n",
      "Epoch 20/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0135 - precision: 0.9852 - recall: 0.9779 - val_loss: 0.3376 - val_precision: 0.7742 - val_recall: 0.7500\n",
      "Epoch 21/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0123 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.3265 - val_precision: 0.8095 - val_recall: 0.7969\n",
      "Epoch 22/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0054 - precision: 0.9950 - recall: 0.9929 - val_loss: 0.3923 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 23/50\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0204 - precision: 0.9699 - recall: 0.9725 - val_loss: 0.3857 - val_precision: 0.8421 - val_recall: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9b225580>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "emb2 = Sequential()\n",
    "\n",
    "emb2.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "emb2.add(Conv1D(128, 5, activation='relu'))\n",
    "emb2.add(GlobalMaxPool1D())\n",
    "emb2.add(Dense(10, activation='relu'))\n",
    "emb2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "emb2.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[Precision(), Recall()])\n",
    "\n",
    "emb2.summary()\n",
    "\n",
    "emb2.fit(Xtok_train, ytok_train,\n",
    "         epochs=50,\n",
    "         batch_size=10,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emb2</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>0.77358</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.785528</td>\n",
       "      <td>0.808725</td>\n",
       "      <td>0.704678</td>\n",
       "      <td>2001</td>\n",
       "      <td>101</td>\n",
       "      <td>57</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  emb2  0.934167     0.77358  0.753125  0.785528  0.808725   0.704678  2001   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  101  57  241  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb2_pred = (emb2.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, emb2_pred, 'emb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 24, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 69,229\n",
      "Trainable params: 69,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "864/864 [==============================] - 3s 2ms/step - loss: 0.3162 - precision: 0.5716 - recall: 0.2584 - val_loss: 0.1742 - val_precision: 0.7411 - val_recall: 0.6484\n",
      "Epoch 2/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.1600 - precision: 0.8094 - recall: 0.6250 - val_loss: 0.1622 - val_precision: 0.8902 - val_recall: 0.5703\n",
      "Epoch 3/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.1243 - precision: 0.8539 - recall: 0.6993 - val_loss: 0.1351 - val_precision: 0.8070 - val_recall: 0.7188\n",
      "Epoch 4/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.1048 - precision: 0.8852 - recall: 0.7792 - val_loss: 0.1496 - val_precision: 0.8641 - val_recall: 0.6953\n",
      "Epoch 5/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0826 - precision: 0.9092 - recall: 0.8378 - val_loss: 0.1530 - val_precision: 0.7518 - val_recall: 0.8047\n",
      "Epoch 6/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0626 - precision: 0.9376 - recall: 0.8722 - val_loss: 0.1560 - val_precision: 0.8083 - val_recall: 0.7578\n",
      "Epoch 7/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0529 - precision: 0.9444 - recall: 0.8944 - val_loss: 0.1575 - val_precision: 0.7500 - val_recall: 0.8203\n",
      "Epoch 8/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0535 - precision: 0.9333 - recall: 0.9120 - val_loss: 0.1613 - val_precision: 0.8403 - val_recall: 0.7812\n",
      "Epoch 9/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0341 - precision: 0.9516 - recall: 0.9353 - val_loss: 0.1790 - val_precision: 0.7656 - val_recall: 0.7656\n",
      "Epoch 10/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0325 - precision: 0.9574 - recall: 0.9432 - val_loss: 0.1908 - val_precision: 0.8182 - val_recall: 0.7734\n",
      "Epoch 11/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0274 - precision: 0.9633 - recall: 0.9564 - val_loss: 0.2265 - val_precision: 0.8544 - val_recall: 0.6875\n",
      "Epoch 12/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0246 - precision: 0.9691 - recall: 0.9609 - val_loss: 0.2412 - val_precision: 0.7812 - val_recall: 0.7812\n",
      "Epoch 13/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0209 - precision: 0.9681 - recall: 0.9684 - val_loss: 0.2518 - val_precision: 0.7500 - val_recall: 0.8203\n",
      "Epoch 14/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0265 - precision: 0.9675 - recall: 0.9683 - val_loss: 0.2478 - val_precision: 0.7903 - val_recall: 0.7656\n",
      "Epoch 15/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0119 - precision: 0.9916 - recall: 0.9869 - val_loss: 0.2961 - val_precision: 0.6968 - val_recall: 0.8438\n",
      "Epoch 16/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0270 - precision: 0.9662 - recall: 0.9636 - val_loss: 0.2968 - val_precision: 0.8148 - val_recall: 0.6875\n",
      "Epoch 17/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0194 - precision: 0.9849 - recall: 0.9735 - val_loss: 0.2952 - val_precision: 0.7752 - val_recall: 0.7812\n",
      "Epoch 18/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0106 - precision: 0.9820 - recall: 0.9785 - val_loss: 0.2841 - val_precision: 0.8142 - val_recall: 0.7188\n",
      "Epoch 19/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0178 - precision: 0.9770 - recall: 0.9816 - val_loss: 0.3396 - val_precision: 0.8485 - val_recall: 0.6562\n",
      "Epoch 20/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0090 - precision: 0.9944 - recall: 0.9832 - val_loss: 0.3326 - val_precision: 0.8614 - val_recall: 0.6797\n",
      "Epoch 21/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0214 - precision: 0.9717 - recall: 0.9716 - val_loss: 0.3618 - val_precision: 0.8750 - val_recall: 0.6562\n",
      "Epoch 22/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0127 - precision: 0.9835 - recall: 0.9712 - val_loss: 0.3602 - val_precision: 0.8198 - val_recall: 0.7109\n",
      "Epoch 23/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0065 - precision: 0.9953 - recall: 0.9906 - val_loss: 0.3751 - val_precision: 0.7260 - val_recall: 0.8281\n",
      "Epoch 24/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0155 - precision: 0.9815 - recall: 0.9834 - val_loss: 0.3855 - val_precision: 0.7647 - val_recall: 0.7109\n",
      "Epoch 25/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0152 - precision: 0.9817 - recall: 0.9810 - val_loss: 0.3511 - val_precision: 0.7578 - val_recall: 0.7578\n",
      "Epoch 26/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0088 - precision: 0.9882 - recall: 0.9850 - val_loss: 0.3454 - val_precision: 0.8125 - val_recall: 0.7109\n",
      "Epoch 27/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0098 - precision: 0.9909 - recall: 0.9784 - val_loss: 0.3915 - val_precision: 0.7200 - val_recall: 0.7031\n",
      "Epoch 28/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0099 - precision: 0.9887 - recall: 0.9828 - val_loss: 0.3753 - val_precision: 0.7606 - val_recall: 0.8438\n",
      "Epoch 29/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0052 - precision: 0.9922 - recall: 0.9932 - val_loss: 0.4533 - val_precision: 0.7059 - val_recall: 0.7500\n",
      "Epoch 30/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0103 - precision: 0.9895 - recall: 0.9792 - val_loss: 0.3802 - val_precision: 0.7597 - val_recall: 0.7656\n",
      "Epoch 31/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0180 - precision: 0.9815 - recall: 0.9725 - val_loss: 0.3937 - val_precision: 0.7597 - val_recall: 0.7656\n",
      "Epoch 32/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0112 - precision: 0.9871 - recall: 0.9846 - val_loss: 0.3792 - val_precision: 0.8229 - val_recall: 0.6172\n",
      "Epoch 33/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0091 - precision: 0.9951 - recall: 0.9888 - val_loss: 0.3678 - val_precision: 0.7967 - val_recall: 0.7656\n",
      "Epoch 34/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0108 - precision: 0.9890 - recall: 0.9830 - val_loss: 0.3704 - val_precision: 0.7086 - val_recall: 0.8359\n",
      "Epoch 35/100\n",
      "864/864 [==============================] - 2s 2ms/step - loss: 0.0082 - precision: 0.9840 - recall: 0.9875 - val_loss: 0.4557 - val_precision: 0.9070 - val_recall: 0.6094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda516065b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "emb3 = Sequential()\n",
    "\n",
    "emb3.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "emb3.add(Conv1D(128, 5, activation='relu'))\n",
    "emb3.add(GlobalMaxPool1D())\n",
    "emb3.add(Dense(10, activation='relu'))\n",
    "emb3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "emb3.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[Precision(), Recall()])\n",
    "\n",
    "emb3.summary()\n",
    "\n",
    "emb3.fit(Xtok_train, ytok_train,\n",
    "         epochs=100,\n",
    "         batch_size=10,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emb3</td>\n",
       "      <td>0.92625</td>\n",
       "      <td>0.757649</td>\n",
       "      <td>0.730594</td>\n",
       "      <td>0.773694</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>1983</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  emb3   0.92625    0.757649  0.730594  0.773694  0.805369   0.668524  1983   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  119  58  240  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb3_pred = (emb3.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, emb3_pred, 'emb3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                4256      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,089\n",
      "Trainable params: 8,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 3s 7ms/step - loss: 0.3406 - precision: 0.5523 - recall: 0.0994 - val_loss: 0.2373 - val_precision: 0.5800 - val_recall: 0.4531\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.2217 - precision: 0.6750 - recall: 0.4916 - val_loss: 0.2177 - val_precision: 0.8000 - val_recall: 0.4062\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1865 - precision: 0.7713 - recall: 0.4833 - val_loss: 0.2107 - val_precision: 0.6961 - val_recall: 0.5547\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1943 - precision: 0.7699 - recall: 0.5112 - val_loss: 0.2130 - val_precision: 0.6288 - val_recall: 0.6484\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1766 - precision: 0.8000 - recall: 0.5794 - val_loss: 0.1987 - val_precision: 0.7228 - val_recall: 0.5703\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1753 - precision: 0.8094 - recall: 0.5814 - val_loss: 0.1931 - val_precision: 0.7196 - val_recall: 0.6016\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1657 - precision: 0.8030 - recall: 0.5672 - val_loss: 0.1858 - val_precision: 0.7500 - val_recall: 0.5625\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1624 - precision: 0.8134 - recall: 0.6192 - val_loss: 0.1811 - val_precision: 0.7500 - val_recall: 0.6328\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1568 - precision: 0.7979 - recall: 0.6239 - val_loss: 0.1879 - val_precision: 0.7411 - val_recall: 0.6484\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1513 - precision: 0.7948 - recall: 0.6399 - val_loss: 0.2013 - val_precision: 0.8286 - val_recall: 0.4531\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1402 - precision: 0.8416 - recall: 0.6411 - val_loss: 0.1881 - val_precision: 0.6908 - val_recall: 0.8203\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1403 - precision: 0.8075 - recall: 0.7026 - val_loss: 0.1831 - val_precision: 0.8409 - val_recall: 0.5781\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1285 - precision: 0.8351 - recall: 0.6901 - val_loss: 0.1734 - val_precision: 0.7480 - val_recall: 0.7422\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1274 - precision: 0.8496 - recall: 0.7268 - val_loss: 0.1704 - val_precision: 0.7798 - val_recall: 0.6641\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1232 - precision: 0.8515 - recall: 0.7472 - val_loss: 0.1672 - val_precision: 0.7500 - val_recall: 0.6797\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1119 - precision: 0.8675 - recall: 0.7728 - val_loss: 0.1705 - val_precision: 0.7981 - val_recall: 0.6484\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1194 - precision: 0.8845 - recall: 0.7690 - val_loss: 0.1811 - val_precision: 0.8021 - val_recall: 0.6016\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1076 - precision: 0.8739 - recall: 0.7606 - val_loss: 0.1690 - val_precision: 0.7615 - val_recall: 0.7734\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1045 - precision: 0.8701 - recall: 0.8082 - val_loss: 0.1940 - val_precision: 0.8152 - val_recall: 0.5859\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0952 - precision: 0.8739 - recall: 0.7826 - val_loss: 0.1864 - val_precision: 0.7500 - val_recall: 0.7031\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0980 - precision: 0.8843 - recall: 0.7993 - val_loss: 0.1730 - val_precision: 0.8218 - val_recall: 0.6484\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0930 - precision: 0.8975 - recall: 0.8143 - val_loss: 0.2055 - val_precision: 0.8621 - val_recall: 0.5859\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0999 - precision: 0.8784 - recall: 0.8007 - val_loss: 0.1776 - val_precision: 0.7857 - val_recall: 0.6875\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0878 - precision: 0.8895 - recall: 0.8123 - val_loss: 0.1808 - val_precision: 0.7797 - val_recall: 0.7188\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0787 - precision: 0.9096 - recall: 0.8494 - val_loss: 0.1714 - val_precision: 0.7634 - val_recall: 0.7812\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0746 - precision: 0.9041 - recall: 0.8471 - val_loss: 0.1776 - val_precision: 0.7812 - val_recall: 0.7812\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0750 - precision: 0.9148 - recall: 0.8655 - val_loss: 0.1710 - val_precision: 0.7742 - val_recall: 0.7500\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0742 - precision: 0.9316 - recall: 0.8571 - val_loss: 0.1847 - val_precision: 0.7481 - val_recall: 0.7891\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0691 - precision: 0.9255 - recall: 0.8642 - val_loss: 0.1932 - val_precision: 0.8018 - val_recall: 0.6953\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0676 - precision: 0.9366 - recall: 0.8679 - val_loss: 0.1901 - val_precision: 0.8095 - val_recall: 0.6641\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0770 - precision: 0.9152 - recall: 0.8507 - val_loss: 0.1914 - val_precision: 0.8174 - val_recall: 0.7344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda5501d910>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "smpl0 = Sequential()\n",
    "\n",
    "smpl0.add(Embedding(input_dim=vocab_size,\n",
    "                         output_dim=100,\n",
    "                         input_length=maxlen))\n",
    "smpl0.add(SimpleRNN(32, activation=\"tanh\"))\n",
    "smpl0.add(Dense(1, \"sigmoid\")) \n",
    "\n",
    "smpl0.summary()\n",
    "\n",
    "smpl0.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=\"adam\",\n",
    "                   metrics=[Precision(), Recall()])\n",
    "\n",
    "smpl0.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smpl0</td>\n",
       "      <td>0.927917</td>\n",
       "      <td>0.743411</td>\n",
       "      <td>0.726698</td>\n",
       "      <td>0.753111</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>1997</td>\n",
       "      <td>105</td>\n",
       "      <td>68</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  smpl0  0.927917    0.743411  0.726698  0.753111  0.771812   0.686567  1997   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  105  68  230  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl0_pred = (smpl0.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, smpl0_pred, 'smpl0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 64)                10560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,425\n",
      "Trainable params: 14,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 3s 7ms/step - loss: 0.3347 - precision: 0.4295 - recall: 0.1153 - val_loss: 0.2315 - val_precision: 0.5977 - val_recall: 0.4062\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.2174 - precision: 0.7043 - recall: 0.4758 - val_loss: 0.2156 - val_precision: 0.7910 - val_recall: 0.4141\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1889 - precision: 0.7708 - recall: 0.4747 - val_loss: 0.2126 - val_precision: 0.6667 - val_recall: 0.5469\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1986 - precision: 0.7402 - recall: 0.5226 - val_loss: 0.2138 - val_precision: 0.6606 - val_recall: 0.5625\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.1855 - precision: 0.7605 - recall: 0.5252 - val_loss: 0.2068 - val_precision: 0.7113 - val_recall: 0.5391\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1848 - precision: 0.7883 - recall: 0.5385 - val_loss: 0.2074 - val_precision: 0.6818 - val_recall: 0.5859\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1791 - precision: 0.7900 - recall: 0.5269 - val_loss: 0.2061 - val_precision: 0.7848 - val_recall: 0.4844\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1771 - precision: 0.7943 - recall: 0.6142 - val_loss: 0.1956 - val_precision: 0.7009 - val_recall: 0.5859\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1720 - precision: 0.7662 - recall: 0.5555 - val_loss: 0.2073 - val_precision: 0.7212 - val_recall: 0.5859\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1606 - precision: 0.8034 - recall: 0.6113 - val_loss: 0.2191 - val_precision: 0.9091 - val_recall: 0.3906\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1571 - precision: 0.8261 - recall: 0.5766 - val_loss: 0.1865 - val_precision: 0.7193 - val_recall: 0.6406\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1530 - precision: 0.8339 - recall: 0.6454 - val_loss: 0.1904 - val_precision: 0.7207 - val_recall: 0.6250\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1395 - precision: 0.8194 - recall: 0.6544 - val_loss: 0.1788 - val_precision: 0.8020 - val_recall: 0.6328\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1342 - precision: 0.8532 - recall: 0.7136 - val_loss: 0.2470 - val_precision: 0.8723 - val_recall: 0.3203\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1619 - precision: 0.8260 - recall: 0.6247 - val_loss: 0.1732 - val_precision: 0.7523 - val_recall: 0.6406\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1176 - precision: 0.8904 - recall: 0.7308 - val_loss: 0.1708 - val_precision: 0.7565 - val_recall: 0.6797\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1221 - precision: 0.8754 - recall: 0.7502 - val_loss: 0.1918 - val_precision: 0.8171 - val_recall: 0.5234\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1073 - precision: 0.8821 - recall: 0.7485 - val_loss: 0.1825 - val_precision: 0.7222 - val_recall: 0.7109\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1016 - precision: 0.8664 - recall: 0.7795 - val_loss: 0.2098 - val_precision: 0.8592 - val_recall: 0.4766\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0909 - precision: 0.8962 - recall: 0.7744 - val_loss: 0.2017 - val_precision: 0.8043 - val_recall: 0.5781\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0906 - precision: 0.8926 - recall: 0.8041 - val_loss: 0.1897 - val_precision: 0.8000 - val_recall: 0.5938\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0833 - precision: 0.9155 - recall: 0.8389 - val_loss: 0.2255 - val_precision: 0.8462 - val_recall: 0.5156\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0834 - precision: 0.9100 - recall: 0.8334 - val_loss: 0.2013 - val_precision: 0.7323 - val_recall: 0.7266\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0784 - precision: 0.8936 - recall: 0.8361 - val_loss: 0.2119 - val_precision: 0.7925 - val_recall: 0.6562\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0697 - precision: 0.9237 - recall: 0.8609 - val_loss: 0.2109 - val_precision: 0.6970 - val_recall: 0.7188\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0601 - precision: 0.9303 - recall: 0.8919 - val_loss: 0.2154 - val_precision: 0.6957 - val_recall: 0.7500\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0582 - precision: 0.9382 - recall: 0.8888 - val_loss: 0.2362 - val_precision: 0.7624 - val_recall: 0.6016\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0594 - precision: 0.9371 - recall: 0.8873 - val_loss: 0.2160 - val_precision: 0.7131 - val_recall: 0.6797\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0486 - precision: 0.9626 - recall: 0.9039 - val_loss: 0.2424 - val_precision: 0.7339 - val_recall: 0.6250\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0439 - precision: 0.9569 - recall: 0.9179 - val_loss: 0.2413 - val_precision: 0.7304 - val_recall: 0.6562\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0514 - precision: 0.9451 - recall: 0.9038 - val_loss: 0.2496 - val_precision: 0.6692 - val_recall: 0.6797\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0435 - precision: 0.9503 - recall: 0.9210 - val_loss: 0.2409 - val_precision: 0.7544 - val_recall: 0.6719\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0418 - precision: 0.9583 - recall: 0.9224 - val_loss: 0.2597 - val_precision: 0.7732 - val_recall: 0.5859\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0326 - precision: 0.9698 - recall: 0.9492 - val_loss: 0.2477 - val_precision: 0.7434 - val_recall: 0.6562\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0275 - precision: 0.9825 - recall: 0.9638 - val_loss: 0.2679 - val_precision: 0.7419 - val_recall: 0.7188\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0257 - precision: 0.9734 - recall: 0.9584 - val_loss: 0.2889 - val_precision: 0.7212 - val_recall: 0.5859\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0334 - precision: 0.9762 - recall: 0.9520 - val_loss: 0.2956 - val_precision: 0.7453 - val_recall: 0.6172\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0226 - precision: 0.9877 - recall: 0.9656 - val_loss: 0.2961 - val_precision: 0.7658 - val_recall: 0.6641\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0168 - precision: 0.9894 - recall: 0.9785 - val_loss: 0.2856 - val_precision: 0.7087 - val_recall: 0.7031\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0276 - precision: 0.9778 - recall: 0.9592 - val_loss: 0.3263 - val_precision: 0.6640 - val_recall: 0.6484\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0284 - precision: 0.9707 - recall: 0.9610 - val_loss: 0.3196 - val_precision: 0.6544 - val_recall: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0204 - precision: 0.9805 - recall: 0.9798 - val_loss: 0.3157 - val_precision: 0.7154 - val_recall: 0.6875\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0214 - precision: 0.9790 - recall: 0.9746 - val_loss: 0.3148 - val_precision: 0.7568 - val_recall: 0.6562\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0138 - precision: 0.9931 - recall: 0.9887 - val_loss: 0.3229 - val_precision: 0.7241 - val_recall: 0.6562\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0099 - precision: 0.9957 - recall: 0.9934 - val_loss: 0.3462 - val_precision: 0.6880 - val_recall: 0.6719\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0077 - precision: 0.9984 - recall: 0.9976 - val_loss: 0.3545 - val_precision: 0.7522 - val_recall: 0.6641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda56479610>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "smpl1 = Sequential()\n",
    "\n",
    "smpl1.add(Embedding(input_dim=vocab_size,\n",
    "                         output_dim=100,\n",
    "                         input_length=maxlen))\n",
    "smpl1.add(SimpleRNN(64, activation=\"tanh\"))\n",
    "smpl1.add(Dense(1, \"sigmoid\")) \n",
    "\n",
    "smpl1.summary()\n",
    "\n",
    "smpl1.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=\"adam\",\n",
    "                   metrics=[Precision(), Recall()])\n",
    "\n",
    "smpl1.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smpl1</td>\n",
       "      <td>0.925417</td>\n",
       "      <td>0.728364</td>\n",
       "      <td>0.714514</td>\n",
       "      <td>0.736358</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>1997</td>\n",
       "      <td>105</td>\n",
       "      <td>74</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  smpl1  0.925417    0.728364  0.714514  0.736358  0.751678   0.680851  1997   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  105  74  224  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl1_pred = (smpl1.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, smpl1_pred, 'smpl1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 28, 32)            17024     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 23,977\n",
      "Trainable params: 23,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 7s 17ms/step - loss: 0.4102 - precision: 0.2711 - recall: 0.0421 - val_loss: 0.2563 - val_precision: 0.5854 - val_recall: 0.3750\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.2418 - precision: 0.6192 - recall: 0.4151 - val_loss: 0.2559 - val_precision: 0.7442 - val_recall: 0.2500\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.2145 - precision: 0.6781 - recall: 0.4175 - val_loss: 0.2285 - val_precision: 0.6095 - val_recall: 0.5000\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.2094 - precision: 0.7237 - recall: 0.5101 - val_loss: 0.2187 - val_precision: 0.6383 - val_recall: 0.4688\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.1921 - precision: 0.7840 - recall: 0.5200 - val_loss: 0.2166 - val_precision: 0.6768 - val_recall: 0.5234\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.1824 - precision: 0.7801 - recall: 0.5614 - val_loss: 0.2176 - val_precision: 0.6379 - val_recall: 0.5781\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1756 - precision: 0.7932 - recall: 0.5452 - val_loss: 0.2119 - val_precision: 0.7875 - val_recall: 0.4922\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1774 - precision: 0.8285 - recall: 0.5869 - val_loss: 0.2079 - val_precision: 0.7582 - val_recall: 0.5391\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1720 - precision: 0.7904 - recall: 0.5386 - val_loss: 0.2167 - val_precision: 0.7019 - val_recall: 0.5703\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1693 - precision: 0.7983 - recall: 0.6033 - val_loss: 0.2119 - val_precision: 0.7667 - val_recall: 0.5391\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1525 - precision: 0.8331 - recall: 0.6008 - val_loss: 0.1998 - val_precision: 0.7789 - val_recall: 0.5781\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1598 - precision: 0.8418 - recall: 0.6313 - val_loss: 0.2019 - val_precision: 0.7327 - val_recall: 0.5781\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1449 - precision: 0.8273 - recall: 0.6558 - val_loss: 0.1986 - val_precision: 0.8471 - val_recall: 0.5625\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1449 - precision: 0.8427 - recall: 0.6477 - val_loss: 0.2028 - val_precision: 0.7955 - val_recall: 0.5469\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1397 - precision: 0.8220 - recall: 0.6924 - val_loss: 0.2045 - val_precision: 0.7778 - val_recall: 0.6016\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1251 - precision: 0.8516 - recall: 0.7211 - val_loss: 0.1951 - val_precision: 0.7864 - val_recall: 0.6328\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1338 - precision: 0.8528 - recall: 0.7126 - val_loss: 0.1956 - val_precision: 0.7917 - val_recall: 0.5938\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1237 - precision: 0.8477 - recall: 0.7038 - val_loss: 0.2083 - val_precision: 0.7109 - val_recall: 0.7109\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1187 - precision: 0.8601 - recall: 0.7444 - val_loss: 0.2057 - val_precision: 0.7895 - val_recall: 0.5859\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1075 - precision: 0.8681 - recall: 0.7586 - val_loss: 0.1933 - val_precision: 0.8119 - val_recall: 0.6406\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 3s 13ms/step - loss: 0.1075 - precision: 0.8588 - recall: 0.7835 - val_loss: 0.1924 - val_precision: 0.7544 - val_recall: 0.6719\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.1051 - precision: 0.8844 - recall: 0.7939 - val_loss: 0.2001 - val_precision: 0.7925 - val_recall: 0.6562\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0977 - precision: 0.8662 - recall: 0.7935 - val_loss: 0.2047 - val_precision: 0.7377 - val_recall: 0.7031\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0902 - precision: 0.8818 - recall: 0.8288 - val_loss: 0.2055 - val_precision: 0.8077 - val_recall: 0.6562\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0814 - precision: 0.9083 - recall: 0.8478 - val_loss: 0.2171 - val_precision: 0.6738 - val_recall: 0.7422\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0783 - precision: 0.8962 - recall: 0.8421 - val_loss: 0.2164 - val_precision: 0.7778 - val_recall: 0.6562\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0760 - precision: 0.9174 - recall: 0.8442 - val_loss: 0.2111 - val_precision: 0.7377 - val_recall: 0.7031\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0722 - precision: 0.9230 - recall: 0.8668 - val_loss: 0.2128 - val_precision: 0.7368 - val_recall: 0.6562\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0622 - precision: 0.9279 - recall: 0.8878 - val_loss: 0.2403 - val_precision: 0.7222 - val_recall: 0.7109\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0613 - precision: 0.9354 - recall: 0.8856 - val_loss: 0.2368 - val_precision: 0.8039 - val_recall: 0.6406\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0621 - precision: 0.9315 - recall: 0.8889 - val_loss: 0.2395 - val_precision: 0.7522 - val_recall: 0.6641\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0535 - precision: 0.9304 - recall: 0.8986 - val_loss: 0.2390 - val_precision: 0.7222 - val_recall: 0.7109\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0493 - precision: 0.9477 - recall: 0.9067 - val_loss: 0.2725 - val_precision: 0.6556 - val_recall: 0.7734\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 4s 15ms/step - loss: 0.0559 - precision: 0.9358 - recall: 0.8895 - val_loss: 0.2449 - val_precision: 0.7377 - val_recall: 0.7031\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0411 - precision: 0.9534 - recall: 0.9287 - val_loss: 0.2474 - val_precision: 0.7658 - val_recall: 0.6641\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0349 - precision: 0.9790 - recall: 0.9383 - val_loss: 0.2762 - val_precision: 0.6894 - val_recall: 0.7109\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 4s 15ms/step - loss: 0.0435 - precision: 0.9608 - recall: 0.9243 - val_loss: 0.2607 - val_precision: 0.7500 - val_recall: 0.7266\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0309 - precision: 0.9750 - recall: 0.9450 - val_loss: 0.2916 - val_precision: 0.7652 - val_recall: 0.6875\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0286 - precision: 0.9740 - recall: 0.9476 - val_loss: 0.2885 - val_precision: 0.7500 - val_recall: 0.7031\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0218 - precision: 0.9848 - recall: 0.9654 - val_loss: 0.3043 - val_precision: 0.7302 - val_recall: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0316 - precision: 0.9638 - recall: 0.9262 - val_loss: 0.2926 - val_precision: 0.7077 - val_recall: 0.7188\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 4s 13ms/step - loss: 0.0221 - precision: 0.9810 - recall: 0.9602 - val_loss: 0.3026 - val_precision: 0.7460 - val_recall: 0.7344\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 4s 14ms/step - loss: 0.0176 - precision: 0.9940 - recall: 0.9641 - val_loss: 0.3022 - val_precision: 0.7719 - val_recall: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda585950a0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "lstm0 = Sequential()\n",
    "\n",
    "lstm0.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "lstm0.add(LSTM(32, return_sequences=True))\n",
    "lstm0.add(LSTM(16))\n",
    "lstm0.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "lstm0.summary()\n",
    "\n",
    "lstm0.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "lstm0.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm0</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.742586</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.656425</td>\n",
       "      <td>1979</td>\n",
       "      <td>123</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  lstm0    0.9225    0.742586  0.716463  0.758065  0.788591   0.656425  1979   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  123  63  235  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm0_pred = (lstm0.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, lstm0_pred, 'lstm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,857\n",
      "Trainable params: 20,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 4s 9ms/step - loss: 0.3883 - precision: 0.3628 - recall: 0.0689 - val_loss: 0.2407 - val_precision: 0.5941 - val_recall: 0.4688\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2371 - precision: 0.6320 - recall: 0.4480 - val_loss: 0.2436 - val_precision: 0.7500 - val_recall: 0.3047\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2076 - precision: 0.7115 - recall: 0.4353 - val_loss: 0.2227 - val_precision: 0.6228 - val_recall: 0.5547\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2091 - precision: 0.7145 - recall: 0.5136 - val_loss: 0.2158 - val_precision: 0.6471 - val_recall: 0.5156\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1943 - precision: 0.7572 - recall: 0.5289 - val_loss: 0.2150 - val_precision: 0.6731 - val_recall: 0.5469\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1892 - precision: 0.7657 - recall: 0.5435 - val_loss: 0.2130 - val_precision: 0.6581 - val_recall: 0.6016\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1808 - precision: 0.7837 - recall: 0.5583 - val_loss: 0.2058 - val_precision: 0.7471 - val_recall: 0.5078\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1829 - precision: 0.8068 - recall: 0.5597 - val_loss: 0.2017 - val_precision: 0.7419 - val_recall: 0.5391\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1789 - precision: 0.7592 - recall: 0.5176 - val_loss: 0.2121 - val_precision: 0.7347 - val_recall: 0.5625\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1737 - precision: 0.7807 - recall: 0.5657 - val_loss: 0.2094 - val_precision: 0.8043 - val_recall: 0.5781\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1595 - precision: 0.8182 - recall: 0.5986 - val_loss: 0.1935 - val_precision: 0.7822 - val_recall: 0.6172\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1669 - precision: 0.8247 - recall: 0.6250 - val_loss: 0.1971 - val_precision: 0.7822 - val_recall: 0.6172\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1524 - precision: 0.8153 - recall: 0.6328 - val_loss: 0.1939 - val_precision: 0.8452 - val_recall: 0.5547\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1503 - precision: 0.8173 - recall: 0.6497 - val_loss: 0.1902 - val_precision: 0.8409 - val_recall: 0.5781\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1472 - precision: 0.8455 - recall: 0.6870 - val_loss: 0.1887 - val_precision: 0.7767 - val_recall: 0.6250\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1343 - precision: 0.8361 - recall: 0.6816 - val_loss: 0.1848 - val_precision: 0.7957 - val_recall: 0.5781\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1403 - precision: 0.8481 - recall: 0.6984 - val_loss: 0.1878 - val_precision: 0.8105 - val_recall: 0.6016\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1318 - precision: 0.8440 - recall: 0.6901 - val_loss: 0.1901 - val_precision: 0.7519 - val_recall: 0.7578\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1241 - precision: 0.8700 - recall: 0.7337 - val_loss: 0.1948 - val_precision: 0.7477 - val_recall: 0.6250\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1162 - precision: 0.8501 - recall: 0.7256 - val_loss: 0.1767 - val_precision: 0.7712 - val_recall: 0.7109\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1183 - precision: 0.8509 - recall: 0.7555 - val_loss: 0.1801 - val_precision: 0.7619 - val_recall: 0.7500\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1149 - precision: 0.8813 - recall: 0.7571 - val_loss: 0.1739 - val_precision: 0.8350 - val_recall: 0.6719\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1110 - precision: 0.8583 - recall: 0.7704 - val_loss: 0.1753 - val_precision: 0.7667 - val_recall: 0.7188\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1021 - precision: 0.8678 - recall: 0.7960 - val_loss: 0.1793 - val_precision: 0.7895 - val_recall: 0.7031\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0949 - precision: 0.8778 - recall: 0.8129 - val_loss: 0.1803 - val_precision: 0.7462 - val_recall: 0.7578\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0919 - precision: 0.8948 - recall: 0.8187 - val_loss: 0.1756 - val_precision: 0.7540 - val_recall: 0.7422\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0938 - precision: 0.8768 - recall: 0.8153 - val_loss: 0.1741 - val_precision: 0.7787 - val_recall: 0.7422\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0916 - precision: 0.8835 - recall: 0.8115 - val_loss: 0.1729 - val_precision: 0.7724 - val_recall: 0.7422\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0823 - precision: 0.8971 - recall: 0.8260 - val_loss: 0.1889 - val_precision: 0.7279 - val_recall: 0.7734\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0848 - precision: 0.8912 - recall: 0.8297 - val_loss: 0.1786 - val_precision: 0.8350 - val_recall: 0.6719\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0904 - precision: 0.8908 - recall: 0.7978 - val_loss: 0.1771 - val_precision: 0.8033 - val_recall: 0.7656\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0791 - precision: 0.8988 - recall: 0.8496 - val_loss: 0.1842 - val_precision: 0.7619 - val_recall: 0.7500\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0743 - precision: 0.9210 - recall: 0.8478 - val_loss: 0.1814 - val_precision: 0.8273 - val_recall: 0.7109\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0729 - precision: 0.9200 - recall: 0.8360 - val_loss: 0.1730 - val_precision: 0.7787 - val_recall: 0.7422\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0664 - precision: 0.9202 - recall: 0.8687 - val_loss: 0.1725 - val_precision: 0.7661 - val_recall: 0.7422\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0626 - precision: 0.9382 - recall: 0.8766 - val_loss: 0.1733 - val_precision: 0.7917 - val_recall: 0.7422\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0736 - precision: 0.9269 - recall: 0.8647 - val_loss: 0.1805 - val_precision: 0.8051 - val_recall: 0.7422\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0620 - precision: 0.9303 - recall: 0.8849 - val_loss: 0.1810 - val_precision: 0.7851 - val_recall: 0.7422\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0557 - precision: 0.9275 - recall: 0.8874 - val_loss: 0.1882 - val_precision: 0.7698 - val_recall: 0.7578\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0558 - precision: 0.9399 - recall: 0.9110 - val_loss: 0.1897 - val_precision: 0.7293 - val_recall: 0.7578\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0571 - precision: 0.9238 - recall: 0.9021 - val_loss: 0.1863 - val_precision: 0.7815 - val_recall: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0514 - precision: 0.9415 - recall: 0.8934 - val_loss: 0.1954 - val_precision: 0.7795 - val_recall: 0.7734\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0474 - precision: 0.9467 - recall: 0.9063 - val_loss: 0.1974 - val_precision: 0.7302 - val_recall: 0.7188\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0476 - precision: 0.9446 - recall: 0.9050 - val_loss: 0.1964 - val_precision: 0.7481 - val_recall: 0.7656\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0389 - precision: 0.9578 - recall: 0.9367 - val_loss: 0.1973 - val_precision: 0.7481 - val_recall: 0.7656\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0394 - precision: 0.9544 - recall: 0.9290 - val_loss: 0.2014 - val_precision: 0.7913 - val_recall: 0.7109\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0493 - precision: 0.9524 - recall: 0.9193 - val_loss: 0.2005 - val_precision: 0.7402 - val_recall: 0.7344\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0415 - precision: 0.9637 - recall: 0.9260 - val_loss: 0.2018 - val_precision: 0.7603 - val_recall: 0.7188\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0375 - precision: 0.9537 - recall: 0.9395 - val_loss: 0.2044 - val_precision: 0.7647 - val_recall: 0.7109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda701b4e50>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "lstm1 = Sequential()\n",
    "\n",
    "lstm1.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "lstm1.add(LSTM(32))\n",
    "lstm1.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "lstm1.summary()\n",
    "\n",
    "lstm1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "lstm1.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm1</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>0.75114</td>\n",
       "      <td>0.742671</td>\n",
       "      <td>0.755968</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>2014</td>\n",
       "      <td>88</td>\n",
       "      <td>70</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  lstm1  0.934167     0.75114  0.742671  0.755968  0.765101   0.721519  2014   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  88  70  228  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1_pred = (lstm1.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, lstm1_pred, 'lstm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 21,369\n",
      "Trainable params: 21,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 5s 11ms/step - loss: 0.3909 - precision: 0.3645 - recall: 0.0908 - val_loss: 0.2424 - val_precision: 0.5631 - val_recall: 0.4531\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2338 - precision: 0.6453 - recall: 0.4654 - val_loss: 0.2359 - val_precision: 0.8197 - val_recall: 0.3906\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1959 - precision: 0.7278 - recall: 0.4722 - val_loss: 0.2181 - val_precision: 0.6154 - val_recall: 0.5625\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2013 - precision: 0.7355 - recall: 0.5326 - val_loss: 0.2110 - val_precision: 0.6989 - val_recall: 0.5078\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1846 - precision: 0.7658 - recall: 0.5519 - val_loss: 0.2108 - val_precision: 0.7234 - val_recall: 0.5312\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1817 - precision: 0.8039 - recall: 0.5696 - val_loss: 0.2142 - val_precision: 0.6260 - val_recall: 0.6406\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1732 - precision: 0.7795 - recall: 0.5678 - val_loss: 0.2039 - val_precision: 0.7957 - val_recall: 0.5781\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1735 - precision: 0.7858 - recall: 0.5947 - val_loss: 0.1938 - val_precision: 0.7835 - val_recall: 0.5938\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1683 - precision: 0.7869 - recall: 0.5839 - val_loss: 0.1993 - val_precision: 0.7685 - val_recall: 0.6484\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1658 - precision: 0.7892 - recall: 0.6351 - val_loss: 0.2042 - val_precision: 0.8409 - val_recall: 0.5781\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1468 - precision: 0.8294 - recall: 0.6323 - val_loss: 0.1878 - val_precision: 0.8039 - val_recall: 0.6406\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1531 - precision: 0.8235 - recall: 0.6520 - val_loss: 0.1905 - val_precision: 0.7798 - val_recall: 0.6641\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1384 - precision: 0.8229 - recall: 0.6924 - val_loss: 0.1886 - val_precision: 0.8421 - val_recall: 0.6250\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1379 - precision: 0.8421 - recall: 0.7089 - val_loss: 0.1912 - val_precision: 0.8556 - val_recall: 0.6016\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1355 - precision: 0.8361 - recall: 0.7099 - val_loss: 0.1778 - val_precision: 0.8091 - val_recall: 0.6953\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1252 - precision: 0.8500 - recall: 0.7149 - val_loss: 0.1783 - val_precision: 0.8182 - val_recall: 0.7031\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1255 - precision: 0.8719 - recall: 0.7421 - val_loss: 0.1781 - val_precision: 0.8367 - val_recall: 0.6406\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1234 - precision: 0.8543 - recall: 0.7201 - val_loss: 0.1800 - val_precision: 0.7600 - val_recall: 0.7422\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1167 - precision: 0.8736 - recall: 0.7613 - val_loss: 0.1813 - val_precision: 0.8365 - val_recall: 0.6797\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1049 - precision: 0.8643 - recall: 0.7515 - val_loss: 0.1739 - val_precision: 0.8091 - val_recall: 0.6953\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1039 - precision: 0.8891 - recall: 0.7813 - val_loss: 0.1686 - val_precision: 0.7541 - val_recall: 0.7188\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1013 - precision: 0.8980 - recall: 0.7699 - val_loss: 0.1734 - val_precision: 0.8431 - val_recall: 0.6719\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1006 - precision: 0.8944 - recall: 0.7750 - val_loss: 0.1732 - val_precision: 0.7667 - val_recall: 0.7188\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0890 - precision: 0.8984 - recall: 0.8231 - val_loss: 0.1839 - val_precision: 0.8333 - val_recall: 0.6641\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0847 - precision: 0.9088 - recall: 0.8397 - val_loss: 0.1780 - val_precision: 0.7442 - val_recall: 0.7500\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0768 - precision: 0.9129 - recall: 0.8554 - val_loss: 0.1754 - val_precision: 0.7680 - val_recall: 0.7500\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0794 - precision: 0.9053 - recall: 0.8485 - val_loss: 0.1838 - val_precision: 0.7966 - val_recall: 0.7344\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0812 - precision: 0.9142 - recall: 0.8396 - val_loss: 0.1876 - val_precision: 0.8018 - val_recall: 0.6953\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0664 - precision: 0.9312 - recall: 0.8665 - val_loss: 0.2190 - val_precision: 0.7027 - val_recall: 0.8125\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0644 - precision: 0.9326 - recall: 0.8800 - val_loss: 0.2111 - val_precision: 0.8469 - val_recall: 0.6484\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0722 - precision: 0.9247 - recall: 0.8547 - val_loss: 0.2065 - val_precision: 0.8056 - val_recall: 0.6797\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0615 - precision: 0.9335 - recall: 0.8808 - val_loss: 0.2005 - val_precision: 0.7561 - val_recall: 0.7266\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0560 - precision: 0.9301 - recall: 0.9008 - val_loss: 0.2118 - val_precision: 0.7797 - val_recall: 0.7188\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0522 - precision: 0.9381 - recall: 0.8818 - val_loss: 0.2120 - val_precision: 0.7857 - val_recall: 0.6875\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0492 - precision: 0.9561 - recall: 0.9058 - val_loss: 0.2189 - val_precision: 0.7823 - val_recall: 0.7578\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0413 - precision: 0.9646 - recall: 0.9172 - val_loss: 0.2305 - val_precision: 0.7426 - val_recall: 0.7891\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0465 - precision: 0.9665 - recall: 0.9238 - val_loss: 0.2370 - val_precision: 0.7680 - val_recall: 0.7500\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0331 - precision: 0.9629 - recall: 0.9391 - val_loss: 0.2611 - val_precision: 0.7797 - val_recall: 0.7188\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0282 - precision: 0.9671 - recall: 0.9378 - val_loss: 0.2671 - val_precision: 0.7226 - val_recall: 0.7734\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0267 - precision: 0.9777 - recall: 0.9670 - val_loss: 0.2935 - val_precision: 0.7101 - val_recall: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0318 - precision: 0.9667 - recall: 0.9446 - val_loss: 0.2903 - val_precision: 0.7520 - val_recall: 0.7344\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0228 - precision: 0.9679 - recall: 0.9677 - val_loss: 0.3028 - val_precision: 0.7092 - val_recall: 0.7812\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0180 - precision: 0.9862 - recall: 0.9804 - val_loss: 0.3258 - val_precision: 0.7319 - val_recall: 0.7891\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0189 - precision: 0.9743 - recall: 0.9667 - val_loss: 0.3232 - val_precision: 0.7442 - val_recall: 0.7500\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0201 - precision: 0.9797 - recall: 0.9700 - val_loss: 0.3283 - val_precision: 0.7364 - val_recall: 0.7422\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0172 - precision: 0.9913 - recall: 0.9694 - val_loss: 0.3632 - val_precision: 0.7667 - val_recall: 0.7188\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0179 - precision: 0.9858 - recall: 0.9720 - val_loss: 0.3594 - val_precision: 0.7163 - val_recall: 0.7891\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0151 - precision: 0.9827 - recall: 0.9760 - val_loss: 0.3869 - val_precision: 0.7480 - val_recall: 0.7422\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0106 - precision: 0.9906 - recall: 0.9882 - val_loss: 0.3901 - val_precision: 0.7619 - val_recall: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaa8390070>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "lstm2 = Sequential()\n",
    "\n",
    "lstm2.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "lstm2.add(LSTM(32))\n",
    "lstm2.add(Dense(16, \"tanh\"))\n",
    "lstm2.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "lstm2.summary()\n",
    "\n",
    "lstm2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "lstm2.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm2</td>\n",
       "      <td>0.929583</td>\n",
       "      <td>0.744622</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.752794</td>\n",
       "      <td>0.768456</td>\n",
       "      <td>0.696049</td>\n",
       "      <td>2002</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  lstm2  0.929583    0.744622  0.730463  0.752794  0.768456   0.696049  2002   \n",
       "\n",
       "    fp  fn   tp  \n",
       "0  100  69  229  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm2_pred = (lstm2.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, lstm2_pred, 'lstm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 21,369\n",
      "Trainable params: 21,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 4s 10ms/step - loss: 0.4651 - precision: 0.1116 - recall: 0.1099 - val_loss: 0.3822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3194 - precision: 0.4007 - recall: 0.0550 - val_loss: 0.2689 - val_precision: 0.8571 - val_recall: 0.1875\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2275 - precision: 0.7270 - recall: 0.3623 - val_loss: 0.2348 - val_precision: 0.6216 - val_recall: 0.5391\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2144 - precision: 0.7189 - recall: 0.5426 - val_loss: 0.2216 - val_precision: 0.7561 - val_recall: 0.4844\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1914 - precision: 0.7509 - recall: 0.5474 - val_loss: 0.2140 - val_precision: 0.7558 - val_recall: 0.5078\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1840 - precision: 0.7631 - recall: 0.5918 - val_loss: 0.2115 - val_precision: 0.6880 - val_recall: 0.6719\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1740 - precision: 0.7756 - recall: 0.6030 - val_loss: 0.2006 - val_precision: 0.7426 - val_recall: 0.5859\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1768 - precision: 0.7779 - recall: 0.6190 - val_loss: 0.1938 - val_precision: 0.7849 - val_recall: 0.5703\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1729 - precision: 0.7646 - recall: 0.5683 - val_loss: 0.1908 - val_precision: 0.7732 - val_recall: 0.5859\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1675 - precision: 0.7856 - recall: 0.6312 - val_loss: 0.1913 - val_precision: 0.7912 - val_recall: 0.5625\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1548 - precision: 0.8208 - recall: 0.6283 - val_loss: 0.1786 - val_precision: 0.8061 - val_recall: 0.6172\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1579 - precision: 0.8186 - recall: 0.6640 - val_loss: 0.1776 - val_precision: 0.8242 - val_recall: 0.5859\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1417 - precision: 0.8273 - recall: 0.6839 - val_loss: 0.1743 - val_precision: 0.8652 - val_recall: 0.6016\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1397 - precision: 0.8320 - recall: 0.6980 - val_loss: 0.1779 - val_precision: 0.8404 - val_recall: 0.6172\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1385 - precision: 0.8338 - recall: 0.7166 - val_loss: 0.1712 - val_precision: 0.7925 - val_recall: 0.6562\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1311 - precision: 0.8293 - recall: 0.7351 - val_loss: 0.1641 - val_precision: 0.8447 - val_recall: 0.6797\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1301 - precision: 0.8594 - recall: 0.7538 - val_loss: 0.1758 - val_precision: 0.8804 - val_recall: 0.6328\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1264 - precision: 0.8383 - recall: 0.7169 - val_loss: 0.1623 - val_precision: 0.7422 - val_recall: 0.7422\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1173 - precision: 0.8678 - recall: 0.7877 - val_loss: 0.1642 - val_precision: 0.8462 - val_recall: 0.6875\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1052 - precision: 0.8674 - recall: 0.7603 - val_loss: 0.1592 - val_precision: 0.8142 - val_recall: 0.7188\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1116 - precision: 0.8590 - recall: 0.7818 - val_loss: 0.1604 - val_precision: 0.7778 - val_recall: 0.7109\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1045 - precision: 0.8915 - recall: 0.8018 - val_loss: 0.1746 - val_precision: 0.9091 - val_recall: 0.6250\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1115 - precision: 0.8800 - recall: 0.7747 - val_loss: 0.1605 - val_precision: 0.8120 - val_recall: 0.7422\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0979 - precision: 0.8870 - recall: 0.8237 - val_loss: 0.1680 - val_precision: 0.8208 - val_recall: 0.6797\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0903 - precision: 0.9002 - recall: 0.8260 - val_loss: 0.1647 - val_precision: 0.7407 - val_recall: 0.7812\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0880 - precision: 0.9141 - recall: 0.8386 - val_loss: 0.1611 - val_precision: 0.7869 - val_recall: 0.7500\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0937 - precision: 0.8942 - recall: 0.8245 - val_loss: 0.1696 - val_precision: 0.7899 - val_recall: 0.7344\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0899 - precision: 0.8966 - recall: 0.8276 - val_loss: 0.1683 - val_precision: 0.7917 - val_recall: 0.7422\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0806 - precision: 0.9124 - recall: 0.8518 - val_loss: 0.1781 - val_precision: 0.7218 - val_recall: 0.7500\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0822 - precision: 0.9097 - recall: 0.8517 - val_loss: 0.1883 - val_precision: 0.8317 - val_recall: 0.6562\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0839 - precision: 0.9192 - recall: 0.8296 - val_loss: 0.1830 - val_precision: 0.7818 - val_recall: 0.6719\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0753 - precision: 0.9161 - recall: 0.8560 - val_loss: 0.1874 - val_precision: 0.7778 - val_recall: 0.7109\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0708 - precision: 0.9396 - recall: 0.8597 - val_loss: 0.1948 - val_precision: 0.7520 - val_recall: 0.7344\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0711 - precision: 0.9390 - recall: 0.8626 - val_loss: 0.1982 - val_precision: 0.7273 - val_recall: 0.8125\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0647 - precision: 0.9334 - recall: 0.8852 - val_loss: 0.1885 - val_precision: 0.7541 - val_recall: 0.7188\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0582 - precision: 0.9528 - recall: 0.8895 - val_loss: 0.2001 - val_precision: 0.7540 - val_recall: 0.7422\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0711 - precision: 0.9366 - recall: 0.8733 - val_loss: 0.2108 - val_precision: 0.7279 - val_recall: 0.7734\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0567 - precision: 0.9587 - recall: 0.9048 - val_loss: 0.2095 - val_precision: 0.7405 - val_recall: 0.7578\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0542 - precision: 0.9502 - recall: 0.9043 - val_loss: 0.2119 - val_precision: 0.7266 - val_recall: 0.7266\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0458 - precision: 0.9648 - recall: 0.9253 - val_loss: 0.2152 - val_precision: 0.7348 - val_recall: 0.7578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0490 - precision: 0.9556 - recall: 0.9315 - val_loss: 0.2294 - val_precision: 0.7402 - val_recall: 0.7344\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0500 - precision: 0.9638 - recall: 0.9218 - val_loss: 0.2289 - val_precision: 0.7143 - val_recall: 0.7812\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0423 - precision: 0.9692 - recall: 0.9423 - val_loss: 0.2578 - val_precision: 0.6776 - val_recall: 0.8047\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0373 - precision: 0.9651 - recall: 0.9445 - val_loss: 0.2272 - val_precision: 0.7540 - val_recall: 0.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaabb1e1f0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "lstm3 = Sequential()\n",
    "\n",
    "lstm3.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "lstm3.add(LSTM(32))\n",
    "lstm3.add(Dense(16, \"sigmoid\"))\n",
    "lstm3.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "lstm3.summary()\n",
    "\n",
    "lstm3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "lstm3.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm3</td>\n",
       "      <td>0.937917</td>\n",
       "      <td>0.778832</td>\n",
       "      <td>0.763116</td>\n",
       "      <td>0.787919</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>2011</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  lstm3  0.937917    0.778832  0.763116  0.787919  0.805369   0.725076  2011   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  91  58  240  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm3_pred = (lstm3.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, lstm3_pred, 'lstm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 22,425\n",
      "Trainable params: 22,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 4s 10ms/step - loss: 0.8138 - precision: 0.1254 - recall: 0.3562 - val_loss: 0.3988 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3820 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3926 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3599 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3928 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3795 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3932 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3737 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3904 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3345 - precision: 0.6401 - recall: 0.1238 - val_loss: 0.2532 - val_precision: 0.6569 - val_recall: 0.5234\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2271 - precision: 0.6992 - recall: 0.4821 - val_loss: 0.2296 - val_precision: 0.7674 - val_recall: 0.5156\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2122 - precision: 0.7631 - recall: 0.4953 - val_loss: 0.2187 - val_precision: 0.7692 - val_recall: 0.4688\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2047 - precision: 0.7642 - recall: 0.4298 - val_loss: 0.2300 - val_precision: 0.6735 - val_recall: 0.5156\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1961 - precision: 0.7528 - recall: 0.5160 - val_loss: 0.2109 - val_precision: 0.7204 - val_recall: 0.5234\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1792 - precision: 0.7807 - recall: 0.5633 - val_loss: 0.2046 - val_precision: 0.7875 - val_recall: 0.4922\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1869 - precision: 0.7714 - recall: 0.5658 - val_loss: 0.2082 - val_precision: 0.7528 - val_recall: 0.5234\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1690 - precision: 0.7612 - recall: 0.5815 - val_loss: 0.1983 - val_precision: 0.7300 - val_recall: 0.5703\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1706 - precision: 0.7667 - recall: 0.6315 - val_loss: 0.2011 - val_precision: 0.7727 - val_recall: 0.5312\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1665 - precision: 0.7925 - recall: 0.6812 - val_loss: 0.1932 - val_precision: 0.7547 - val_recall: 0.6250\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1585 - precision: 0.7867 - recall: 0.6413 - val_loss: 0.1837 - val_precision: 0.8125 - val_recall: 0.6094\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1586 - precision: 0.8036 - recall: 0.6842 - val_loss: 0.1986 - val_precision: 0.8554 - val_recall: 0.5547\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1501 - precision: 0.7989 - recall: 0.6547 - val_loss: 0.1967 - val_precision: 0.6857 - val_recall: 0.7500\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1396 - precision: 0.8240 - recall: 0.7263 - val_loss: 0.1859 - val_precision: 0.8000 - val_recall: 0.6250\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1274 - precision: 0.8224 - recall: 0.7086 - val_loss: 0.1796 - val_precision: 0.8316 - val_recall: 0.6172\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1306 - precision: 0.8421 - recall: 0.7202 - val_loss: 0.1739 - val_precision: 0.7838 - val_recall: 0.6797\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1306 - precision: 0.8640 - recall: 0.7151 - val_loss: 0.1910 - val_precision: 0.8333 - val_recall: 0.5859\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1284 - precision: 0.8407 - recall: 0.7536 - val_loss: 0.1745 - val_precision: 0.7838 - val_recall: 0.6797\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1141 - precision: 0.8568 - recall: 0.7809 - val_loss: 0.1782 - val_precision: 0.8095 - val_recall: 0.6641\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1020 - precision: 0.8813 - recall: 0.8015 - val_loss: 0.1800 - val_precision: 0.7615 - val_recall: 0.6484\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0990 - precision: 0.8876 - recall: 0.8122 - val_loss: 0.1827 - val_precision: 0.7826 - val_recall: 0.7031\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0978 - precision: 0.8960 - recall: 0.8087 - val_loss: 0.1802 - val_precision: 0.7778 - val_recall: 0.7109\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1009 - precision: 0.8904 - recall: 0.8057 - val_loss: 0.1768 - val_precision: 0.7692 - val_recall: 0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaaebcabe0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "lstm4 = Sequential()\n",
    "\n",
    "lstm4.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "lstm4.add(LSTM(32))\n",
    "lstm4.add(Dense(32, \"relu\"))\n",
    "lstm4.add(Dense(16, \"sigmoid\"))\n",
    "lstm4.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "lstm4.summary()\n",
    "\n",
    "lstm4.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "lstm4.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm4</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.737659</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.741356</td>\n",
       "      <td>0.748322</td>\n",
       "      <td>0.714744</td>\n",
       "      <td>2013</td>\n",
       "      <td>89</td>\n",
       "      <td>75</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy  F1.5-score  F1-score  F2-score    recall  precision    tn  \\\n",
       "0  lstm4  0.931667    0.737659  0.731148  0.741356  0.748322   0.714744  2013   \n",
       "\n",
       "   fp  fn   tp  \n",
       "0  89  75  223  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm4_pred = (lstm4.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, lstm4_pred, 'lstm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 37,913\n",
      "Trainable params: 37,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 6s 13ms/step - loss: 0.3735 - precision: 0.3571 - recall: 0.0767 - val_loss: 0.2423 - val_precision: 0.5370 - val_recall: 0.4531\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.2341 - precision: 0.6556 - recall: 0.4267 - val_loss: 0.2403 - val_precision: 0.8000 - val_recall: 0.3125\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.2032 - precision: 0.7268 - recall: 0.4412 - val_loss: 0.2207 - val_precision: 0.6261 - val_recall: 0.5625\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.2050 - precision: 0.7173 - recall: 0.5146 - val_loss: 0.2107 - val_precision: 0.7342 - val_recall: 0.4531\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1902 - precision: 0.7718 - recall: 0.5195 - val_loss: 0.2128 - val_precision: 0.7010 - val_recall: 0.5312\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1867 - precision: 0.7753 - recall: 0.5502 - val_loss: 0.2172 - val_precision: 0.6378 - val_recall: 0.6328\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1803 - precision: 0.7929 - recall: 0.5481 - val_loss: 0.2072 - val_precision: 0.7609 - val_recall: 0.5469\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1826 - precision: 0.7988 - recall: 0.5657 - val_loss: 0.1984 - val_precision: 0.7640 - val_recall: 0.5312\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1769 - precision: 0.7933 - recall: 0.5463 - val_loss: 0.2055 - val_precision: 0.7525 - val_recall: 0.5938\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1708 - precision: 0.7909 - recall: 0.5921 - val_loss: 0.2001 - val_precision: 0.7700 - val_recall: 0.6016\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1610 - precision: 0.8099 - recall: 0.6004 - val_loss: 0.1868 - val_precision: 0.7843 - val_recall: 0.6250\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1654 - precision: 0.8132 - recall: 0.6149 - val_loss: 0.1996 - val_precision: 0.7822 - val_recall: 0.6172\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1492 - precision: 0.8049 - recall: 0.6406 - val_loss: 0.1892 - val_precision: 0.8023 - val_recall: 0.5391\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1511 - precision: 0.8243 - recall: 0.6324 - val_loss: 0.1966 - val_precision: 0.8140 - val_recall: 0.5469\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1481 - precision: 0.8381 - recall: 0.6657 - val_loss: 0.1852 - val_precision: 0.7714 - val_recall: 0.6328\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1394 - precision: 0.8277 - recall: 0.6863 - val_loss: 0.1828 - val_precision: 0.8163 - val_recall: 0.6250\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1449 - precision: 0.8399 - recall: 0.6831 - val_loss: 0.1925 - val_precision: 0.8182 - val_recall: 0.6328\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1347 - precision: 0.8327 - recall: 0.6749 - val_loss: 0.1905 - val_precision: 0.6917 - val_recall: 0.7188\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1282 - precision: 0.8427 - recall: 0.7399 - val_loss: 0.1938 - val_precision: 0.7921 - val_recall: 0.6250\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1216 - precision: 0.8420 - recall: 0.7078 - val_loss: 0.1802 - val_precision: 0.8020 - val_recall: 0.6328\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1221 - precision: 0.8493 - recall: 0.7367 - val_loss: 0.1763 - val_precision: 0.7500 - val_recall: 0.7266\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1203 - precision: 0.8772 - recall: 0.7535 - val_loss: 0.1754 - val_precision: 0.8511 - val_recall: 0.6250\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1183 - precision: 0.8616 - recall: 0.7561 - val_loss: 0.1723 - val_precision: 0.7845 - val_recall: 0.7109\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1066 - precision: 0.8811 - recall: 0.7946 - val_loss: 0.1794 - val_precision: 0.7895 - val_recall: 0.7031\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1010 - precision: 0.8895 - recall: 0.7908 - val_loss: 0.1808 - val_precision: 0.7561 - val_recall: 0.7266\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0982 - precision: 0.9037 - recall: 0.8050 - val_loss: 0.1789 - val_precision: 0.7731 - val_recall: 0.7188\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.0975 - precision: 0.8958 - recall: 0.8049 - val_loss: 0.1872 - val_precision: 0.7619 - val_recall: 0.7500\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.1000 - precision: 0.8760 - recall: 0.7884 - val_loss: 0.1741 - val_precision: 0.8036 - val_recall: 0.7031\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0884 - precision: 0.9009 - recall: 0.8271 - val_loss: 0.1883 - val_precision: 0.7581 - val_recall: 0.7344\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0920 - precision: 0.8972 - recall: 0.8190 - val_loss: 0.1721 - val_precision: 0.7909 - val_recall: 0.6797\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0938 - precision: 0.8839 - recall: 0.7966 - val_loss: 0.1761 - val_precision: 0.8241 - val_recall: 0.6953\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0842 - precision: 0.8946 - recall: 0.8177 - val_loss: 0.1973 - val_precision: 0.7246 - val_recall: 0.7812\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0813 - precision: 0.9073 - recall: 0.8331 - val_loss: 0.1933 - val_precision: 0.7698 - val_recall: 0.7578\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0758 - precision: 0.9138 - recall: 0.8456 - val_loss: 0.1845 - val_precision: 0.7597 - val_recall: 0.7656\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0681 - precision: 0.9240 - recall: 0.8779 - val_loss: 0.1812 - val_precision: 0.7674 - val_recall: 0.7734\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0690 - precision: 0.9292 - recall: 0.8612 - val_loss: 0.1929 - val_precision: 0.7634 - val_recall: 0.7812\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 3s 11ms/step - loss: 0.0728 - precision: 0.9136 - recall: 0.8596 - val_loss: 0.1835 - val_precision: 0.7710 - val_recall: 0.7891\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0622 - precision: 0.9286 - recall: 0.8894 - val_loss: 0.1846 - val_precision: 0.8182 - val_recall: 0.7734\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0575 - precision: 0.9401 - recall: 0.8803 - val_loss: 0.2023 - val_precision: 0.7540 - val_recall: 0.7422\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0558 - precision: 0.9408 - recall: 0.9052 - val_loss: 0.2001 - val_precision: 0.7669 - val_recall: 0.7969\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0561 - precision: 0.9182 - recall: 0.8910 - val_loss: 0.1937 - val_precision: 0.7874 - val_recall: 0.7812\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0465 - precision: 0.9405 - recall: 0.9150 - val_loss: 0.2277 - val_precision: 0.7391 - val_recall: 0.7969\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0464 - precision: 0.9525 - recall: 0.9158 - val_loss: 0.2177 - val_precision: 0.7255 - val_recall: 0.8672\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0466 - precision: 0.9379 - recall: 0.9218 - val_loss: 0.1948 - val_precision: 0.7704 - val_recall: 0.8125\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0376 - precision: 0.9505 - recall: 0.9353 - val_loss: 0.2054 - val_precision: 0.7574 - val_recall: 0.8047\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0400 - precision: 0.9530 - recall: 0.9162 - val_loss: 0.2191 - val_precision: 0.7669 - val_recall: 0.7969\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0402 - precision: 0.9617 - recall: 0.9223 - val_loss: 0.1982 - val_precision: 0.7518 - val_recall: 0.8047\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0454 - precision: 0.9399 - recall: 0.9183 - val_loss: 0.2019 - val_precision: 0.7786 - val_recall: 0.7969\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0280 - precision: 0.9792 - recall: 0.9581 - val_loss: 0.2213 - val_precision: 0.7795 - val_recall: 0.7734\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0257 - precision: 0.9775 - recall: 0.9554 - val_loss: 0.2266 - val_precision: 0.7647 - val_recall: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdabb6c9190>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "bilstm0 = Sequential()\n",
    "\n",
    "bilstm0.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "bilstm0.add(Bidirectional(LSTM(32)))\n",
    "bilstm0.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "bilstm0.summary()\n",
    "\n",
    "bilstm0.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "bilstm0.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bilstm0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.751928</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.755034</td>\n",
       "      <td>0.745033</td>\n",
       "      <td>2025</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  bilstm0    0.9375    0.751928      0.75  0.753012  0.755034   0.745033   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2025  77  73  225  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm0_pred = (bilstm0.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, bilstm0_pred, 'bilstm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 28, 64)            34048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 62,745\n",
      "Trainable params: 62,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 10s 23ms/step - loss: 0.3588 - precision: 0.4489 - recall: 0.1350 - val_loss: 0.2458 - val_precision: 0.5882 - val_recall: 0.4688\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.2324 - precision: 0.6308 - recall: 0.4503 - val_loss: 0.2339 - val_precision: 0.8197 - val_recall: 0.3906\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1985 - precision: 0.7415 - recall: 0.4715 - val_loss: 0.2226 - val_precision: 0.6396 - val_recall: 0.5547\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.2025 - precision: 0.7426 - recall: 0.5183 - val_loss: 0.2147 - val_precision: 0.7500 - val_recall: 0.4453\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1884 - precision: 0.8101 - recall: 0.5071 - val_loss: 0.2145 - val_precision: 0.6931 - val_recall: 0.5469\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1863 - precision: 0.7844 - recall: 0.5450 - val_loss: 0.2154 - val_precision: 0.7030 - val_recall: 0.5547\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1807 - precision: 0.8075 - recall: 0.5351 - val_loss: 0.2050 - val_precision: 0.7692 - val_recall: 0.5469\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1850 - precision: 0.8120 - recall: 0.5429 - val_loss: 0.2014 - val_precision: 0.8148 - val_recall: 0.5156\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1786 - precision: 0.7966 - recall: 0.5127 - val_loss: 0.2072 - val_precision: 0.8161 - val_recall: 0.5547\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1720 - precision: 0.8086 - recall: 0.5929 - val_loss: 0.2008 - val_precision: 0.8161 - val_recall: 0.5547\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 0.1554 - precision: 0.8405 - recall: 0.5918 - val_loss: 0.1916 - val_precision: 0.8211 - val_recall: 0.6094\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1665 - precision: 0.8342 - recall: 0.5934 - val_loss: 0.1962 - val_precision: 0.8242 - val_recall: 0.5859\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1486 - precision: 0.8242 - recall: 0.6238 - val_loss: 0.1911 - val_precision: 0.8649 - val_recall: 0.5000\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1486 - precision: 0.8463 - recall: 0.6262 - val_loss: 0.1902 - val_precision: 0.8625 - val_recall: 0.5391\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1448 - precision: 0.8384 - recall: 0.6505 - val_loss: 0.1831 - val_precision: 0.7981 - val_recall: 0.6484\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 0.1364 - precision: 0.8396 - recall: 0.6806 - val_loss: 0.1857 - val_precision: 0.8242 - val_recall: 0.5859\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1378 - precision: 0.8554 - recall: 0.6901 - val_loss: 0.1890 - val_precision: 0.8020 - val_recall: 0.6328\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1302 - precision: 0.8248 - recall: 0.6855 - val_loss: 0.1888 - val_precision: 0.7500 - val_recall: 0.7031\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1194 - precision: 0.8522 - recall: 0.7531 - val_loss: 0.1992 - val_precision: 0.8105 - val_recall: 0.6016\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1139 - precision: 0.8535 - recall: 0.7192 - val_loss: 0.1942 - val_precision: 0.8081 - val_recall: 0.6250\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1137 - precision: 0.8621 - recall: 0.7461 - val_loss: 0.1883 - val_precision: 0.7545 - val_recall: 0.6484\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1079 - precision: 0.8928 - recall: 0.7594 - val_loss: 0.2078 - val_precision: 0.8229 - val_recall: 0.6172\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1005 - precision: 0.8793 - recall: 0.7899 - val_loss: 0.2064 - val_precision: 0.7281 - val_recall: 0.6484\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0944 - precision: 0.8852 - recall: 0.8113 - val_loss: 0.2107 - val_precision: 0.7941 - val_recall: 0.6328\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0847 - precision: 0.9121 - recall: 0.8109 - val_loss: 0.2203 - val_precision: 0.6870 - val_recall: 0.7031\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0837 - precision: 0.9057 - recall: 0.8349 - val_loss: 0.2308 - val_precision: 0.7167 - val_recall: 0.6719\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0800 - precision: 0.8879 - recall: 0.8404 - val_loss: 0.2246 - val_precision: 0.7063 - val_recall: 0.6953\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0757 - precision: 0.9012 - recall: 0.8298 - val_loss: 0.2136 - val_precision: 0.7778 - val_recall: 0.6562\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0674 - precision: 0.9175 - recall: 0.8534 - val_loss: 0.2428 - val_precision: 0.6846 - val_recall: 0.6953\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0679 - precision: 0.9109 - recall: 0.8440 - val_loss: 0.2349 - val_precision: 0.7870 - val_recall: 0.6641\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0620 - precision: 0.9195 - recall: 0.8707 - val_loss: 0.2637 - val_precision: 0.7000 - val_recall: 0.7109\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0516 - precision: 0.9340 - recall: 0.8873 - val_loss: 0.2334 - val_precision: 0.6875 - val_recall: 0.6875\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0486 - precision: 0.9504 - recall: 0.8996 - val_loss: 0.2709 - val_precision: 0.7850 - val_recall: 0.6562\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0445 - precision: 0.9463 - recall: 0.9114 - val_loss: 0.2979 - val_precision: 0.7434 - val_recall: 0.6562\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0437 - precision: 0.9403 - recall: 0.9247 - val_loss: 0.2722 - val_precision: 0.7440 - val_recall: 0.7266\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0386 - precision: 0.9513 - recall: 0.9270 - val_loss: 0.2995 - val_precision: 0.7227 - val_recall: 0.6719\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0387 - precision: 0.9566 - recall: 0.9316 - val_loss: 0.2334 - val_precision: 0.7023 - val_recall: 0.7188\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0647 - precision: 0.9258 - recall: 0.8985 - val_loss: 0.2697 - val_precision: 0.7083 - val_recall: 0.6641\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0334 - precision: 0.9595 - recall: 0.9202 - val_loss: 0.2901 - val_precision: 0.6992 - val_recall: 0.6719\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0246 - precision: 0.9675 - recall: 0.9651 - val_loss: 0.3000 - val_precision: 0.7586 - val_recall: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.0270 - precision: 0.9631 - recall: 0.9622 - val_loss: 0.3216 - val_precision: 0.7227 - val_recall: 0.6719\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0203 - precision: 0.9756 - recall: 0.9703 - val_loss: 0.3514 - val_precision: 0.7391 - val_recall: 0.6641\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0186 - precision: 0.9774 - recall: 0.9775 - val_loss: 0.3611 - val_precision: 0.7350 - val_recall: 0.6719\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0138 - precision: 0.9838 - recall: 0.9831 - val_loss: 0.3876 - val_precision: 0.7391 - val_recall: 0.6641\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 6s 21ms/step - loss: 0.0171 - precision: 0.9812 - recall: 0.9781 - val_loss: 0.3789 - val_precision: 0.7295 - val_recall: 0.6953\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 6s 21ms/step - loss: 0.0238 - precision: 0.9632 - recall: 0.9662 - val_loss: 0.3744 - val_precision: 0.6742 - val_recall: 0.6953\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0203 - precision: 0.9763 - recall: 0.9684 - val_loss: 0.3793 - val_precision: 0.6866 - val_recall: 0.7188\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0106 - precision: 0.9884 - recall: 0.9798 - val_loss: 0.4142 - val_precision: 0.7265 - val_recall: 0.6641\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0061 - precision: 0.9956 - recall: 0.9934 - val_loss: 0.4404 - val_precision: 0.6984 - val_recall: 0.6875\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0049 - precision: 0.9980 - recall: 0.9969 - val_loss: 0.4750 - val_precision: 0.7040 - val_recall: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdadeed0fd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "bilstm1 = Sequential()\n",
    "\n",
    "bilstm1.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "bilstm1.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "bilstm1.add(Bidirectional(LSTM(32)))\n",
    "bilstm1.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "bilstm1.summary()\n",
    "\n",
    "bilstm1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "bilstm1.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bilstm1</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.733263</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.727891</td>\n",
       "      <td>0.718121</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>2038</td>\n",
       "      <td>64</td>\n",
       "      <td>84</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  bilstm1  0.938333    0.733263  0.743056  0.727891  0.718121   0.769784   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2038  64  84  214  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm1_pred = (bilstm1.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, bilstm1_pred, 'bilstm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 28, 64)            34048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32)                10368     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 48,249\n",
      "Trainable params: 48,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 10s 22ms/step - loss: 0.3737 - precision: 0.3942 - recall: 0.1203 - val_loss: 0.2406 - val_precision: 0.5804 - val_recall: 0.5078\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.2327 - precision: 0.6335 - recall: 0.4866 - val_loss: 0.2341 - val_precision: 0.7179 - val_recall: 0.4375\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.1999 - precision: 0.7349 - recall: 0.4849 - val_loss: 0.2243 - val_precision: 0.6271 - val_recall: 0.5781\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.2018 - precision: 0.7434 - recall: 0.5215 - val_loss: 0.2127 - val_precision: 0.7632 - val_recall: 0.4531\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.1871 - precision: 0.8057 - recall: 0.5282 - val_loss: 0.2082 - val_precision: 0.7100 - val_recall: 0.5547\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.1838 - precision: 0.7868 - recall: 0.5691 - val_loss: 0.2077 - val_precision: 0.7130 - val_recall: 0.6016\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1754 - precision: 0.8024 - recall: 0.5680 - val_loss: 0.2043 - val_precision: 0.8205 - val_recall: 0.5000\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 4s 17ms/step - loss: 0.1805 - precision: 0.8226 - recall: 0.5530 - val_loss: 0.1945 - val_precision: 0.8250 - val_recall: 0.5156\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.1749 - precision: 0.8070 - recall: 0.5451 - val_loss: 0.2009 - val_precision: 0.7979 - val_recall: 0.5859\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1676 - precision: 0.8100 - recall: 0.6043 - val_loss: 0.1939 - val_precision: 0.8118 - val_recall: 0.5391\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 6s 23ms/step - loss: 0.1534 - precision: 0.8254 - recall: 0.6045 - val_loss: 0.1902 - val_precision: 0.8152 - val_recall: 0.5859\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1637 - precision: 0.8307 - recall: 0.5959 - val_loss: 0.1858 - val_precision: 0.8125 - val_recall: 0.6094\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.1461 - precision: 0.8259 - recall: 0.6491 - val_loss: 0.1963 - val_precision: 0.8493 - val_recall: 0.4844\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 0.1467 - precision: 0.8475 - recall: 0.6364 - val_loss: 0.1965 - val_precision: 0.8256 - val_recall: 0.5547\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 4s 17ms/step - loss: 0.1408 - precision: 0.8479 - recall: 0.6786 - val_loss: 0.1803 - val_precision: 0.8041 - val_recall: 0.6094\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.1335 - precision: 0.8370 - recall: 0.6811 - val_loss: 0.1768 - val_precision: 0.8280 - val_recall: 0.6016\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1371 - precision: 0.8707 - recall: 0.7028 - val_loss: 0.1791 - val_precision: 0.7843 - val_recall: 0.6250\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.1262 - precision: 0.8322 - recall: 0.7111 - val_loss: 0.1802 - val_precision: 0.7417 - val_recall: 0.6953\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1180 - precision: 0.8583 - recall: 0.7688 - val_loss: 0.1920 - val_precision: 0.8211 - val_recall: 0.6094\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1128 - precision: 0.8415 - recall: 0.7300 - val_loss: 0.1846 - val_precision: 0.8211 - val_recall: 0.6094\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 0.1088 - precision: 0.8634 - recall: 0.7569 - val_loss: 0.1800 - val_precision: 0.7843 - val_recall: 0.6250\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.1050 - precision: 0.8844 - recall: 0.7672 - val_loss: 0.1974 - val_precision: 0.8352 - val_recall: 0.5938\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 4s 17ms/step - loss: 0.1010 - precision: 0.8809 - recall: 0.7767 - val_loss: 0.1890 - val_precision: 0.7759 - val_recall: 0.7031\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0928 - precision: 0.8918 - recall: 0.8051 - val_loss: 0.1946 - val_precision: 0.8511 - val_recall: 0.6250\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0845 - precision: 0.9169 - recall: 0.8189 - val_loss: 0.1875 - val_precision: 0.7570 - val_recall: 0.6328\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0795 - precision: 0.9142 - recall: 0.8342 - val_loss: 0.2060 - val_precision: 0.7739 - val_recall: 0.6953\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 4s 17ms/step - loss: 0.0828 - precision: 0.9035 - recall: 0.8391 - val_loss: 0.2038 - val_precision: 0.7623 - val_recall: 0.7266\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.0792 - precision: 0.9245 - recall: 0.8191 - val_loss: 0.2066 - val_precision: 0.8081 - val_recall: 0.6250\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.0688 - precision: 0.9249 - recall: 0.8543 - val_loss: 0.2217 - val_precision: 0.7440 - val_recall: 0.7266\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 4s 16ms/step - loss: 0.0663 - precision: 0.9197 - recall: 0.8589 - val_loss: 0.2167 - val_precision: 0.8351 - val_recall: 0.6328\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 4s 17ms/step - loss: 0.0700 - precision: 0.9297 - recall: 0.8512 - val_loss: 0.2279 - val_precision: 0.7727 - val_recall: 0.6641\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0556 - precision: 0.9447 - recall: 0.8785 - val_loss: 0.2046 - val_precision: 0.7917 - val_recall: 0.7422\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0621 - precision: 0.9291 - recall: 0.8681 - val_loss: 0.2269 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.0507 - precision: 0.9441 - recall: 0.8881 - val_loss: 0.2143 - val_precision: 0.7805 - val_recall: 0.7500\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0445 - precision: 0.9414 - recall: 0.9067 - val_loss: 0.2383 - val_precision: 0.7815 - val_recall: 0.7266\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0460 - precision: 0.9412 - recall: 0.8998 - val_loss: 0.2613 - val_precision: 0.7857 - val_recall: 0.6875\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.0451 - precision: 0.9527 - recall: 0.9031 - val_loss: 0.2441 - val_precision: 0.8095 - val_recall: 0.6641\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0422 - precision: 0.9520 - recall: 0.9195 - val_loss: 0.2765 - val_precision: 0.8073 - val_recall: 0.6875\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0330 - precision: 0.9607 - recall: 0.9307 - val_loss: 0.2830 - val_precision: 0.7521 - val_recall: 0.7109\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0301 - precision: 0.9759 - recall: 0.9457 - val_loss: 0.2896 - val_precision: 0.7647 - val_recall: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0382 - precision: 0.9443 - recall: 0.9387 - val_loss: 0.2995 - val_precision: 0.8224 - val_recall: 0.6875\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 5s 19ms/step - loss: 0.0245 - precision: 0.9680 - recall: 0.9539 - val_loss: 0.3243 - val_precision: 0.8302 - val_recall: 0.6875\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 5s 17ms/step - loss: 0.0255 - precision: 0.9670 - recall: 0.9494 - val_loss: 0.3266 - val_precision: 0.7705 - val_recall: 0.7344\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 5s 18ms/step - loss: 0.0227 - precision: 0.9653 - recall: 0.9553 - val_loss: 0.3187 - val_precision: 0.8235 - val_recall: 0.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdac14b0250>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "bilstm2 = Sequential()\n",
    "\n",
    "bilstm2.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "bilstm2.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "bilstm2.add(Bidirectional(LSTM(16)))\n",
    "bilstm2.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "bilstm2.summary()\n",
    "\n",
    "bilstm2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "bilstm2.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bilstm2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.737045</td>\n",
       "      <td>0.734219</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.741611</td>\n",
       "      <td>0.726974</td>\n",
       "      <td>2019</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  bilstm2  0.933333    0.737045  0.734219  0.738636  0.741611   0.726974   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2019  83  77  221  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm2_pred = (bilstm2.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, bilstm2_pred, 'bilstm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 40,473\n",
      "Trainable params: 40,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 6s 13ms/step - loss: 0.6246 - precision: 0.1217 - recall: 0.2803 - val_loss: 0.3931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.3707 - precision: 0.1695 - recall: 0.0108 - val_loss: 0.2891 - val_precision: 0.6923 - val_recall: 0.2812\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.2528 - precision: 0.6542 - recall: 0.4107 - val_loss: 0.2433 - val_precision: 0.6339 - val_recall: 0.5547\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.2228 - precision: 0.7094 - recall: 0.5239 - val_loss: 0.2251 - val_precision: 0.6882 - val_recall: 0.5000\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1988 - precision: 0.7639 - recall: 0.5601 - val_loss: 0.2194 - val_precision: 0.7030 - val_recall: 0.5547\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1898 - precision: 0.7716 - recall: 0.5790 - val_loss: 0.2118 - val_precision: 0.6923 - val_recall: 0.5625\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1797 - precision: 0.8012 - recall: 0.5620 - val_loss: 0.2094 - val_precision: 0.7927 - val_recall: 0.5078\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1817 - precision: 0.7914 - recall: 0.6059 - val_loss: 0.2031 - val_precision: 0.7816 - val_recall: 0.5312\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1755 - precision: 0.7950 - recall: 0.5343 - val_loss: 0.2082 - val_precision: 0.7290 - val_recall: 0.6094\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1720 - precision: 0.7876 - recall: 0.5923 - val_loss: 0.2095 - val_precision: 0.8022 - val_recall: 0.5703\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1547 - precision: 0.8246 - recall: 0.6144 - val_loss: 0.1979 - val_precision: 0.7849 - val_recall: 0.5703\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1599 - precision: 0.8233 - recall: 0.6429 - val_loss: 0.1971 - val_precision: 0.7647 - val_recall: 0.6094\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1458 - precision: 0.8236 - recall: 0.6581 - val_loss: 0.1941 - val_precision: 0.8125 - val_recall: 0.6094\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1432 - precision: 0.8222 - recall: 0.6933 - val_loss: 0.1960 - val_precision: 0.7524 - val_recall: 0.6172\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1390 - precision: 0.8230 - recall: 0.7422 - val_loss: 0.2008 - val_precision: 0.7788 - val_recall: 0.6328\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1324 - precision: 0.8138 - recall: 0.7131 - val_loss: 0.1935 - val_precision: 0.7570 - val_recall: 0.6328\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1282 - precision: 0.8561 - recall: 0.7616 - val_loss: 0.1928 - val_precision: 0.7864 - val_recall: 0.6328\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1243 - precision: 0.8358 - recall: 0.7359 - val_loss: 0.2010 - val_precision: 0.7054 - val_recall: 0.7109\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1132 - precision: 0.8640 - recall: 0.7953 - val_loss: 0.2060 - val_precision: 0.7714 - val_recall: 0.6328\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1048 - precision: 0.8770 - recall: 0.7882 - val_loss: 0.1950 - val_precision: 0.7436 - val_recall: 0.6797\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1094 - precision: 0.8608 - recall: 0.7998 - val_loss: 0.1989 - val_precision: 0.6923 - val_recall: 0.7031\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1047 - precision: 0.8918 - recall: 0.7939 - val_loss: 0.1999 - val_precision: 0.7685 - val_recall: 0.6484\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1024 - precision: 0.8934 - recall: 0.8170 - val_loss: 0.2072 - val_precision: 0.7176 - val_recall: 0.7344\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0956 - precision: 0.8865 - recall: 0.8352 - val_loss: 0.1982 - val_precision: 0.7455 - val_recall: 0.6406\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0873 - precision: 0.9056 - recall: 0.8457 - val_loss: 0.2137 - val_precision: 0.6370 - val_recall: 0.7266\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0817 - precision: 0.9111 - recall: 0.8629 - val_loss: 0.2036 - val_precision: 0.6899 - val_recall: 0.6953\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0837 - precision: 0.9006 - recall: 0.8678 - val_loss: 0.2113 - val_precision: 0.7120 - val_recall: 0.6953\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0869 - precision: 0.9011 - recall: 0.8472 - val_loss: 0.1986 - val_precision: 0.7265 - val_recall: 0.6641\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0717 - precision: 0.9293 - recall: 0.8776 - val_loss: 0.2225 - val_precision: 0.6815 - val_recall: 0.7188\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0728 - precision: 0.9168 - recall: 0.8836 - val_loss: 0.2183 - val_precision: 0.8316 - val_recall: 0.6172\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0779 - precision: 0.9171 - recall: 0.8576 - val_loss: 0.2380 - val_precision: 0.7109 - val_recall: 0.7109\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0687 - precision: 0.9169 - recall: 0.8787 - val_loss: 0.2405 - val_precision: 0.6788 - val_recall: 0.7266\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0662 - precision: 0.9327 - recall: 0.8967 - val_loss: 0.2665 - val_precision: 0.7131 - val_recall: 0.6797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaf2a4e910>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "bilstm3 = Sequential()\n",
    "\n",
    "bilstm3.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "bilstm3.add(Bidirectional(LSTM(32)))\n",
    "bilstm3.add(Dense(32, \"relu\"))\n",
    "bilstm3.add(Dense(16, \"sigmoid\"))\n",
    "bilstm3.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "bilstm3.summary()\n",
    "\n",
    "bilstm3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "bilstm3.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bilstm3</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.751928</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.755034</td>\n",
       "      <td>0.745033</td>\n",
       "      <td>2025</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  bilstm3    0.9375    0.751928      0.75  0.753012  0.755034   0.745033   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2025  77  73  225  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm3_pred = (bilstm3.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, bilstm3_pred, 'bilstm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 38,905\n",
      "Trainable params: 38,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 6s 12ms/step - loss: 0.4615 - precision: 0.1179 - recall: 0.1397 - val_loss: 0.3740 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.3016 - precision: 0.4457 - recall: 0.1453 - val_loss: 0.2618 - val_precision: 0.6974 - val_recall: 0.4141\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.2244 - precision: 0.6666 - recall: 0.4991 - val_loss: 0.2341 - val_precision: 0.6121 - val_recall: 0.5547\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.2132 - precision: 0.6898 - recall: 0.5760 - val_loss: 0.2239 - val_precision: 0.7326 - val_recall: 0.4922\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1956 - precision: 0.7254 - recall: 0.5556 - val_loss: 0.2189 - val_precision: 0.7129 - val_recall: 0.5625\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1879 - precision: 0.7380 - recall: 0.6088 - val_loss: 0.2181 - val_precision: 0.6143 - val_recall: 0.6719\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1804 - precision: 0.7682 - recall: 0.5986 - val_loss: 0.2065 - val_precision: 0.7609 - val_recall: 0.5469\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1799 - precision: 0.7833 - recall: 0.6125 - val_loss: 0.1945 - val_precision: 0.7091 - val_recall: 0.6094\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.1748 - precision: 0.7567 - recall: 0.5593 - val_loss: 0.1991 - val_precision: 0.7524 - val_recall: 0.6172\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1682 - precision: 0.7902 - recall: 0.6363 - val_loss: 0.1939 - val_precision: 0.8068 - val_recall: 0.5547\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1539 - precision: 0.8286 - recall: 0.6394 - val_loss: 0.1850 - val_precision: 0.7476 - val_recall: 0.6016\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1581 - precision: 0.8276 - recall: 0.6520 - val_loss: 0.1845 - val_precision: 0.8043 - val_recall: 0.5781\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1432 - precision: 0.8317 - recall: 0.6724 - val_loss: 0.1820 - val_precision: 0.8041 - val_recall: 0.6094\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1407 - precision: 0.8516 - recall: 0.6950 - val_loss: 0.1814 - val_precision: 0.8316 - val_recall: 0.6172\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1414 - precision: 0.8210 - recall: 0.7154 - val_loss: 0.1724 - val_precision: 0.7845 - val_recall: 0.7109\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.1339 - precision: 0.8407 - recall: 0.7367 - val_loss: 0.1685 - val_precision: 0.8182 - val_recall: 0.7031\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1340 - precision: 0.8470 - recall: 0.7341 - val_loss: 0.1817 - val_precision: 0.8333 - val_recall: 0.6250\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1243 - precision: 0.8428 - recall: 0.7232 - val_loss: 0.1725 - val_precision: 0.7538 - val_recall: 0.7656\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1184 - precision: 0.8690 - recall: 0.7833 - val_loss: 0.1747 - val_precision: 0.7881 - val_recall: 0.7266\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1082 - precision: 0.8692 - recall: 0.7528 - val_loss: 0.1688 - val_precision: 0.7815 - val_recall: 0.7266\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1103 - precision: 0.8631 - recall: 0.7921 - val_loss: 0.1654 - val_precision: 0.8125 - val_recall: 0.7109\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1079 - precision: 0.8958 - recall: 0.7824 - val_loss: 0.1786 - val_precision: 0.8317 - val_recall: 0.6562\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.1132 - precision: 0.8791 - recall: 0.7722 - val_loss: 0.1686 - val_precision: 0.8034 - val_recall: 0.7344\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0966 - precision: 0.9042 - recall: 0.8278 - val_loss: 0.1685 - val_precision: 0.8034 - val_recall: 0.7344\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0891 - precision: 0.9105 - recall: 0.8400 - val_loss: 0.1733 - val_precision: 0.7615 - val_recall: 0.7734\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0898 - precision: 0.9006 - recall: 0.8452 - val_loss: 0.1747 - val_precision: 0.8426 - val_recall: 0.7109\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0913 - precision: 0.8902 - recall: 0.8428 - val_loss: 0.1749 - val_precision: 0.7787 - val_recall: 0.7422\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0899 - precision: 0.9068 - recall: 0.8443 - val_loss: 0.1747 - val_precision: 0.8108 - val_recall: 0.7031\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0803 - precision: 0.9131 - recall: 0.8658 - val_loss: 0.1850 - val_precision: 0.7559 - val_recall: 0.7500\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0769 - precision: 0.9292 - recall: 0.8647 - val_loss: 0.1961 - val_precision: 0.8431 - val_recall: 0.6719\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0858 - precision: 0.9005 - recall: 0.8224 - val_loss: 0.1854 - val_precision: 0.7899 - val_recall: 0.7344\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0724 - precision: 0.9192 - recall: 0.8798 - val_loss: 0.1868 - val_precision: 0.7931 - val_recall: 0.7188\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0723 - precision: 0.9313 - recall: 0.8678 - val_loss: 0.1990 - val_precision: 0.8165 - val_recall: 0.6953\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0674 - precision: 0.9289 - recall: 0.8773 - val_loss: 0.1926 - val_precision: 0.7787 - val_recall: 0.7422\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.0603 - precision: 0.9446 - recall: 0.9068 - val_loss: 0.1963 - val_precision: 0.7750 - val_recall: 0.7266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb19a43640>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "bilstm4 = Sequential()\n",
    "\n",
    "bilstm4.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "bilstm4.add(Bidirectional(LSTM(32)))\n",
    "bilstm4.add(Dense(16, \"sigmoid\"))\n",
    "bilstm4.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "bilstm4.summary()\n",
    "\n",
    "bilstm4.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "bilstm4.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bilstm4</td>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.769429</td>\n",
       "      <td>0.767947</td>\n",
       "      <td>0.770261</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.76412</td>\n",
       "      <td>2031</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  bilstm4  0.942083    0.769429  0.767947  0.770261  0.771812    0.76412   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2031  71  68  230  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm4_pred = (bilstm4.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, bilstm4_pred, 'bilstm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 26, 16)            4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,921\n",
      "Trainable params: 14,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 4s 8ms/step - loss: 0.4004 - precision: 0.3121 - recall: 0.0300 - val_loss: 0.2360 - val_precision: 0.5895 - val_recall: 0.4375\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.2199 - precision: 0.6777 - recall: 0.4483 - val_loss: 0.2114 - val_precision: 0.7937 - val_recall: 0.3906\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1680 - precision: 0.7901 - recall: 0.5387 - val_loss: 0.1846 - val_precision: 0.6718 - val_recall: 0.6875\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1685 - precision: 0.7884 - recall: 0.6144 - val_loss: 0.1668 - val_precision: 0.7589 - val_recall: 0.6641\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1432 - precision: 0.8150 - recall: 0.6832 - val_loss: 0.1602 - val_precision: 0.7381 - val_recall: 0.7266\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1426 - precision: 0.8278 - recall: 0.6834 - val_loss: 0.1680 - val_precision: 0.6918 - val_recall: 0.7891\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1333 - precision: 0.8297 - recall: 0.7134 - val_loss: 0.1482 - val_precision: 0.8725 - val_recall: 0.6953\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1229 - precision: 0.8546 - recall: 0.7550 - val_loss: 0.1409 - val_precision: 0.8130 - val_recall: 0.7812\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1182 - precision: 0.8184 - recall: 0.7324 - val_loss: 0.1494 - val_precision: 0.8738 - val_recall: 0.7031\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1177 - precision: 0.8539 - recall: 0.7412 - val_loss: 0.1487 - val_precision: 0.9149 - val_recall: 0.6719\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1073 - precision: 0.8717 - recall: 0.7526 - val_loss: 0.1455 - val_precision: 0.7967 - val_recall: 0.7656\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1069 - precision: 0.8636 - recall: 0.7705 - val_loss: 0.1517 - val_precision: 0.7969 - val_recall: 0.7969\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1026 - precision: 0.8583 - recall: 0.7847 - val_loss: 0.1443 - val_precision: 0.8807 - val_recall: 0.7500\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0923 - precision: 0.8830 - recall: 0.8096 - val_loss: 0.1581 - val_precision: 0.8426 - val_recall: 0.7109\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0928 - precision: 0.8780 - recall: 0.8204 - val_loss: 0.1475 - val_precision: 0.8291 - val_recall: 0.7578\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0869 - precision: 0.8846 - recall: 0.8125 - val_loss: 0.1470 - val_precision: 0.8033 - val_recall: 0.7656\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0869 - precision: 0.9183 - recall: 0.8253 - val_loss: 0.1762 - val_precision: 0.8830 - val_recall: 0.6484\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0923 - precision: 0.8790 - recall: 0.7855 - val_loss: 0.1683 - val_precision: 0.7429 - val_recall: 0.8125\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0777 - precision: 0.8769 - recall: 0.8548 - val_loss: 0.1999 - val_precision: 0.9481 - val_recall: 0.5703\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0782 - precision: 0.9034 - recall: 0.8009 - val_loss: 0.1623 - val_precision: 0.7698 - val_recall: 0.7578\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0718 - precision: 0.9124 - recall: 0.8668 - val_loss: 0.1569 - val_precision: 0.8257 - val_recall: 0.7031\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0726 - precision: 0.8979 - recall: 0.8510 - val_loss: 0.1790 - val_precision: 0.8617 - val_recall: 0.6328\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0764 - precision: 0.9013 - recall: 0.8320 - val_loss: 0.1726 - val_precision: 0.7687 - val_recall: 0.8047\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0691 - precision: 0.9136 - recall: 0.8649 - val_loss: 0.1738 - val_precision: 0.8037 - val_recall: 0.6719\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0634 - precision: 0.9105 - recall: 0.8765 - val_loss: 0.1618 - val_precision: 0.7778 - val_recall: 0.7656\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0576 - precision: 0.9270 - recall: 0.9060 - val_loss: 0.1685 - val_precision: 0.7931 - val_recall: 0.7188\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0618 - precision: 0.9145 - recall: 0.8843 - val_loss: 0.1927 - val_precision: 0.7333 - val_recall: 0.7734\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0659 - precision: 0.9034 - recall: 0.8786 - val_loss: 0.1803 - val_precision: 0.7869 - val_recall: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb1f730100>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "convlstm0 = Sequential()\n",
    "\n",
    "convlstm0.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "convlstm0.add(Conv1D(16, 3, activation=\"relu\"))\n",
    "convlstm0.add(MaxPooling1D((2)))\n",
    "convlstm0.add(LSTM(32))\n",
    "convlstm0.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "convlstm0.summary()\n",
    "\n",
    "convlstm0.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "convlstm0.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convlstm0</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.77961</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.788436</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>2012</td>\n",
       "      <td>90</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  convlstm0  0.938333     0.77961  0.764331  0.788436  0.805369   0.727273   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2012  90  58  240  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm0_pred = (convlstm0.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, convlstm0_pred, 'convlstm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 26, 16)            4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,433\n",
      "Trainable params: 15,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 4s 8ms/step - loss: 0.3732 - precision: 0.2604 - recall: 0.0291 - val_loss: 0.2496 - val_precision: 0.6222 - val_recall: 0.4375\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.2275 - precision: 0.6563 - recall: 0.4480 - val_loss: 0.2229 - val_precision: 0.8246 - val_recall: 0.3672\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1753 - precision: 0.7637 - recall: 0.5634 - val_loss: 0.1976 - val_precision: 0.6618 - val_recall: 0.7031\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1721 - precision: 0.7667 - recall: 0.6446 - val_loss: 0.1767 - val_precision: 0.7302 - val_recall: 0.7188\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1482 - precision: 0.7906 - recall: 0.6963 - val_loss: 0.1737 - val_precision: 0.7739 - val_recall: 0.6953\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1446 - precision: 0.8121 - recall: 0.6996 - val_loss: 0.1714 - val_precision: 0.7185 - val_recall: 0.7578\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1324 - precision: 0.8234 - recall: 0.7368 - val_loss: 0.1638 - val_precision: 0.8673 - val_recall: 0.6641\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1237 - precision: 0.8465 - recall: 0.7737 - val_loss: 0.1559 - val_precision: 0.7481 - val_recall: 0.7656\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1208 - precision: 0.8055 - recall: 0.7549 - val_loss: 0.1632 - val_precision: 0.8812 - val_recall: 0.6953\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1224 - precision: 0.8345 - recall: 0.7642 - val_loss: 0.1702 - val_precision: 0.8925 - val_recall: 0.6484\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1154 - precision: 0.8613 - recall: 0.7650 - val_loss: 0.1453 - val_precision: 0.8167 - val_recall: 0.7656\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1157 - precision: 0.8511 - recall: 0.7745 - val_loss: 0.1492 - val_precision: 0.8017 - val_recall: 0.7578\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1114 - precision: 0.8562 - recall: 0.7911 - val_loss: 0.1511 - val_precision: 0.8049 - val_recall: 0.7734\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1014 - precision: 0.8628 - recall: 0.8240 - val_loss: 0.1439 - val_precision: 0.8571 - val_recall: 0.7500\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1019 - precision: 0.8612 - recall: 0.8247 - val_loss: 0.1411 - val_precision: 0.8246 - val_recall: 0.7344\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0967 - precision: 0.8805 - recall: 0.8197 - val_loss: 0.1466 - val_precision: 0.8407 - val_recall: 0.7422\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.1038 - precision: 0.8887 - recall: 0.8110 - val_loss: 0.1608 - val_precision: 0.8571 - val_recall: 0.7031\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0997 - precision: 0.8665 - recall: 0.7937 - val_loss: 0.1529 - val_precision: 0.7907 - val_recall: 0.7969\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0907 - precision: 0.8809 - recall: 0.8349 - val_loss: 0.1762 - val_precision: 0.8800 - val_recall: 0.6875\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0790 - precision: 0.8962 - recall: 0.8280 - val_loss: 0.1670 - val_precision: 0.8585 - val_recall: 0.7109\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0815 - precision: 0.8940 - recall: 0.8498 - val_loss: 0.1514 - val_precision: 0.8167 - val_recall: 0.7656\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0782 - precision: 0.9155 - recall: 0.8678 - val_loss: 0.1744 - val_precision: 0.8854 - val_recall: 0.6641\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0836 - precision: 0.8994 - recall: 0.8571 - val_loss: 0.1496 - val_precision: 0.8361 - val_recall: 0.7969\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0680 - precision: 0.9006 - recall: 0.8986 - val_loss: 0.1525 - val_precision: 0.8182 - val_recall: 0.7734\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0645 - precision: 0.9221 - recall: 0.8900 - val_loss: 0.1483 - val_precision: 0.8403 - val_recall: 0.7812\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0574 - precision: 0.9353 - recall: 0.9076 - val_loss: 0.1555 - val_precision: 0.8496 - val_recall: 0.7500\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0618 - precision: 0.9311 - recall: 0.9023 - val_loss: 0.1674 - val_precision: 0.8062 - val_recall: 0.8125\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0609 - precision: 0.9227 - recall: 0.9026 - val_loss: 0.1587 - val_precision: 0.8305 - val_recall: 0.7656\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0529 - precision: 0.9431 - recall: 0.9196 - val_loss: 0.1648 - val_precision: 0.8333 - val_recall: 0.7812\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0493 - precision: 0.9340 - recall: 0.9252 - val_loss: 0.1697 - val_precision: 0.8962 - val_recall: 0.7422\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0604 - precision: 0.9337 - recall: 0.8922 - val_loss: 0.1764 - val_precision: 0.8080 - val_recall: 0.7891\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0460 - precision: 0.9424 - recall: 0.9217 - val_loss: 0.1903 - val_precision: 0.8545 - val_recall: 0.7344\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0498 - precision: 0.9435 - recall: 0.9158 - val_loss: 0.1939 - val_precision: 0.9091 - val_recall: 0.7031\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0422 - precision: 0.9550 - recall: 0.9202 - val_loss: 0.1846 - val_precision: 0.8305 - val_recall: 0.7656\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0397 - precision: 0.9529 - recall: 0.9399 - val_loss: 0.1823 - val_precision: 0.8403 - val_recall: 0.7812\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0316 - precision: 0.9568 - recall: 0.9583 - val_loss: 0.1883 - val_precision: 0.8846 - val_recall: 0.7188\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0446 - precision: 0.9554 - recall: 0.9267 - val_loss: 0.1799 - val_precision: 0.8125 - val_recall: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb25d5d190>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "convlstm1 = Sequential()\n",
    "\n",
    "convlstm1.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "convlstm1.add(Conv1D(16, 3, activation=\"relu\"))\n",
    "convlstm1.add(MaxPooling1D((2)))\n",
    "convlstm1.add(LSTM(32))\n",
    "convlstm1.add(Dense(16, \"sigmoid\"))\n",
    "convlstm1.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "convlstm1.summary()\n",
    "\n",
    "convlstm1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "convlstm1.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convlstm1</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.766617</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.775296</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>2008</td>\n",
       "      <td>94</td>\n",
       "      <td>62</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  convlstm1     0.935    0.766617  0.751592  0.775296  0.791946   0.715152   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2008  94  62  236  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm1_pred = (convlstm1.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, convlstm1_pred, 'convlstm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 26, 16)            4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 13, 32)            6272      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 18,313\n",
      "Trainable params: 18,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 6s 11ms/step - loss: 0.4666 - precision: 0.1116 - recall: 0.1099 - val_loss: 0.3912 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.3329 - precision: 0.3587 - recall: 0.1005 - val_loss: 0.2651 - val_precision: 0.7679 - val_recall: 0.3359\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.2041 - precision: 0.7168 - recall: 0.5395 - val_loss: 0.2104 - val_precision: 0.6696 - val_recall: 0.6016\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1855 - precision: 0.7511 - recall: 0.6213 - val_loss: 0.1988 - val_precision: 0.6528 - val_recall: 0.7344\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1633 - precision: 0.7700 - recall: 0.6771 - val_loss: 0.1888 - val_precision: 0.7177 - val_recall: 0.6953\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1522 - precision: 0.8037 - recall: 0.6866 - val_loss: 0.2016 - val_precision: 0.6190 - val_recall: 0.8125\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1463 - precision: 0.7974 - recall: 0.7134 - val_loss: 0.1696 - val_precision: 0.8478 - val_recall: 0.6094\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1320 - precision: 0.8340 - recall: 0.7643 - val_loss: 0.1604 - val_precision: 0.7807 - val_recall: 0.6953\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1289 - precision: 0.8209 - recall: 0.7456 - val_loss: 0.1736 - val_precision: 0.8400 - val_recall: 0.6562\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1281 - precision: 0.8298 - recall: 0.7529 - val_loss: 0.1809 - val_precision: 0.8889 - val_recall: 0.6250\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1195 - precision: 0.8683 - recall: 0.7553 - val_loss: 0.1745 - val_precision: 0.6993 - val_recall: 0.7812\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1248 - precision: 0.8361 - recall: 0.7642 - val_loss: 0.1647 - val_precision: 0.8660 - val_recall: 0.6562\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1115 - precision: 0.8630 - recall: 0.7812 - val_loss: 0.1552 - val_precision: 0.8174 - val_recall: 0.7344\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1081 - precision: 0.8688 - recall: 0.7991 - val_loss: 0.1543 - val_precision: 0.8151 - val_recall: 0.7578\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1070 - precision: 0.8648 - recall: 0.8173 - val_loss: 0.1548 - val_precision: 0.8091 - val_recall: 0.6953\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.1031 - precision: 0.8809 - recall: 0.8203 - val_loss: 0.1520 - val_precision: 0.8598 - val_recall: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaf29871f0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "convlstm2 = Sequential()\n",
    "\n",
    "convlstm2.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "convlstm2.add(Conv1D(16, 3, activation=\"relu\"))\n",
    "convlstm2.add(MaxPooling1D((2)))\n",
    "convlstm2.add(LSTM(32, return_sequences=True))\n",
    "convlstm2.add(LSTM(16))\n",
    "convlstm2.add(Dense(16, \"sigmoid\"))\n",
    "convlstm2.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "convlstm2.summary()\n",
    "\n",
    "convlstm2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "convlstm2.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convlstm2</td>\n",
       "      <td>0.924583</td>\n",
       "      <td>0.791802</td>\n",
       "      <td>0.743989</td>\n",
       "      <td>0.821362</td>\n",
       "      <td>0.88255</td>\n",
       "      <td>0.643032</td>\n",
       "      <td>1956</td>\n",
       "      <td>146</td>\n",
       "      <td>35</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  accuracy  F1.5-score  F1-score  F2-score   recall  precision  \\\n",
       "0  convlstm2  0.924583    0.791802  0.743989  0.821362  0.88255   0.643032   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1956  146  35  263  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm2_pred = (convlstm2.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, convlstm2_pred, 'convlstm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/convlstm2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/convlstm2/assets\n"
     ]
    }
   ],
   "source": [
    "convlstm2.save('models/convlstm2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 26, 16)            4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                12544     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 23,785\n",
      "Trainable params: 23,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 6s 10ms/step - loss: 0.4109 - precision: 0.2247 - recall: 0.0091 - val_loss: 0.2717 - val_precision: 0.5974 - val_recall: 0.3594\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.2375 - precision: 0.6395 - recall: 0.4826 - val_loss: 0.2327 - val_precision: 0.7818 - val_recall: 0.3359\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1872 - precision: 0.7384 - recall: 0.5401 - val_loss: 0.2079 - val_precision: 0.6587 - val_recall: 0.6484\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1781 - precision: 0.7816 - recall: 0.6328 - val_loss: 0.1950 - val_precision: 0.6947 - val_recall: 0.7109\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1567 - precision: 0.7979 - recall: 0.6715 - val_loss: 0.1789 - val_precision: 0.7603 - val_recall: 0.7188\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1454 - precision: 0.8446 - recall: 0.6902 - val_loss: 0.1787 - val_precision: 0.7231 - val_recall: 0.7344\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1344 - precision: 0.8393 - recall: 0.7280 - val_loss: 0.1662 - val_precision: 0.8851 - val_recall: 0.6016\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1245 - precision: 0.8695 - recall: 0.7526 - val_loss: 0.1557 - val_precision: 0.7899 - val_recall: 0.7344\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1180 - precision: 0.8371 - recall: 0.7463 - val_loss: 0.1812 - val_precision: 0.8696 - val_recall: 0.6250\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1187 - precision: 0.8576 - recall: 0.7658 - val_loss: 0.1679 - val_precision: 0.8587 - val_recall: 0.6172\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1097 - precision: 0.8759 - recall: 0.7560 - val_loss: 0.1625 - val_precision: 0.8087 - val_recall: 0.7266\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1110 - precision: 0.8757 - recall: 0.7700 - val_loss: 0.1628 - val_precision: 0.7931 - val_recall: 0.7188\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1052 - precision: 0.8665 - recall: 0.7644 - val_loss: 0.1705 - val_precision: 0.7851 - val_recall: 0.7422\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1013 - precision: 0.8880 - recall: 0.7916 - val_loss: 0.1545 - val_precision: 0.8318 - val_recall: 0.6953\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1007 - precision: 0.8680 - recall: 0.8013 - val_loss: 0.1661 - val_precision: 0.8103 - val_recall: 0.7344\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0972 - precision: 0.8888 - recall: 0.8042 - val_loss: 0.1555 - val_precision: 0.8571 - val_recall: 0.7031\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1051 - precision: 0.9005 - recall: 0.8044 - val_loss: 0.1546 - val_precision: 0.8319 - val_recall: 0.7344\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0935 - precision: 0.8911 - recall: 0.7997 - val_loss: 0.1627 - val_precision: 0.7717 - val_recall: 0.7656\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0864 - precision: 0.9101 - recall: 0.8331 - val_loss: 0.1865 - val_precision: 0.9059 - val_recall: 0.6016\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0808 - precision: 0.9190 - recall: 0.8188 - val_loss: 0.1729 - val_precision: 0.8571 - val_recall: 0.7031\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0819 - precision: 0.9095 - recall: 0.8270 - val_loss: 0.1729 - val_precision: 0.7600 - val_recall: 0.7422\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0776 - precision: 0.9181 - recall: 0.8507 - val_loss: 0.1931 - val_precision: 0.8913 - val_recall: 0.6406\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0828 - precision: 0.9064 - recall: 0.8314 - val_loss: 0.1765 - val_precision: 0.7407 - val_recall: 0.7812\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0781 - precision: 0.8940 - recall: 0.8516 - val_loss: 0.1887 - val_precision: 0.8500 - val_recall: 0.6641\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0629 - precision: 0.9379 - recall: 0.8794 - val_loss: 0.1638 - val_precision: 0.7931 - val_recall: 0.7188\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0565 - precision: 0.9347 - recall: 0.8968 - val_loss: 0.1760 - val_precision: 0.7444 - val_recall: 0.7734\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0661 - precision: 0.9163 - recall: 0.8798 - val_loss: 0.1792 - val_precision: 0.8230 - val_recall: 0.7266\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0664 - precision: 0.9210 - recall: 0.8774 - val_loss: 0.1845 - val_precision: 0.8125 - val_recall: 0.7109\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0494 - precision: 0.9434 - recall: 0.9158 - val_loss: 0.1895 - val_precision: 0.7462 - val_recall: 0.7578\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0534 - precision: 0.9356 - recall: 0.9037 - val_loss: 0.1867 - val_precision: 0.7742 - val_recall: 0.7500\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0587 - precision: 0.9286 - recall: 0.9025 - val_loss: 0.1860 - val_precision: 0.7724 - val_recall: 0.7422\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0491 - precision: 0.9340 - recall: 0.9144 - val_loss: 0.2069 - val_precision: 0.8198 - val_recall: 0.7109\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0445 - precision: 0.9537 - recall: 0.9291 - val_loss: 0.2091 - val_precision: 0.8182 - val_recall: 0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda47725ee0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "convbilstm0 = Sequential()\n",
    "\n",
    "convbilstm0.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "convbilstm0.add(Conv1D(16, 3, activation=\"relu\"))\n",
    "convbilstm0.add(MaxPooling1D((2)))\n",
    "convbilstm0.add(Bidirectional(LSTM(32)))\n",
    "convbilstm0.add(Dense(32, \"relu\"))\n",
    "convbilstm0.add(Dense(16, \"sigmoid\"))\n",
    "convbilstm0.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "convbilstm0.summary()\n",
    "\n",
    "convbilstm0.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "convbilstm0.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convbilstm0</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.794551</td>\n",
       "      <td>0.770898</td>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.83557</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>2003</td>\n",
       "      <td>99</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  accuracy  F1.5-score  F1-score  F2-score   recall  precision  \\\n",
       "0  convbilstm0  0.938333    0.794551  0.770898  0.808442  0.83557   0.715517   \n",
       "\n",
       "     tn  fp  fn   tp  \n",
       "0  2003  99  49  249  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convbilstm0_pred = (convbilstm0.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, convbilstm0_pred, 'convbilstm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/convbilstm0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/convbilstm0/assets\n"
     ]
    }
   ],
   "source": [
    "convbilstm0.save('models/convbilstm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 100)           3800      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 26, 16)            4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                12544     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 22,217\n",
      "Trainable params: 22,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 5s 9ms/step - loss: 0.3544 - precision: 0.3843 - recall: 0.0889 - val_loss: 0.2566 - val_precision: 0.5918 - val_recall: 0.4531\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.2251 - precision: 0.6490 - recall: 0.5359 - val_loss: 0.2218 - val_precision: 0.7656 - val_recall: 0.3828\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1809 - precision: 0.7480 - recall: 0.5875 - val_loss: 0.1942 - val_precision: 0.7119 - val_recall: 0.6562\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.1784 - precision: 0.7914 - recall: 0.6119 - val_loss: 0.1858 - val_precision: 0.7167 - val_recall: 0.6719\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1553 - precision: 0.8140 - recall: 0.6613 - val_loss: 0.1814 - val_precision: 0.7355 - val_recall: 0.6953\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1476 - precision: 0.8354 - recall: 0.6701 - val_loss: 0.1936 - val_precision: 0.6478 - val_recall: 0.8047\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1393 - precision: 0.8179 - recall: 0.7091 - val_loss: 0.1672 - val_precision: 0.8478 - val_recall: 0.6094\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1328 - precision: 0.8671 - recall: 0.7313 - val_loss: 0.1511 - val_precision: 0.8000 - val_recall: 0.7188\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1291 - precision: 0.8254 - recall: 0.7152 - val_loss: 0.1612 - val_precision: 0.8241 - val_recall: 0.6953\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1259 - precision: 0.8556 - recall: 0.7450 - val_loss: 0.1530 - val_precision: 0.8673 - val_recall: 0.6641\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1153 - precision: 0.8682 - recall: 0.7380 - val_loss: 0.1425 - val_precision: 0.8374 - val_recall: 0.8047\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1188 - precision: 0.8501 - recall: 0.7592 - val_loss: 0.1597 - val_precision: 0.8476 - val_recall: 0.6953\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1131 - precision: 0.8753 - recall: 0.7673 - val_loss: 0.1492 - val_precision: 0.8571 - val_recall: 0.7031\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1043 - precision: 0.8864 - recall: 0.7854 - val_loss: 0.1431 - val_precision: 0.8785 - val_recall: 0.7344\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.1045 - precision: 0.8688 - recall: 0.8102 - val_loss: 0.1440 - val_precision: 0.8250 - val_recall: 0.7734\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0967 - precision: 0.8848 - recall: 0.8044 - val_loss: 0.1528 - val_precision: 0.8197 - val_recall: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb5d190f70>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "convbilstm1 = Sequential()\n",
    "\n",
    "convbilstm1.add(Embedding(vocab_size,\n",
    "                   output_dim=100,\n",
    "                   input_length=maxlen))\n",
    "convbilstm1.add(Conv1D(16, 3, activation=\"relu\"))\n",
    "convbilstm1.add(MaxPooling1D((2)))\n",
    "convbilstm1.add(Bidirectional(LSTM(32)))\n",
    "convbilstm1.add(Dense(16, \"sigmoid\"))\n",
    "convbilstm1.add(Dense(1, \"sigmoid\"))\n",
    "\n",
    "convbilstm1.summary()\n",
    "\n",
    "convbilstm1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "convbilstm1.fit(Xtok_train, ytok_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_split=0.1, \n",
    "          callbacks=[early_stopping3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convbilstm1</td>\n",
       "      <td>0.920417</td>\n",
       "      <td>0.74241</td>\n",
       "      <td>0.712782</td>\n",
       "      <td>0.760103</td>\n",
       "      <td>0.795302</td>\n",
       "      <td>0.645777</td>\n",
       "      <td>1972</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  accuracy  F1.5-score  F1-score  F2-score    recall  precision  \\\n",
       "0  convbilstm1  0.920417     0.74241  0.712782  0.760103  0.795302   0.645777   \n",
       "\n",
       "     tn   fp  fn   tp  \n",
       "0  1972  130  61  237  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convbilstm1_pred = (convbilstm1.predict(Xtok_test) > 0.5).astype(\"int32\")\n",
    "save_model_results(y_test, convbilstm1_pred, 'convbilstm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = ['results/baseline_210228_2044.csv',\n",
    "                 'results/bilstm0_210301_0103.csv',\n",
    "                 'results/bilstm1_210301_0114.csv',\n",
    "                 'results/bilstm1_210301_0125.csv',\n",
    "                 'results/bilstm2_210301_0129.csv',\n",
    "                 'results/bilstm3_210301_0131.csv',\n",
    "                 'results/bilstm4_210301_0133.csv',\n",
    "                 'results/cld3_df.csv',\n",
    "                 'results/convbilstm0_210301_0140.csv',\n",
    "                 'results/convbilstm1_210301_0142.csv',\n",
    "                 'results/convlstm0_210301_0135.csv',\n",
    "                 'results/convlstm1_210301_0136.csv',\n",
    "                 'results/convlstm2_210301_0137.csv',\n",
    "                 'results/dtc_210301_2159.csv',\n",
    "                 'results/emb0_210301_0027.csv',\n",
    "                 'results/emb1_210301_0029.csv',\n",
    "                 'results/emb2_210301_0030.csv',\n",
    "                 'results/emb3_210301_0032.csv',\n",
    "                 'results/fasttext_df.csv',\n",
    "                 'results/knn_210301_2205.csv',\n",
    "                 'results/logreg_210301_0323.csv',\n",
    "                 'results/lstm0_210301_0039.csv',\n",
    "                 'results/lstm1_210301_0047.csv',\n",
    "                 'results/lstm2_210301_0053.csv',\n",
    "                 'results/lstm3_210301_0056.csv',\n",
    "                 'results/lstm4_210301_0058.csv',\n",
    "                 'results/mlp0_210301_0001.csv',\n",
    "                 'results/mlp0maxabs_210301_0004.csv',\n",
    "                 'results/mlp0scaled_210301_0002.csv',\n",
    "                 'results/mlp1_210301_0005.csv',\n",
    "                 'results/mlp1maxabs_210301_0009.csv',\n",
    "                 'results/mlp1scaled_210301_0007.csv',\n",
    "                 'results/mlp2_210301_0009.csv',\n",
    "                 'results/mlp2maxabs_210301_0012.csv',\n",
    "                 'results/mlp2scaled_210301_0011.csv',\n",
    "                 'results/mlp3_210301_0149.csv',\n",
    "                 'results/mlp3scaled_210301_0148.csv',\n",
    "                 'results/mlp4_210301_0151.csv',\n",
    "                 'results/mlp4scaled_210301_0151.csv',\n",
    "                 'results/mlp5_210301_0154.csv',\n",
    "                 'results/mlp5scaled_210301_0154.csv',\n",
    "                 'results/ridge_210301_0324.csv',\n",
    "                 'results/rfc_210301_2200.csv',\n",
    "                 'results/smpl0_210301_0034.csv',\n",
    "                 'results/smpl1_210301_0036.csv',\n",
    "                 'results/svm_210301_2202.csv',\n",
    "                 'results/textcat_df.csv']\n",
    "\n",
    "df_list = []\n",
    "for file in csv_list:\n",
    "    df_list.append(pd.read_csv(file, index_col=False))\n",
    "\n",
    "combined_results = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "combined_results = combined_results.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "combined_results = combined_results.sort_values(by=['F1.5-score'], ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1.5-score</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convbilstm0</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.794551</td>\n",
       "      <td>0.770898</td>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.835570</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>2003</td>\n",
       "      <td>99</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convlstm2</td>\n",
       "      <td>0.924583</td>\n",
       "      <td>0.791802</td>\n",
       "      <td>0.743989</td>\n",
       "      <td>0.821362</td>\n",
       "      <td>0.882550</td>\n",
       "      <td>0.643032</td>\n",
       "      <td>1956</td>\n",
       "      <td>146</td>\n",
       "      <td>35</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>convlstm0</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.779610</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.788436</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>2012</td>\n",
       "      <td>90</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm3</td>\n",
       "      <td>0.937917</td>\n",
       "      <td>0.778832</td>\n",
       "      <td>0.763116</td>\n",
       "      <td>0.787919</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>2011</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.776996</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.784443</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.732308</td>\n",
       "      <td>2015</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>emb2</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>0.773580</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.785528</td>\n",
       "      <td>0.808725</td>\n",
       "      <td>0.704678</td>\n",
       "      <td>2001</td>\n",
       "      <td>101</td>\n",
       "      <td>57</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bilstm4</td>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.769429</td>\n",
       "      <td>0.767947</td>\n",
       "      <td>0.770261</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.764120</td>\n",
       "      <td>2031</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>convlstm1</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.766617</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.775296</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>2008</td>\n",
       "      <td>94</td>\n",
       "      <td>62</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.763742</td>\n",
       "      <td>0.752827</td>\n",
       "      <td>0.769993</td>\n",
       "      <td>0.781879</td>\n",
       "      <td>0.725857</td>\n",
       "      <td>2014</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlp2scaled</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.768476</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>2000</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emb3</td>\n",
       "      <td>0.926250</td>\n",
       "      <td>0.757649</td>\n",
       "      <td>0.730594</td>\n",
       "      <td>0.773694</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>1983</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bilstm0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.751928</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.755034</td>\n",
       "      <td>0.745033</td>\n",
       "      <td>2025</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bilstm3</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.751928</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.755034</td>\n",
       "      <td>0.745033</td>\n",
       "      <td>2025</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lstm1</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>0.751140</td>\n",
       "      <td>0.742671</td>\n",
       "      <td>0.755968</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>2014</td>\n",
       "      <td>88</td>\n",
       "      <td>70</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lstm2</td>\n",
       "      <td>0.929583</td>\n",
       "      <td>0.744622</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.752794</td>\n",
       "      <td>0.768456</td>\n",
       "      <td>0.696049</td>\n",
       "      <td>2002</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>smpl0</td>\n",
       "      <td>0.927917</td>\n",
       "      <td>0.743411</td>\n",
       "      <td>0.726698</td>\n",
       "      <td>0.753111</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>1997</td>\n",
       "      <td>105</td>\n",
       "      <td>68</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lstm0</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.742586</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.656425</td>\n",
       "      <td>1979</td>\n",
       "      <td>123</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>convbilstm1</td>\n",
       "      <td>0.920417</td>\n",
       "      <td>0.742410</td>\n",
       "      <td>0.712782</td>\n",
       "      <td>0.760103</td>\n",
       "      <td>0.795302</td>\n",
       "      <td>0.645777</td>\n",
       "      <td>1972</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lstm4</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.737659</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.741356</td>\n",
       "      <td>0.748322</td>\n",
       "      <td>0.714744</td>\n",
       "      <td>2013</td>\n",
       "      <td>89</td>\n",
       "      <td>75</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bilstm2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.737045</td>\n",
       "      <td>0.734219</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.741611</td>\n",
       "      <td>0.726974</td>\n",
       "      <td>2019</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bilstm1</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.735139</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.730299</td>\n",
       "      <td>0.721477</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>2037</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bilstm1</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.733263</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.727891</td>\n",
       "      <td>0.718121</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>2038</td>\n",
       "      <td>64</td>\n",
       "      <td>84</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mlp5</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.732589</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.725034</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>2044</td>\n",
       "      <td>58</td>\n",
       "      <td>86</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>smpl1</td>\n",
       "      <td>0.925417</td>\n",
       "      <td>0.728364</td>\n",
       "      <td>0.714514</td>\n",
       "      <td>0.736358</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>1997</td>\n",
       "      <td>105</td>\n",
       "      <td>74</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mlp0maxabs</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.728056</td>\n",
       "      <td>0.748201</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>2052</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mlp3</td>\n",
       "      <td>0.937917</td>\n",
       "      <td>0.726815</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.708054</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>2040</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mlp2</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.726450</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.780669</td>\n",
       "      <td>2043</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mlp0</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.722998</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.712810</td>\n",
       "      <td>0.694631</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>2049</td>\n",
       "      <td>53</td>\n",
       "      <td>91</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mlp2maxabs</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.714825</td>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>2049</td>\n",
       "      <td>53</td>\n",
       "      <td>94</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mlp1</td>\n",
       "      <td>0.939583</td>\n",
       "      <td>0.712425</td>\n",
       "      <td>0.735883</td>\n",
       "      <td>0.699931</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>2053</td>\n",
       "      <td>49</td>\n",
       "      <td>96</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mlp3scaled</td>\n",
       "      <td>0.932083</td>\n",
       "      <td>0.712375</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.708475</td>\n",
       "      <td>0.701342</td>\n",
       "      <td>0.738516</td>\n",
       "      <td>2028</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mlp4scaled</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.710141</td>\n",
       "      <td>0.715753</td>\n",
       "      <td>0.707037</td>\n",
       "      <td>0.701342</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>2025</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mlp1maxabs</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.709669</td>\n",
       "      <td>0.733577</td>\n",
       "      <td>0.696949</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>2053</td>\n",
       "      <td>49</td>\n",
       "      <td>97</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mlp0scaled</td>\n",
       "      <td>0.919167</td>\n",
       "      <td>0.703055</td>\n",
       "      <td>0.690096</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>1990</td>\n",
       "      <td>112</td>\n",
       "      <td>82</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.933750</td>\n",
       "      <td>0.683651</td>\n",
       "      <td>0.708257</td>\n",
       "      <td>0.670605</td>\n",
       "      <td>0.647651</td>\n",
       "      <td>0.781377</td>\n",
       "      <td>2048</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mlp1scaled</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.678287</td>\n",
       "      <td>0.640805</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.748322</td>\n",
       "      <td>0.560302</td>\n",
       "      <td>1927</td>\n",
       "      <td>175</td>\n",
       "      <td>75</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>emb0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.655837</td>\n",
       "      <td>0.665505</td>\n",
       "      <td>0.650545</td>\n",
       "      <td>0.640940</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>2017</td>\n",
       "      <td>85</td>\n",
       "      <td>107</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mlp4</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.647454</td>\n",
       "      <td>0.683301</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>2057</td>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.641373</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.615994</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>2077</td>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dtc</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.624789</td>\n",
       "      <td>0.661509</td>\n",
       "      <td>0.605953</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>2054</td>\n",
       "      <td>48</td>\n",
       "      <td>127</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rfc</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.623027</td>\n",
       "      <td>0.679089</td>\n",
       "      <td>0.595497</td>\n",
       "      <td>0.550336</td>\n",
       "      <td>0.886486</td>\n",
       "      <td>2081</td>\n",
       "      <td>21</td>\n",
       "      <td>134</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mlp5scaled</td>\n",
       "      <td>0.782083</td>\n",
       "      <td>0.621076</td>\n",
       "      <td>0.514392</td>\n",
       "      <td>0.702689</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.355584</td>\n",
       "      <td>1600</td>\n",
       "      <td>502</td>\n",
       "      <td>21</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>textcat</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.619680</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>1584</td>\n",
       "      <td>518</td>\n",
       "      <td>18</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>emb1</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.601399</td>\n",
       "      <td>0.617594</td>\n",
       "      <td>0.592695</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.664093</td>\n",
       "      <td>2015</td>\n",
       "      <td>87</td>\n",
       "      <td>126</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.848750</td>\n",
       "      <td>0.601285</td>\n",
       "      <td>0.543396</td>\n",
       "      <td>0.639432</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>1821</td>\n",
       "      <td>281</td>\n",
       "      <td>82</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>0.767917</td>\n",
       "      <td>0.591516</td>\n",
       "      <td>0.488522</td>\n",
       "      <td>0.670701</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.336283</td>\n",
       "      <td>1577</td>\n",
       "      <td>525</td>\n",
       "      <td>32</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cld3</td>\n",
       "      <td>0.580833</td>\n",
       "      <td>0.473001</td>\n",
       "      <td>0.360051</td>\n",
       "      <td>0.573804</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.222135</td>\n",
       "      <td>1111</td>\n",
       "      <td>991</td>\n",
       "      <td>15</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy  F1.5-score  F1-score  F2-score    recall  \\\n",
       "0   convbilstm0  0.938333    0.794551  0.770898  0.808442  0.835570   \n",
       "1     convlstm2  0.924583    0.791802  0.743989  0.821362  0.882550   \n",
       "2     convlstm0  0.938333    0.779610  0.764331  0.788436  0.805369   \n",
       "3         lstm3  0.937917    0.778832  0.763116  0.787919  0.805369   \n",
       "4         ridge  0.938750    0.776996  0.764045  0.784443  0.798658   \n",
       "5          emb2  0.934167    0.773580  0.753125  0.785528  0.808725   \n",
       "6       bilstm4  0.942083    0.769429  0.767947  0.770261  0.771812   \n",
       "7     convlstm1  0.935000    0.766617  0.751592  0.775296  0.791946   \n",
       "8        logreg  0.936250    0.763742  0.752827  0.769993  0.781879   \n",
       "9    mlp2scaled  0.931250    0.758065  0.740157  0.768476  0.788591   \n",
       "10         emb3  0.926250    0.757649  0.730594  0.773694  0.805369   \n",
       "11      bilstm0  0.937500    0.751928  0.750000  0.753012  0.755034   \n",
       "12      bilstm3  0.937500    0.751928  0.750000  0.753012  0.755034   \n",
       "13        lstm1  0.934167    0.751140  0.742671  0.755968  0.765101   \n",
       "14        lstm2  0.929583    0.744622  0.730463  0.752794  0.768456   \n",
       "15        smpl0  0.927917    0.743411  0.726698  0.753111  0.771812   \n",
       "16        lstm0  0.922500    0.742586  0.716463  0.758065  0.788591   \n",
       "17  convbilstm1  0.920417    0.742410  0.712782  0.760103  0.795302   \n",
       "18        lstm4  0.931667    0.737659  0.731148  0.741356  0.748322   \n",
       "19      bilstm2  0.933333    0.737045  0.734219  0.738636  0.741611   \n",
       "20      bilstm1  0.938333    0.735139  0.743945  0.730299  0.721477   \n",
       "21      bilstm1  0.938333    0.733263  0.743056  0.727891  0.718121   \n",
       "22         mlp5  0.940000    0.732589  0.746479  0.725034  0.711409   \n",
       "23        smpl1  0.925417    0.728364  0.714514  0.736358  0.751678   \n",
       "24   mlp0maxabs  0.941667    0.728056  0.748201  0.717241  0.697987   \n",
       "25         mlp3  0.937917    0.726815  0.739054  0.720137  0.708054   \n",
       "26         mlp2  0.938750    0.726450  0.740741  0.718686  0.704698   \n",
       "27         mlp0  0.940000    0.722998  0.741935  0.712810  0.694631   \n",
       "28   mlp2maxabs  0.938750    0.714825  0.735135  0.703934  0.684564   \n",
       "29         mlp1  0.939583    0.712425  0.735883  0.699931  0.677852   \n",
       "30   mlp3scaled  0.932083    0.712375  0.719449  0.708475  0.701342   \n",
       "31   mlp4scaled  0.930833    0.710141  0.715753  0.707037  0.701342   \n",
       "32   mlp1maxabs  0.939167    0.709669  0.733577  0.696949  0.674497   \n",
       "33   mlp0scaled  0.919167    0.703055  0.690096  0.710526  0.724832   \n",
       "34          svm  0.933750    0.683651  0.708257  0.670605  0.647651   \n",
       "35   mlp1scaled  0.895833    0.678287  0.640805  0.701258  0.748322   \n",
       "36         emb0  0.920000    0.655837  0.665505  0.650545  0.640940   \n",
       "37         mlp4  0.931250    0.647454  0.683301  0.628975  0.597315   \n",
       "38     baseline  0.936667    0.641373  0.692308  0.615994  0.573826   \n",
       "39          dtc  0.927083    0.624789  0.661509  0.605953  0.573826   \n",
       "40          rfc  0.935417    0.623027  0.679089  0.595497  0.550336   \n",
       "41   mlp5scaled  0.782083    0.621076  0.514392  0.702689  0.929530   \n",
       "42      textcat  0.776667    0.619680  0.510949  0.703518  0.939597   \n",
       "43         emb1  0.911250    0.601399  0.617594  0.592695  0.577181   \n",
       "44          knn  0.848750    0.601285  0.543396  0.639432  0.724832   \n",
       "45     fasttext  0.767917    0.591516  0.488522  0.670701  0.892617   \n",
       "46         cld3  0.580833    0.473001  0.360051  0.573804  0.949664   \n",
       "\n",
       "    precision    tn   fp   fn   tp  \n",
       "0    0.715517  2003   99   49  249  \n",
       "1    0.643032  1956  146   35  263  \n",
       "2    0.727273  2012   90   58  240  \n",
       "3    0.725076  2011   91   58  240  \n",
       "4    0.732308  2015   87   60  238  \n",
       "5    0.704678  2001  101   57  241  \n",
       "6    0.764120  2031   71   68  230  \n",
       "7    0.715152  2008   94   62  236  \n",
       "8    0.725857  2014   88   65  233  \n",
       "9    0.697329  2000  102   63  235  \n",
       "10   0.668524  1983  119   58  240  \n",
       "11   0.745033  2025   77   73  225  \n",
       "12   0.745033  2025   77   73  225  \n",
       "13   0.721519  2014   88   70  228  \n",
       "14   0.696049  2002  100   69  229  \n",
       "15   0.686567  1997  105   68  230  \n",
       "16   0.656425  1979  123   63  235  \n",
       "17   0.645777  1972  130   61  237  \n",
       "18   0.714744  2013   89   75  223  \n",
       "19   0.726974  2019   83   77  221  \n",
       "20   0.767857  2037   65   83  215  \n",
       "21   0.769784  2038   64   84  214  \n",
       "22   0.785185  2044   58   86  212  \n",
       "23   0.680851  1997  105   74  224  \n",
       "24   0.806202  2052   50   90  208  \n",
       "25   0.772894  2040   62   87  211  \n",
       "26   0.780669  2043   59   88  210  \n",
       "27   0.796154  2049   53   91  207  \n",
       "28   0.793774  2049   53   94  204  \n",
       "29   0.804781  2053   49   96  202  \n",
       "30   0.738516  2028   74   89  209  \n",
       "31   0.730769  2025   77   89  209  \n",
       "32   0.804000  2053   49   97  201  \n",
       "33   0.658537  1990  112   82  216  \n",
       "34   0.781377  2048   54  105  193  \n",
       "35   0.560302  1927  175   75  223  \n",
       "36   0.692029  2017   85  107  191  \n",
       "37   0.798206  2057   45  120  178  \n",
       "38   0.872449  2077   25  127  171  \n",
       "39   0.780822  2054   48  127  171  \n",
       "40   0.886486  2081   21  134  164  \n",
       "41   0.355584  1600  502   21  277  \n",
       "42   0.350877  1584  518   18  280  \n",
       "43   0.664093  2015   87  126  172  \n",
       "44   0.434608  1821  281   82  216  \n",
       "45   0.336283  1577  525   32  266  \n",
       "46   0.222135  1111  991   15  283  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(combined_results, 'combined_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although none of the models achieved F1.5-score of 0.8 or higher, the results of the research are promising. The difference between scores of existing language detection models (textcat, fasttext, cld3) and newly trained ones are large.\n",
    "\n",
    "Best results are achieved by models combining convolutional and LSTM or bidirectional LSTM layers: `convbilstm0` and `convlstm2`. In business context a further analysis of the two models would have to be prepared in order to choose the best one for company's purposes. Possibly, the choice of metrics could be reconsidered and yet more emphasis would be put on recall, leading to choosing `convlstm2`.\n",
    "\n",
    "It is also worth noting that `ridge`, classifier using ridge regression took 5. place, before many (however simple) CNN and RNN models.\n",
    "\n",
    "Two best models (`convbilstm0` and `convlstm2`) have been saved to `models` subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible ways to continue work on the project:\n",
    "\n",
    "* acquiring more / more diverse training data\n",
    "* additional ways of data preparation - what else could be done?\n",
    "    * would TfidfVectorizer() give better results than CountVectorizer()?\n",
    "    * instead of 3-grams, should other n-grams be used? maybe of different lenghts?\n",
    "    * other ways of dimensionality reduction, apart from TruncatedSVD()\n",
    "    * would the results be better after using a lemmatizer on the dataset?\n",
    "* additional algorithms to test - e.g. a voting classifier?\n",
    "* further study of Tensorflow and Keras libraries, i.a.:\n",
    "    * grid search of hyperparameters\n",
    "    * use of initial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
